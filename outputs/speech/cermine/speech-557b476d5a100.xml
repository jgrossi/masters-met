<article>
  <front>
    <journal-meta>
      <journal-title-group>
        <journal-title>JARO</journal-title>
      </journal-title-group>
    </journal-meta>
    <article-meta>
      <title-group>
        <article-title>Effects of Temporal Fine Structure on the Lateralization of Speech and on Speech Understanding in Noise</article-title>
      </title-group>
      <article-id pub-id-type="doi">10.1007/s10162-007-0074-y</article-id>
      <contrib-group>
        <aff id="0">
          <label>0</label>
          <institution>Department of Bioengineering, University of Washington</institution>
          ,
          <addr-line>Seattle, WA</addr-line>
          ,
          <country country="US">USA</country>
        </aff>
        <aff id="1">
          <label>1</label>
          <institution>Department of Otolaryngology, Head and Neck Surgery, University of Washington</institution>
          ,
          <addr-line>Seattle, WA</addr-line>
          ,
          <country country="US">USA</country>
        </aff>
        <aff id="2">
          <label>2</label>
          <institution>VM Bloedel Hearing Research Center, University of Washington</institution>
          ,
          <addr-line>Box 357923, Seattle, WA 98195-7923</addr-line>
          ,
          <country country="US">USA</country>
        </aff>
      </contrib-group>
      <abstract>
        <p>This study evaluated the role of temporal fine structure in the lateralization and understanding of speech in six normal-hearing listeners. Interaural time differences (ITDs) were introduced to invoke lateralization. Speech reception thresholds (SRTs) were evaluated in backgrounds of two-talker babble and speech-shaped noise. Two-syllable words with ITDs of 0 and 700 ms were used as targets. A vocoder technique, which systematically randomized fine structure, was used to evaluate the effects of fine structure on these tasks. Randomization of temporal fine structure was found to significantly reduce the ability of normal-hearing listeners to lateralize words, although for many listeners, good lateralization performance was achieved with as much as 80% fine-structure randomization. Most listeners demonstrated some rudimentary ability to lateralize with 100% fine-structure randomization. When ITDs were 0 ms, randomization of fine structure had a much greater effect on SRT in two-talker babble than in speech-shaped noise. Binaural advantages were also observed. In steady noise, the difference in SRT between words with 0- vs 700-ms ITDs was, on average, 6 dB with no fine-structure randomization and 2 dB with 100% fine-structure randomization. In two-talker babble this difference was 1.9 dB and, for most listeners, showed little effect of the degree of finestructure randomization. These results suggest that (1) improved delivery of temporal fine structure would improve speech understanding in noise for implant recipients, (2) bilateral implant recipients might benefit from temporal envelope ITDs, and (3) improved delivery of temporal information could improve binaural benefits.</p>
      </abstract>
      <kwd-group>
        <kwd>binaural hearing</kwd>
        <kwd>fine structure</kwd>
        <kwd>cochlear implant</kwd>
      </kwd-group>
      <volume>383</volume>
      <issue>2007</issue>
      <fpage>373</fpage>
      <lpage>383</lpage>
      <pub-date>
        <year>2007</year>
      </pub-date>
      <history>
        <date date-type="accepted">
          <day>17</day>
          <month>1</month>
          <year>2007</year>
        </date>
        <date date-type="received">
          <day>30</day>
          <month>8</month>
          <year>2006</year>
        </date>
      </history>
    </article-meta>
  </front>
  <body>
    <sec id="1">
      <title>-</title>
      <p>Interaural time differences (ITDs) contribute to
important real-world tasks such as localization ability
(Rayleigh 1907; Wightman and Kistler 1992) and
binaural unmasking (Carhart et al. 1967; Bronkhorst
and Plomp 1988; Culling et al. 2004). Real
environmental sounds provide ITDs with both envelope and
fine structure. At low frequencies (G1.5 kHz) for
stimuli longer than 100 ms, fine-structure ITDs
dominate perception (Tobias and Schubert 1959);
however, both envelope and fine-structure ITDs
contribute to lateralization ability (Klumpp and Eady
1956; Yost et al. 1971; Henning 1974; McFadden and
Pasanen 1976; Van de Par and Kohlrausch 1997),
binaural unmasking (Van de Par and Kohlrausch
1997; Long et al. 2006), and segregation ability
(Drennan et al. 2003; Best et al. 2004).</p>
      <p>Common cochlear implant sound processing
strategies do not explicitly encode temporal fine-structure
information, but only the envelope information.</p>
      <p>While some fine-structure information for low
frequencies is passed through the temporal envelope,
most temporal fine-structure information is lost in
processing. Previous observations that envelope ITDs
contribute to lateralization and segregation in
normal-hearing listeners is beneficial for bilateral
implantees because this means it would be
theoretically possible for implantees to glean some benefit
from interaural timing differences. Temporal fine
structure is also known to provide information, which
help normal-hearing humans perceive music (Smith
et al. 2002), speech in noise (Kong et al. 2005), and
tonal languages (Xu and Pfingst 2003). Hence,
improved delivery of temporal fine structure should
help monaural and binaural implantees. This study
evaluates the role of fine structure in practical tasks
such as the lateralization of speech and speech
understanding in noise. A key motivation is to better
understand how improved delivery of fine structure
could improve hearing in implantees. Insights into
the role of fine structure in practical hearing tasks
could lead to improvements in cochlear implant
sound processing.</p>
      <p>In this study, we presented vocoder-processed
sounds to normal-hearing listeners. The vocoder
divided the signal into six band-pass channels. A
signal processing technique enabled graded
randomization of the fine structure, but preserved the
temporal envelope of the waveforms. The procedure
offers the unique capability to systematically vary the
extent of the randomization of the fine structure to
quantify the effect of temporal fine structure on
human auditory processing capabilities. This study
served two purposes, one scientific and one clinical:
(1) to determine the extent to which temporal fine
structure contributes to lateralization and speech
understanding in noise, and (2) to evaluate how
improved fine-structure delivery might improve these
capabilities.
Bilateral cochlear implant simulations were
presented to normal-hearing listeners who had
thresholds of less than 25 dB HL at all audiometric
frequencies. Six listeners participated in the study.</p>
      <p>The stimuli were presented over TDH-50P
headphones via a Macintosh G4 laptop in a quiet room.</p>
      <p>Speech levels were calibrated at 65 dBA. Listeners_
ages ranged from 26–38 with a mean of 32.3 years.</p>
      <p>They included two women and four men who
volunteered their time for the study. The study was
approved by the University of Washington
Institutional Review Board.</p>
      <p>A diagram of the fine-structure randomization
procedure is shown in Figure 1. The stimulus, X(t),
was passed through a bank of 6 band-pass FIR filters.</p>
      <p>The filters covered the logarithmically spaced
frequency ranges of 80–308, 308–788, 788–1794, 1794–
3906, 3906–8338, and 8,338–17,640 Hz. A Hilbert
transform was used to extract the envelope and fine
structure of each filter. A random component was
added to the Hilbert phase and then was weighted by</p>
      <p>Envelope x Randomized
Fine Structure Product
FIG. 1. Schematic of signal processing to randomize fine structure showing an acoustic signal X(t) that passed through 1 of 6 BPFs to create
xi(t). A An example filtered wave. The band-passed waveform was then passed through a Hilbert transform. B The resultant example envelope
and fine-structure waves are shown with the randomized fine structure. C, D The Hilbert phase was added to a sequence of uniform random
variables ri(t), that were weighted by NF (C), and then filtered again with the same band pass filter (D). E The final wave was multiplied by the
original Hilbert envelope to produce band-specific randomized fine structure bearing nearly the original envelope. The same processing was
executed with all six bands, which were summed to create the signal with randomized fine structure.
a noise factor, NF, which varied from 0 to 1. The NF
represents the extent of randomization of the fine
structure such that NF=1 was 100% fine-structure
randomization and NF=0 was only filtered, keeping
the fine structure identical to the original signal. This
NF concept was first introduced by Rubinstein and
Turner (2003). In signal processing terms, the NF
determined the extent of randomization of the
Hilbert phase from 0 to 100%. A sequence of
identically distributed uniform random variables
from 0 to 1, ri(t), was multiplied by 2p times the NF
and added to the Hilbert phase of the original
stimulus (see Eq. 1). The randomized fine structure
was filtered by Bi(t), and the output was multiplied by
the Hilbert envelope of the original stimulus. This
procedure is represented analytically by the following
equation operating on the output of a single
channel:
yiðtÞ ¼ absðH ðxiðtÞÞÞ
½BiðtÞ* cos ðangleðH ðxiðtÞÞÞ þ 2 nriðtÞÞ
in which yi(t) is the output stimulus, xi(t) is the filtered
stimulus, H(xi(t)) is the Hilbert transform, Bi(t) is the
impulse response of the ith band pass filter, B*^
indicates convolution, ri(t) is a sequence of uniformly
distributed random variables from 0 to 1, and n is the
NF. All six channels are summed to create the output
signal Y(t). Randomization of phase was independent
for the two ears and for each band. Using this
approach, psychophysical abilities were evaluated as a
function of the NFs ranging from 0 (no
randomization, i.e., the original stimulus filtered) to 1 (complete
randomization equivalent to a traditional 6-channel,
vocoder-type, noise-band cochlear implant simulation,
e.g., Shannon et al. 1995). In experiments with
background noise, ITDs were introduced to the
signal before NF processing. The sum of the signal
and noise (X(t)) was then processed using Eq. 1.</p>
      <p>The process of introducing fine-structure
randomization and refiltering could alter the envelope.</p>
      <p>When comparing the Btarget^ envelope before
processing and the output envelope for single pass
bands, the correlations were 0.98–0.99. Thus, the
effect of fine-structure randomization on the
envelope was slight.
Two spondees, Bpadlock^ and Bstairway,^ were
chosen, because they had robust low-frequency energy. A
6 4 repeated-measures design was used with 6 NFs
and 4 repetitions. The spondees were presented to
listeners using NFs of 0, 0.5, 0.7, 0.8, 0.9, and 1. The
ITD conditions were _750, _500, _250, 0, 250, 500,
and 750 ms. Listeners responded using a computer
mouse, clicking on one of seven boxes on a monitor
labeled L3, L2, L1, C, R1, R2, and R3 for each ITD.</p>
      <p>Each listener had a short training period in which
they could listen to each spondee with any ITD by
clicking on the response box. Listeners completed
training runs with the higher NFs until they did not
demonstrate improvement. After training,
participants completed 42 lateralization judgments per
run including 3 judgments for each word at each
ITD. Four runs were completed for each listener with
each NF. The order of presentation was randomized
in the following manner: an NF was selected
randomly from the set of six, 42 presentations including
6 at each ITD were presented in a random order
using that NF, then a different NF was selected and
the process repeated. Listeners thus heard 42
presentations with 1 NF before moving onto another NF.</p>
      <p>Performance was evaluated using r 2, based on the
correlation of the actual ITD vs the response ITD
(Good and Gilkey 1996). This metric was chosen to
look specifically at lateralization ability because a
variety of biases could be observed (left side, right
side, and center), which would yield extremely poor
accuracy even if the listener had reasonable sensitivity
to ITDs. That is, biases using other measures, such as
percent correct, could hide true lateralization ability.</p>
      <p>Binaural intelligibility level difference
The binaural intelligibility level difference (BILD)
refers to an intelligibility advantage a listener can
obtain when listening to speech in noise if the
binaural timing or phase of the speech differs from
that of the noise (Bronkhorst and Plomp 1988). A
speech reception threshold (SRT) is the signal to
noise ratio (S/N) at which speech is intelligible. In
this case, S/N for the 50% intelligibility level (the
SRT) was determined for speech in two conditions in
which the ITDs of the speech differed. Binaural
intelligibility level differences were calculated by
determining the difference between the SRT for
spondees with 0 and 700-ms ITDs. This was done four
times with two types of background noise,
steadystate, speech-shaped noise, and two-talker babble
with a variety of NFs. The final analysis was 4 2 5
using 4 repetitions, 2 types of noise background, and
5 NFs.</p>
      <p>On each trial, normal-hearing listeners identified
1 of 12 equally difficult spondees (Harris 1991)
presented in one of the two noise backgrounds. The
babble consisted of one male and one female talker
using a sentence from the SPIN test (Bilger et al.
1984). The target spondees were all spoken by a
female talker, different from the female talker in the
babble. To minimize variance that might result from
variable difficulty by using different babble
backgrounds on each trial, i.e., to get the least noisy
measure of SRT in the babble, the same babble
background was used on every trial. The male talker
spoke the sentence BName two uses for ice,^ and the
female talker spoke the sentence BBill might discuss
the foam.^ The target speech (the spondee) was
delayed from the onset of the babble by 500 ms. In
the steady noise background, the same noise was
used on every trial, and the spondees were delayed by
500 ms relative to the start of the noise. Both the
target and noise were processed with fine-structure
(Hilbert phase) randomization, independently
processed for the two ears. The spondees were presented
with ITDs of 0 or 700 ms. Noise factors were 0, 0.5,
0.75, 0.875, and 1. A one-down, one-up adaptive
tracking procedure was used in which noise levels
were tracked in 2-dB increments to determine an
SRT representing 50% correct. In the NF=0
condition using babble background, the S/N ratio
dropped below _40 dB. In this case, the listeners
were permitted to lower the overall level about 5 dB
because background noise was quite loud. The
12spondee closed set discrimination task and tracking
procedure were the same as used by Turner et al.</p>
      <p>Noise Factor
FIG. 2. Lateralization performance (r2) as a function of fine-structure randomization (noise factor) for six individual listeners. Error bars show
the 95% confidence interval from six repeated measures for each listener.
(2004). One run consisted of 14 reversals in which
the threshold was the mean of the last 10 reversals.</p>
      <p>Four tracking histories were completed for each
condition. The order of presentation was
randomized in the following way: one of the NFs was selected
randomly, then listeners completed all four runs (two
in babble and two in steady noise, with ITDs=0 and
700 ms) presented in a random order using that
specific NF. Then, a different NF was selected
randomly, and listeners completed the four
conditions (two noise backgrounds and two ITDs) in a newly
randomized order. This procedure continued until all
conditions were finished. Each listener had a different
randomized order of presentation for both the NFs
and the four conditions run with each NF. Listeners
completed all NF conditions for the first repetition
before moving on to the second repetition.
Figure 2 shows the individual lateralization results as
a function of the NF. Figure 3 shows the mean
lateralization results. Error bars in all figures show
the 95% confidence interval. A 6 4 repeated
measures ANOVA (6 NFs and 4 repetition times)
demonstrated that, as expected, there was a
significant effect of NF (F5,25=17.831, p G0.0005). There was
no effect of repetition time demonstrating there was
no learning trend in this task. The mean r2 for
lateralization was above chance for NF=1 (p =0.0093),
with 100% fine-structure randomization, suggesting
that most listeners could lateralize without
finestructure ITD information. This is consistent with
previous observations that normal-hearing listeners</p>
      <p>Mean lateralization R 2 N=6
FIG. 3. Average lateralization performance (r 2) as a function of the
noise factor. Error bars show the 95% confidence interval based on
data from six listeners.
can detect the ITD of the envelope alone (McFadden
and Pasanen 1976). There were also substantial
variations among listeners when 50% or more of the
fine structure was randomized. A few listeners (L1
and L4) were only slightly affected by 50%
finestructure randomization, whereas others (L3, L5, L6,
and L7) were greatly affected by this randomization.</p>
      <p>Speech understanding
Figure 4 shows individual data from the speech-in-noise
experiments in which the ITD=0 ms. Figure 5 shows
mean data. A 2 5 4 repeated-measures ANOVA
(2 noise backgrounds, 5 NFs, and 4 repetition times)
demonstrated that there was a main effect of the NF
(F4,20=126.5, p G0.0005), an interaction between NF
and noise background (F4,20=34.308), p G0.0005), and a
main effect of the noise background (F1,4=96.306,
p G0.0005). The main effect of noise background
demonstrated that speech understanding in babble
was usually better than speech understanding in
speech-shaped noise. The interaction demonstrated
that fine-structure randomization improved SRTs
much more in babble than in steady-state noise. As
reflected in the interaction, the difference in SRT
between the two background noises was not significant
when the NF was 1 (100% fine-structure
randomization). We note that in babble, the thresholds for NF=0
were extremely low, in the range of _35 to _40 dB S/N.</p>
      <p>These results were slightly lower than those of Turner
et al. (2004) who found _30 dB for a similar condition.</p>
      <p>The primary difference between studies was that the
present study used more reversals and more repetitions
to determine a threshold. Also, different groups of
listeners could have different capabilities.</p>
      <p>For ITD=0 ms, there was a main effect of repetition
number (F3,15=7.951, p G0.002); an interaction
between repetition number and noise background
(F3,15=5.222, p G0.011); a weak interaction between
repetition and NF (F12,60=1.914, p G0.05); and a
threeway interaction among repetition time, NF, and noise
background (F12,60=2.280, p G0.018). The effects of
repetition time indicated that there was some
improvement over time in the SRT; however, the
interactions suggest that this improvement over time
was limited to higher NFs in the babble background.</p>
      <p>For NFs of 0.75, 0.875, and 1 in the babble
background, SRTs improved by about 6 dB from the
first to the fourth time of testing, suggesting that for
the spondees presented in babble, the listeners
learned to make use of envelope cues without fine
structure or learned how to listen in the silent gaps.</p>
      <p>In all the other conditions, for speech-shaped noise
with all NFs and for two-talker babble backgrounds
with NF=0 or 0.5, there was little effect of repetition
time. We also found similar learning trends in real
)
B -50
d
(
na -50
g
i</p>
      <p>Noise Factor
FIG. 4. The figure shows individual SRTs as a function of noise factor (fine-structure randomization) for spondees in two-talker babble and
spondees in steady-state, speech-shaped noise. The spondee ITD was 0 in all cases. Error bars show the 95% confidence interval based on four
repeated measures.
cochlear implantees using the same methods for
evaluation of SRTs (Won et al. 2007, submitted).</p>
      <p>Binaural intelligibility level difference
Figure 6 shows individual BILDs based on ITDs for
spondees in babble and speech-shaped noise as a
function of the NF. The BILD is calculated by
subtracting the SRT for ITD=700 ms from the SRT
for ITD=0 ms. Figure 7 shows mean BILD data. The
result shows the extent to which fine structure
contributes to ITD-only binaural advantages in
normal-hearing listeners. A 2 5 4 repeated-measures
ANOVA (2 noise backgrounds, 5 NFs, and 4
repetition times) was conducted. A main effect of noise
background (F1,5=13.799, p G0.014) and a main effect
of NF (F4,20=5.441, p G0.004) were observed. All other
effects, including the effect of repetition time and
associated interactions, were not significant. This lack
of interaction of the BILD with the main factor of
repetition time suggested that any learning that
occurred was statistically equivalent for 0- and
700ms ITDs. Binaural intelligibility level differences were
generally larger in speech-shaped noise than in a
babble background, which was shown by the main
effect of noise background. Binaural intelligibility
level differences decrease as the amount of fine
structure decreases (i.e., as the NF increases),
demonstrated by the main effect of NF. The BILD for
NF=0 in speech-shaped noise was about 6 dB on
average, consistent with previous observations (e.g.,
Carhart et al. 1967; Bronkhorst and Plomp 1988). In
two-talker babble, the effect of fine structure on the
BILD was highly variable among listeners and did not
appear to change much as fine-structure
randomization increased, averaging about 1.9 dB across all NFs.</p>
      <p>Binaural intelligibility level differences for
speechshaped noise were more consistent among listeners
and declined monotonically from about 6 dB for
NF=0 to 1.1 dB for NF=1. Thus, the effect of fine
structure for binaural cues appeared to be greater in
speech-shaped noise than in two-talker babble.
In the first experiment, lateralization became more
difficult with increased fine-structure randomization
(Figs. 2 and 3). The results demonstrated the
dominance of fine structure (relative to envelope)
in lateralization based on ITDs. There was some
lateralization ability even with 100% fine-structure
randomization, but performance was greatly
enhanced by fine structure. The result might also
underestimate the effect of fine structure because
the interaural level differences were 0, which could
push the percept toward center, although center bias
was only apparent in the high-NF conditions when r2
values were low.</p>
      <p>The results from the listeners least affected by
finestructure randomization paralleled results from</p>
      <p>Mean SRT for ITD = 0
FIG. 5. Average SRTs as a function of noise factor for spondees in
two-talker babble and in steady-state, speech-shaped noise. The
spondee ITD was 0 in all cases. Error bars show the 95% confidence
interval based on data from six listeners.</p>
      <p>Jeffress et al. (1962) in which listeners centered
noises by adjusting the ITD of noises at the two ears.</p>
      <p>They found that listeners could center a noise image
well when the interaural correlation was as low as 0.2.</p>
      <p>The fine structure of the noise bands in the present
experiment were individually uncorrelated, making
the experimental conditions similar to those of
Jeffress et al., but the stimuli in the present
experiment had some interaural correlation, even at NF=1
because the temporal envelopes in each band
matched.</p>
      <p>The listeners showed some lateralization ability
even when the NF was 1, suggesting sensitivity to
envelope ITDs. With current processing schemes,
using acoustic presentations and unsynchronized
bilateral processors, implant users can detect
envelope ITDs as demonstrated with click trains (Laback
et al. 2004). This suggests that lateralization in
implantees based on ITDs is possible and increased
delivery of fine structure would enhance the utility of
ITD cues.</p>
      <p>For those implanted bilaterally, the place of
current delivery for a specific frequency might be
mismatched between the two ears, possibly resulting
in decreased coincident detection in the medial
superior olive (Jeffress 1948, 1958). To date,
commercial cochlear implants are not synchronized
bilaterally, so there is a potential for bilateral drift
of ITDs based on the slight variations in the pulse
rates between implants. However, the problem is
alleviated with higher pulse rates, e.g., above about
2,000 pps because the ITDs of individual pulses are
not discernable. Also, if an individual were deaf
during a critical period in development, the binaural
hearing system might not have developed normally.</p>
      <p>Nevertheless, sensitivity to ITDs was demonstrated in
implantees (Long et al. 2003; Van Hoesel and Tyler
2003; Laback et al. 2004) and, given the dominance
of fine structure for lateralization in normal-hearing
listeners, improving the delivery of fine structure
could greatly enhance the utility of ITD information
in bilateral implantees.</p>
      <p>For the case in which ITD=0 ms, the effect of
randomization of fine structure was much greater in
babble than in speech-shaped noise (Figs. 4 and 5).</p>
      <p>In babble, improved spectral and temporal
information would enhance the ability of listeners to
segregate the male and female voices based on
fundamental frequency (F0) (Brokx and Nooteboom
1982; Assmann and Summerfield 1990; Culling and
Darwin 1993; Bird and Darwin 1998; Qin and
Oxenham 2005). Hearing the individual F0s of each
voice requires good spectral resolution and accurate
perception of the temporal fine structure, which
contributes to the perception of periodicity pitch
for the low-frequency, resolved harmonics (Plomp
1967; Houtsma and Smurzynski 1990; Meddis and
O_Mard 1997). Voices can be segregated based on
the pitch manifested from the encoding of temporal
fine structure (Qin and Oxenham 2003; Kong et al.
2005; Qin and Oxenham 2006). The effect of fine
structure was less in speech-shaped noise because
there was no pitch-basis to segregate the target
speech from the background. Thus, fine-structure
randomization appeared to significantly reduce the
ability to segregate based on F0.</p>
      <p>Normal-hearing listeners benefit both from
increased spectral and temporal information with
increased fine structure, but we would not expect
the extent of spectral information to increase as
dramatically in cochlear implant users because nerve
survival and current spread are likely to limit the
number of channels that can be resolved. Previous
studies have demonstrated a limit in the spectral
processing capability of cochlear implantees to
about nine channels (e.g., Fishman et al. 1997;
Dorman et al. 1998; Friesen et al. 2001). Whereas
decreases in SRT with ITD=0 could result from
temporal and spectral degradation, decreases in
binaural unmasking with increased fine-structure</p>
      <p>Noise Factor
FIG. 6. Binaural intelligibility level difference as a function of noise factor (fine-structure randomization) for six individual listeners for
spondees in two-talker babble and in steady-state, speech-shaped noise. Error bars show the 95% confidence interval based on four repeated
measures for each listener.</p>
      <p>10</p>
      <p>8
) 6
dB 4
(
2
0</p>
      <p>Mean BILD N=6
FIG. 7. Average BILD as a function of noise factor for spondees in
two-talker babble and in steady-state, speech-shaped noise. Error
bars show the 95% confidence interval from six listeners.
randomization must result from temporal factors
because spectral factors do not play a role in
ITDonly tasks. An attractive feature of tests requiring use
of only ITDs is that any change in lateralization
ability or BILDs must be because of temporal factors.</p>
      <p>In the binaural unmasking experiments, there was
a nonzero BILD at NF=1 for both babble and
speechshaped noise. As with lateralization, we expect that this
small but positive BILD was because of sensitivity to
envelope ITDs. The noise backgrounds were, however,
the same in all cases, so in the condition in which the
signal was delayed, bilaterally, there could be an extra
700-ms bit of signal information available to the
listeners in the temporal gaps, which could contribute
to the observed binaural advantage. We expect this
was not a contributor to the BILD for NF=1 for two
reasons: (1) the duration of extra signal information
was one to two orders of magnitude less than the
duration of the gaps (õ30–70 ms), and (2) the results
suggested listening in the gaps was a learned skill, and
no evidence was found of learning the BILD. Thus, we
believe these nonzero BILDs at NF=1 were because of
sensitivity to the envelope ITDs.</p>
      <p>The presence of temporal fine structure greatly
enhanced the ability of the listeners to take
advantage of ITD cues when identifying speech in a
steadystate background, but fine structure had little effect
on the BILD in the babble background (Figs. 6 and
7). The babble had brief silent periods, which alone
would not yield any binaural advantage, but could
yield a unilateral advantage. There cannot be
binaural unmasking in periods in which there is no
masking. Thus, when ITD=0 ms, the system appears
to make maximum use of timing information
unilaterally, such that the system could glean little
additional benefit from bilateral interaural timing difference.</p>
      <p>The present study compared SRTs between
steadystate background and babble in which the babble was
the same on every trial. The purpose of using the
same noise background was to maintain consistency
in the difficulty of the background noise. Trial-to-trial
changes in the background noises would add a
source of variance to the measurement of the SRT
that was undesirable. With the babble background,
however, listeners could learn to listen in the gaps. In
the high NF condition in babble, there was about 6
dB of improvement, on average, in SRT over time.</p>
      <p>The NF=1 condition was similar to previous studies
(Qin and Oxenham 2003; Stickney et al. 2004), which
used multichannel, noise-excited vocoders, with no
binaural cues. Qin and Oxenham demonstrated that
SRTs were better for steady noise than for the
singletalker background noise, and Stickney et al.
demonstrated similar, and sometimes better performance
with the steady background. Our study showed
slightly better performance (although not
significant) for the babble background than for
steadystate background. The use of the same background
noise on each trial could account for the
differences, as these two previous studies used a speech
masker, which differed on each trial. Also, we used
two-talker babble, whereas Qin and Oxenham and
Stickney et al. used one-talker background noise.</p>
      <p>The number of talkers can have a big effect on the
extent of masking (Miller 1947). In addition, our
listeners used a closed set speech test whereas the
other studies used open set. Finally, our study used a
Hilbert vocoder, but the other studies used a
rectification-and-low-pass-filter approach. All of these factors
could contribute to differences among studies.</p>
      <p>The results suggested that improved delivery of
temporal fine structure using a cochlear implant could
improve the ability of implantees to localize by
providing improved ITD encoding, and improve the ability of
implantees to segregate speech from noise. Implantees
have previously been shown to have more difficulty
understanding spondees in babble versus steady
backgrounds (Turner et al. 2004), but our recent
(unpublished) results with 20 implant listeners have shown
SRTs in babble and steady-state noise are about the
same (mean SRT in babble _5.6 dB and mean SRT in
steady-state, speech-shaped noise _6.6 dB). The best
performance for an implantee in steady noise was _15
dB, corresponding to normal-hearing performance in
Figure 5 at NF equal to about 0.85. This suggests that
in steady noise better implant users receive some
finestructure information. Improvement in the delivery of
fine-structure information would be expected to
enhance performance.</p>
      <p>Rubinstein et al. (1999) has proposed an approach
for improving temporal encoding, which was shown
neurophysiologically to yield responses that more
closely resemble normal-hearing than those
generated from traditional processing schemes (Litvak et al.
2003). The procedures described herein could be
useful in evaluating strategies for improving temporal
delivery in any cochlear implant device.</p>
    </sec>
    <sec id="2">
      <title>ACKNOWLEDGMENTS</title>
      <p>The authors are grateful for the dedicated efforts of our
listeners. We thank Chad Ruffin for assistance in the
creation of Figure 1. Leah Drennan and two anonymous
reviewers provided helpful comments on previous versions
of this manuscript. JHW appreciates the mentorship of SM
Lee and SH Hong. This work was supported by NIH grants
R01-DC007525, a subcontract of P50-DC00242,
T32DC00018 (VKD), the University of Washington, and grants
from the Korean Science and Engineering Foundation, and
Hanyang University (JHW).</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>ASSMANN</surname>
            <given-names>PF</given-names>
          </string-name>
          ,
          <string-name>
            <surname>SUMMERFIELD</surname>
            <given-names>Q.</given-names>
          </string-name>
          <article-title>Modeling the perception of concurrent vowels: vowels with different fundamental frequencies</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>88</volume>
          :
          <fpage>680</fpage>
          -
          <lpage>697</lpage>
          ,
          <year>1990</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>BEST</surname>
            <given-names>V</given-names>
          </string-name>
          ,
          <string-name>
            <surname>SCHAIK</surname>
            <given-names>AV</given-names>
          </string-name>
          ,
          <string-name>
            <surname>CARLILE</surname>
            <given-names>S.</given-names>
          </string-name>
          <article-title>Separation of concurrent broadband sound sources by human listeners</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>115</volume>
          :
          <fpage>324</fpage>
          -
          <lpage>336</lpage>
          ,
          <year>2004</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>BILGER</surname>
            <given-names>RC</given-names>
          </string-name>
          ,
          <string-name>
            <surname>NUETZEL</surname>
            <given-names>JM</given-names>
          </string-name>
          ,
          <string-name>
            <surname>RABINOWITZ</surname>
            <given-names>WM</given-names>
          </string-name>
          , RZECZKOWSKI C.
          <article-title>Standardization of a test of speech perception in noise</article-title>
          .
          <source>J. Speech Hear. Res</source>
          .
          <volume>27</volume>
          :
          <fpage>32</fpage>
          -
          <lpage>48</lpage>
          ,
          <year>1984</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>BIRD</surname>
            <given-names>J</given-names>
          </string-name>
          , DARWIN CJ.
          <article-title>Effects of a difference in fundamental frequency in separating two sentences</article-title>
          . In: Palmer AR,
          <string-name>
            <surname>Rees</surname>
            <given-names>A</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Summerfield</surname>
            <given-names>AQ</given-names>
          </string-name>
          and Meddis R (eds) Psychophysical and
          <string-name>
            <given-names>Physiological</given-names>
            <surname>Advances</surname>
          </string-name>
          in Hearing. London, Whurr, pp.
          <fpage>263</fpage>
          -
          <lpage>269</lpage>
          ,
          <year>1998</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>BROKX</surname>
            <given-names>JPL</given-names>
          </string-name>
          ,
          <article-title>NOOTEBOOM SG. Intonation and the perceptual separation of simultaneous voices</article-title>
          .
          <source>J. Phon</source>
          .
          <volume>10</volume>
          :
          <fpage>23</fpage>
          -
          <lpage>36</lpage>
          ,
          <year>1982</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>BRONKHORST</surname>
            <given-names>AW</given-names>
          </string-name>
          ,
          <string-name>
            <surname>PLOMP R.</surname>
          </string-name>
          <article-title>The effect of head-induced interaural time and level differences on speech intelligibility in noise</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>83</volume>
          :
          <fpage>1508</fpage>
          -
          <lpage>1516</lpage>
          ,
          <year>1988</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <given-names>CARHART R</given-names>
            ,
            <surname>TILLMAN</surname>
          </string-name>
          <string-name>
            <surname>TW</surname>
          </string-name>
          , JOHNSON KR.
          <article-title>Release of masking for speech through interaural time delay</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>42</volume>
          :
          <fpage>124</fpage>
          -
          <lpage>138</lpage>
          ,
          <year>1967</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>CULLING</surname>
            <given-names>JF</given-names>
          </string-name>
          , DARWIN CJ.
          <article-title>Perceptual separation of simultaneous vowels: within and across-formant grouping by F0</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>93</volume>
          :
          <fpage>3454</fpage>
          -
          <lpage>3467</lpage>
          ,
          <year>1993</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>CULLING</surname>
            <given-names>JF</given-names>
          </string-name>
          ,
          <string-name>
            <surname>HAWLEY</surname>
            <given-names>ML</given-names>
          </string-name>
          ,
          <string-name>
            <surname>LITOVSKY</surname>
            <given-names>RY</given-names>
          </string-name>
          .
          <article-title>The role of head-induced interaural time and level differences in the speech reception threshold for multiple interfering sound sources</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>116</volume>
          :
          <fpage>1057</fpage>
          -
          <lpage>1065</lpage>
          ,
          <year>2004</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>DORMAN</surname>
            <given-names>MF</given-names>
          </string-name>
          ,
          <string-name>
            <surname>LOIZOU</surname>
            <given-names>PC</given-names>
          </string-name>
          ,
          <string-name>
            <surname>FITZKE</surname>
            <given-names>J</given-names>
          </string-name>
          ,
          <string-name>
            <surname>TU</surname>
            <given-names>Z.</given-names>
          </string-name>
          <article-title>The recognition of sentences in noise by normal-hearing listeners using simulations of cochlear-implant signal processors with 6-20 channels</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>104</volume>
          :
          <fpage>3583</fpage>
          -
          <lpage>3585</lpage>
          ,
          <year>1998</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>DRENNAN</surname>
            <given-names>WR</given-names>
          </string-name>
          ,
          <string-name>
            <surname>GATEHOUSE</surname>
            <given-names>S</given-names>
          </string-name>
          , LEVER C.
          <article-title>Perceptual segregation of competing speech sounds: the role of spatial location</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>114</volume>
          :
          <fpage>2178</fpage>
          -
          <lpage>2189</lpage>
          ,
          <year>2003</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>FISHMAN</surname>
            <given-names>K</given-names>
          </string-name>
          ,
          <string-name>
            <surname>SHANNON</surname>
            <given-names>RV</given-names>
          </string-name>
          , SLATTERY WH.
          <article-title>Speech recognition as a function of the number of electrodes used in the SPEAK cochlear implant speech processor</article-title>
          .
          <source>J. Speech Hear. Res</source>
          .
          <volume>32</volume>
          :
          <fpage>524</fpage>
          -
          <lpage>535</lpage>
          ,
          <year>1997</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>FRIESEN</surname>
            <given-names>LM</given-names>
          </string-name>
          ,
          <string-name>
            <surname>SHANNON</surname>
            <given-names>RV</given-names>
          </string-name>
          ,
          <string-name>
            <surname>BASKENT</surname>
            <given-names>D</given-names>
          </string-name>
          ,
          <string-name>
            <surname>WANG</surname>
            <given-names>X.</given-names>
          </string-name>
          <article-title>Speech recognition in noise as a function of the number of spectral channels: comparison of acoustic hearing and cochlear implants</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>110</volume>
          :
          <fpage>1150</fpage>
          -
          <lpage>1163</lpage>
          ,
          <year>2001</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>GOOD</surname>
            <given-names>MD</given-names>
          </string-name>
          , GILKEY RH.
          <article-title>Sound localization in noise. The effect of signal-to-noise ratio</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>99</volume>
          :
          <fpage>1108</fpage>
          -
          <lpage>1117</lpage>
          ,
          <year>1996</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>HARRIS RW</surname>
          </string-name>
          .
          <article-title>Speech audiometry materials compact disk</article-title>
          .
          <source>Provo</source>
          , UT, Brigham Young University, pp.
          <year>1991</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>HENNING GB</surname>
          </string-name>
          .
          <article-title>Detectability of interaural delay in high-frequency complex waveforms</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>55</volume>
          :
          <year>1974</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>HOUTSMA</surname>
            <given-names>AJM</given-names>
          </string-name>
          , SMURZYNSKI J.
          <article-title>Pitch identification and discrimination for complex tones with many harmonics</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>87</volume>
          :
          <fpage>304</fpage>
          -
          <lpage>310</lpage>
          ,
          <year>1990</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>JEFFRESS LA</surname>
          </string-name>
          .
          <article-title>A place theory of sound localization</article-title>
          .
          <source>J. Comp. Physiol. Psychol</source>
          .
          <volume>41</volume>
          :
          <fpage>35</fpage>
          -
          <lpage>39</lpage>
          ,
          <year>1948</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>JEFFRESS LA</surname>
          </string-name>
          .
          <article-title>Medial geniculate body-a disavowal</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>30</volume>
          :
          <fpage>802</fpage>
          -
          <lpage>803</lpage>
          ,
          <year>1958</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>JEFFRESS</surname>
            <given-names>LA</given-names>
          </string-name>
          ,
          <string-name>
            <surname>BLODGETT</surname>
            <given-names>HC</given-names>
          </string-name>
          , DEATHERAGE BH.
          <article-title>Effect of interaural correlation on the precision of centering a noise</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>34</volume>
          :
          <fpage>1122</fpage>
          -
          <lpage>1123</lpage>
          ,
          <year>1962</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>KLUMPP</surname>
            <given-names>RG</given-names>
          </string-name>
          ,
          <string-name>
            <surname>EADY</surname>
            <given-names>HR</given-names>
          </string-name>
          .
          <article-title>Some measurements of interaural time difference thresholds</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>28</volume>
          :
          <fpage>859</fpage>
          -
          <lpage>860</lpage>
          ,
          <year>1956</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>KONG</surname>
            <given-names>Y-Y</given-names>
          </string-name>
          ,
          <string-name>
            <surname>STICKNEY</surname>
            <given-names>GS</given-names>
          </string-name>
          ,
          <string-name>
            <surname>ZENG</surname>
            <given-names>F-G</given-names>
          </string-name>
          .
          <article-title>Speech and melody recognition in binaurally combined acoustic and electric hearing</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>117</volume>
          :
          <fpage>1351</fpage>
          -
          <lpage>1361</lpage>
          ,
          <year>2005</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>LABACK</surname>
            <given-names>B</given-names>
          </string-name>
          ,
          <string-name>
            <surname>POK</surname>
            <given-names>S-M</given-names>
          </string-name>
          ,
          <string-name>
            <surname>BAUMGARTNER</surname>
            <given-names>W-D</given-names>
          </string-name>
          ,
          <string-name>
            <surname>DEUTSCH</surname>
            <given-names>WA</given-names>
          </string-name>
          ,
          <string-name>
            <surname>SCHMID</surname>
            <given-names>K.</given-names>
          </string-name>
          <article-title>Sensitivity to interaural level and envelope differences of two bilateral cochlear implant listeners using clinical sound processors</article-title>
          .
          <source>Ear Hear</source>
          .
          <volume>25</volume>
          :
          <fpage>488</fpage>
          -
          <lpage>500</lpage>
          ,
          <year>2004</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>LITVAK</surname>
            <given-names>L</given-names>
          </string-name>
          ,
          <string-name>
            <surname>DELGUTTE</surname>
            <given-names>B</given-names>
          </string-name>
          ,
          <string-name>
            <surname>EDDINGTON</surname>
            <given-names>D.</given-names>
          </string-name>
          <article-title>Improved neural representation of vowels in electric stimulation using desynchronizing pulse trains</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>114</volume>
          :
          <fpage>2099</fpage>
          -
          <lpage>2111</lpage>
          ,
          <year>2003</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>LONG</surname>
            <given-names>CJ</given-names>
          </string-name>
          ,
          <string-name>
            <surname>CARLYON</surname>
            <given-names>RP</given-names>
          </string-name>
          ,
          <string-name>
            <surname>LITOVSKY</surname>
            <given-names>RY</given-names>
          </string-name>
          , DOWNS DH.
          <article-title>Binaural unmasking with bilateral cochlear implants</article-title>
          .
          <source>J. Assoc. Res. Otolaryngol</source>
          .
          <volume>7</volume>
          :
          <fpage>352</fpage>
          -
          <lpage>360</lpage>
          ,
          <year>2006</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>LONG</surname>
            <given-names>CJ</given-names>
          </string-name>
          ,
          <string-name>
            <surname>EDDINGTON</surname>
            <given-names>DK</given-names>
          </string-name>
          ,
          <string-name>
            <surname>COLBURN</surname>
            <given-names>HS</given-names>
          </string-name>
          , RABINOWITZ WM.
          <article-title>Binaural sensitivity as a function of interaural electrode position with a bilateral cochlear implant user</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>114</volume>
          :
          <fpage>1565</fpage>
          -
          <lpage>1574</lpage>
          ,
          <year>2003</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>MCFADDEN</surname>
            <given-names>D</given-names>
          </string-name>
          ,
          <string-name>
            <surname>PASANEN</surname>
            <given-names>EG</given-names>
          </string-name>
          .
          <article-title>Lateralization at high frequencies based on interaural time differences</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>59</volume>
          :
          <fpage>634</fpage>
          -
          <lpage>639</lpage>
          ,
          <year>1976</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <given-names>MEDDIS R</given-names>
            ,
            <surname>O_MARD</surname>
          </string-name>
          <string-name>
            <surname>L.</surname>
          </string-name>
          <article-title>A unitary model of pitch perception</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>102</volume>
          :
          <fpage>1811</fpage>
          -
          <lpage>1820</lpage>
          ,
          <year>1997</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>MILLER GA</surname>
          </string-name>
          .
          <article-title>The masking of speech</article-title>
          .
          <source>Psychol. Bull</source>
          .
          <volume>44</volume>
          :
          <fpage>105</fpage>
          -
          <lpage>129</lpage>
          ,
          <year>1947</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>PLOMP R.</surname>
          </string-name>
          <article-title>Pitch of complex tones</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>41</volume>
          :
          <fpage>1526</fpage>
          -
          <lpage>1533</lpage>
          ,
          <year>1967</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>QIN</surname>
            <given-names>MK</given-names>
          </string-name>
          ,
          <string-name>
            <surname>OXENHAM</surname>
            <given-names>AJ</given-names>
          </string-name>
          .
          <article-title>Effects of simulated cochlear-implant processing on speech reception in fluctuating maskers</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>114</volume>
          :
          <fpage>446</fpage>
          -
          <lpage>454</lpage>
          ,
          <year>2003</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>QIN</surname>
            <given-names>MK</given-names>
          </string-name>
          ,
          <string-name>
            <surname>OXENHAM</surname>
            <given-names>AJ</given-names>
          </string-name>
          .
          <article-title>Effects of envelope-vocoder processing on F0 discrimination and concurrent-vowel identification</article-title>
          .
          <source>Ear Hear</source>
          .
          <volume>26</volume>
          :
          <fpage>451</fpage>
          -
          <lpage>460</lpage>
          ,
          <year>2005</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>QIN</surname>
            <given-names>MK</given-names>
          </string-name>
          ,
          <string-name>
            <surname>OXENHAM</surname>
            <given-names>AJ</given-names>
          </string-name>
          .
          <article-title>Effects of introducing unprocessed lowfrequency information on the reception of envelope-vocoder processed speech</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>119</volume>
          :
          <fpage>2417</fpage>
          -
          <lpage>2426</lpage>
          ,
          <year>2006</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>RAYLEIGH L.</surname>
          </string-name>
          <article-title>On our perception of sound direction</article-title>
          .
          <source>Philos. Mag</source>
          .
          <volume>74</volume>
          :
          <fpage>214</fpage>
          -
          <lpage>231</lpage>
          ,
          <year>1907</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>RUBINSTEIN</surname>
            <given-names>JT</given-names>
          </string-name>
          ,
          <article-title>TURNER CW. A novel acoustic simulation of cochlear implant hearing: effects of temporal fine structure</article-title>
          .
          <source>First International IEEE EMBS Conference on Neural Engineering</source>
          , IEEE Press,
          <fpage>142</fpage>
          -
          <lpage>145</lpage>
          ,
          <year>2003</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>RUBINSTEIN</surname>
            <given-names>JT</given-names>
          </string-name>
          ,
          <string-name>
            <surname>WILSON</surname>
            <given-names>BS</given-names>
          </string-name>
          ,
          <string-name>
            <surname>FINLEY</surname>
            <given-names>CC</given-names>
          </string-name>
          ,
          <string-name>
            <surname>ABBAS</surname>
            <given-names>PJ</given-names>
          </string-name>
          .
          <article-title>Pseudospontaneous activity: stochastic independence of auditory nerve fibers with electrical stimulation</article-title>
          .
          <source>Hear. Res</source>
          .
          <volume>127</volume>
          :
          <fpage>108</fpage>
          -
          <lpage>118</lpage>
          ,
          <year>1999</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>SHANNON</surname>
            <given-names>RV</given-names>
          </string-name>
          ,
          <string-name>
            <surname>ZENG</surname>
            <given-names>F-G</given-names>
          </string-name>
          ,
          <string-name>
            <surname>KAMATH</surname>
            <given-names>V</given-names>
          </string-name>
          ,
          <string-name>
            <surname>WYGONSKI</surname>
            <given-names>J</given-names>
          </string-name>
          ,
          <string-name>
            <surname>EKELID</surname>
            <given-names>M.</given-names>
          </string-name>
          <article-title>Speech recognition with primarily temporal cues</article-title>
          .
          <source>Science</source>
          <volume>270</volume>
          :
          <fpage>303</fpage>
          -
          <lpage>304</lpage>
          ,
          <year>1995</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>SMITH</surname>
            <given-names>ZM</given-names>
          </string-name>
          ,
          <string-name>
            <surname>DELGUTTE</surname>
            <given-names>B</given-names>
          </string-name>
          ,
          <string-name>
            <surname>OXENHAM</surname>
            <given-names>AJ</given-names>
          </string-name>
          .
          <article-title>Chimaeric sounds reveal dichotomies in auditory perception</article-title>
          .
          <source>Nature</source>
          <volume>416</volume>
          :
          <fpage>87</fpage>
          -
          <lpage>90</lpage>
          ,
          <year>2002</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>STICKNEY</surname>
            <given-names>GS</given-names>
          </string-name>
          ,
          <string-name>
            <surname>ZENG</surname>
            <given-names>F-G</given-names>
          </string-name>
          ,
          <string-name>
            <surname>LITOVSKY</surname>
            <given-names>R</given-names>
          </string-name>
          , ASSMANN P.
          <article-title>Cochlear implant speech recognition with speech maskers</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>116</volume>
          :
          <fpage>1081</fpage>
          -
          <lpage>1091</lpage>
          ,
          <year>2004</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>TOBIAS</surname>
            <given-names>JV</given-names>
          </string-name>
          , SCHUBERT ED.
          <article-title>Effective onset duration of auditory stimuli</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>31</volume>
          :
          <fpage>1595</fpage>
          -
          <lpage>1605</lpage>
          ,
          <year>1959</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>TURNER</surname>
            <given-names>CW</given-names>
          </string-name>
          ,
          <string-name>
            <surname>GANTZ</surname>
            <given-names>BJ</given-names>
          </string-name>
          ,
          <string-name>
            <surname>VIDAL</surname>
            <given-names>C</given-names>
          </string-name>
          ,
          <string-name>
            <surname>BEHRENS</surname>
            <given-names>A</given-names>
          </string-name>
          , HENRY BA.
          <article-title>Speech recognition in noise for cochlear implant listeners: Benefits of residual acoustic hearing</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>115</volume>
          :
          <fpage>1729</fpage>
          -
          <lpage>1735</lpage>
          ,
          <year>2004</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>VAN DE PAR</surname>
            <given-names>S</given-names>
          </string-name>
          ,
          <article-title>KOHLRAUSCH A. A new approach to comparing binaural masking level differences at low and high frequencies</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>101</volume>
          :
          <fpage>1671</fpage>
          -
          <lpage>1680</lpage>
          ,
          <year>1997</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>VAN HOESEL</surname>
            <given-names>RJM</given-names>
          </string-name>
          , TYLER RS.
          <article-title>Speech perception, localization and lateralization with bilateral cochlear implants</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>113</volume>
          :
          <fpage>1617</fpage>
          -
          <lpage>1630</lpage>
          ,
          <year>2003</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>WIGHTMAN</surname>
            <given-names>FL</given-names>
          </string-name>
          ,
          <string-name>
            <surname>KISTLER</surname>
            <given-names>DJ</given-names>
          </string-name>
          .
          <article-title>The dominant role of low frequency interaural time differences in sound localization</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>91</volume>
          :
          <fpage>1648</fpage>
          -
          <lpage>1661</lpage>
          ,
          <year>1992</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>WON</surname>
            <given-names>JH</given-names>
          </string-name>
          ,
          <string-name>
            <surname>DRENNAN</surname>
            <given-names>W</given-names>
          </string-name>
          , RUBINSTEIN J.
          <article-title>Spectral ripple resolution and speech perception in babble and speech-shaped noise by cochlear implant listeners</article-title>
          .
          <article-title>Presented at the 30th annual midwinter meeting of the Association for</article-title>
          Research in Otolaryngology, vol.
          <volume>30</volume>
          , pp.
          <fpage>304</fpage>
          ,
          <year>2007</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>XU</surname>
            <given-names>L</given-names>
          </string-name>
          ,
          <string-name>
            <surname>PFINGST</surname>
            <given-names>BE</given-names>
          </string-name>
          .
          <article-title>Relative importance of temporal envelope and fine structure in lexical-tone perception</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>114</volume>
          :
          <fpage>3024</fpage>
          -
          <lpage>3027</lpage>
          ,
          <year>2003</year>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>YOST</surname>
            <given-names>WA</given-names>
          </string-name>
          ,
          <string-name>
            <surname>WIGHTMAN</surname>
            <given-names>FL</given-names>
          </string-name>
          , GREEN DM.
          <article-title>Lateralization of filtered clicks</article-title>
          .
          <source>J. Acoust. Soc. Am.</source>
          <volume>39</volume>
          :
          <fpage>1526</fpage>
          -
          <lpage>1531</lpage>
          ,
          <year>1971</year>
          .
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
