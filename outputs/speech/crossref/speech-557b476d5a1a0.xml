<?xml version="1.0"?>
<pdf>
  <title line_height="17.86" font="JMCDNP+Arial-BoldMT">Interaction between auditory
and motor systems in speech perception</title>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.02"
year_ratio="0.0" cap_ratio="0.0" name_ratio="0.2564102564102564" word_count="117"
lateness="0.14285714285714285" reference_score="0.29">How listeners process the
acoustic signals of speech is a hot question. Traditionally, studies of this question
have mainly focused on the functions of the auditory system. However, speech
processing is not the pure and simple analysis of speech sound signals, but a quite
complicated integrated process involving multisensory modalities and even the motor
system. In this review, we focus on the interaction between the auditory system and
the motor system in speech perception and emphasize that the motor processing
component plays an essential role: activation of the perceptual-motor loop enables
listeners to both track the speaker over time and form the intention to speak,
especially under adverse listening conditions, such as a noisy and reverberating
environment.<component x="59.39" y="114.33" width="239.17" height="192.1" page="1"
page_width="612.0" page_height="792.0"></component></section>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.04"
year_ratio="0.0" cap_ratio="0.02" name_ratio="0.20920245398773007" word_count="1630"
lateness="0.5714285714285714" reference_score="4.76">in a reading-machine study. In
their experiments, although bl i nd peopl e coul d recogni ze i ndependent l i ngui
st i c units, they could not perceive alphabetic sequences and understand synthesized
speech, because the linguistic units [3] they perceived tended to merge into a blur .
This problem related to speech perception is called coarticulation, in which speech
acoustic signals are highly context-sensitive; a single phoneme can be influenced by
its surrounding [2] phonemes . However, normal listeners are able to conquer [4]
coarticulation and perceive the original phonemes well . Based on the results,
Liberman and colleagues assumed that what we really perceive when hearing speech
signals is not only sound waves, but also body "gestures" that reflect the speaker's
intention. Liberman proposed three [1] hypotheses in both a weak and a strong version
of the [5] Motor Theory . (1) The object of speech perception is the "gesture"; (2)
speech processing is special and requires a specific phonetic module; and (3)
activation of the motor cortex is involved in speech perception. When Liberman
advanced the Motor Theory, he asked a critical question, "when articulation and sound
wave go their separate ways, which way does perception go?". The answer he provided
was that perception goes with [1] . In more detail, the theory suggests that the
articulation speech sound wave that we perceive carries the speaker's information
indirectly, and there is a direct way to transmit i nformati on, that i s through the
"gesture" beari ng the speaker's intention. In other words, perceiving the "gesture"
is just perceiving the actual movement of the speaker's vocal tract, including motion
of the larynx, tongue, and [1] . Our understanding of this theory is that although
lips the listener may not be aware of tracking movement of the vocal tract, he/she
automatically uses this motor cue to recognize the speaker's intention, just as in
imitative behavior. When a speaker talks, the listener tries to follow his speech
style in mind and make a prediction before the speaker says the next word. Thus, the
speaker and the listener must converge on the same "linguistic currency", the
"gesture", to communicate. It is well known that "gesture" information can affect
speech perception in different ways, such as the McGurk effect. When the listener
sees the speaker producing t he syl l abl e ( / ga/) whi l e l i st eni ng t o anot
her syl l abl e ( / ba/), the mouth movement may mislead the listener into [6] . This
visuomotor cue hearing a different syllable (/da/) strongly influences what we
actually hear. Also, another study focused on the role of articulatory organ movement
[7] . Listeners perceive speech more in a noisy environment accurately when they can
see the speaker's articulatory organ movement than when they cannot. Al so, under
adverse listening conditions, lip-reading associated with the target sentence can act
as a cue to improve listener [ 8,9] . Thus, percei vi ng " gest ure" recogni t i on
of speech signals provides visuomotor cues, which help listeners take advantage of
the speaker's motor actions during speech in an adverse noisy environment and
facilitate the perceptual performance. In other words, listeners actively, rather
than passively, receive speech information. Supporting this view, Alho et al.
reported that stronger activation in the left premotor cortex is associated with
better identifi cation of syllables that are embedded in noise, and the cortical
activation is quite different between active and passive [10] . Also, Calla et al.
reported stronger activity in listening [11] . However, it is still not correct
trials over incorrect trials within both the ventral premotor cortex and Broca's area
clear whether the enhanced activity of the cortical areas is specifi c to speech
perceptual performance or just refl ects an increase in general processing load. To
confi rm the involvement of the motor system in speech perception, evidence of both
anatomical and functional links between the motor and auditory systems is needed. I
ndeed, some model s emphasi ze t he audi t ory-mot or link in speech perception. For
example, the dual-stream processing model suggests that there are two pathways i n
audi t i on: one i s t he vent ral pat hway down t o t he temporal lobe regulating
"what" in acoustic information, and the other is the dorsal pathway from primary
sensory areas up to the posterior cortex regulating "how" speech [12,13] . It is also
known that the ventral production takes place pathway is involved in analyzing
phonetic characters, [14,15] , and the acoustic features, and speech intelligibility
dorsal pathway is associated with sensorimotor mapping [16,17] , speech between
auditory and motor representations [14,18] [19] , and silent articulatory organ
movement . production Although this dual-stream model proposes that each of the
pathways plays a specifi c role in speech perception, how the streams interact with
each other is still not clear. The other model, the forward-inverse model, proposes
that the motor cortical regions predict the consequences of mot or commands and revi
se t he si gnal s wi t h t he [20,21] . In more detail, before motor changing
environment commands reach the effectors, the forward-inverse model produces
predicted sensory consequences of the motor commands, and then compares the predicted
results with the real sensory information. This comparison provides more i nformati
on for the central system to produce a more appropri ate performance. Wi th ti me del
ays and interruptions from the surroundings, the motor commands need to be up-dated
from time to time in order to produce the desi red outcome. Thus, when a speech si
gnal i s distorted by environmental noise and/or time delays, the motor
representation of the previous signals modifies the current auditory representation
through inverse mapping. Due to the role of motor representation in revising
distorted signals, listeners can recognize the speaker's intention and predict the
outcome of motor commands before making responses. In other words, anticipation of a
motor signal can be combined with both signal characteristics and the speaker's
articulatory information, producing a more desirable response. Based on the basic
principles of the dual-stream processing and forward-inverse models, we propose that
further-developed models should emphasize how the auditory-motor interaction is
modulated by both processing load (due to complex inputs) and prediction/ estimation
(due to task goals and feedback) (Fig. 1). So far, co-activations between auditory
and motor regions in speech perception have been clearly demonstrated. When exposed
to novel speech distortions, such as timecompressed sentences, listeners can rapidly
distinguish distorted sentences from normal-speed sentences, with increased
activation associations between the auditory [22] . Moreover, cortices and the left
ventral premotor cortex compared to listening to pseudo-words and reversedwords,
listening to normal words induces broad activation connectivity in the auditory-motor
network, which may [23] . Further be useful for facilitating semantic processing
investigation is needed to verify whether this enhanced dynamic auditory-motor
network promotes the transition from a sound stream into a series of meaningful
motorbased units and results in speech comprehension. I n addi t i on t o t he wel l
- known f act t hat speech production is tightly related to the motor cortex, some
[24-30] . For example, when listeners studies have shown that the motor cortex is
activated in speech perception tasks hear a lip-related phoneme [p] or a
tongue-related phoneme [26,27] , suggesting [t], motor regions are activated
differentially that different speech stimuli activate motor cortical regions with
different patterns. In other words, listening to various verbal stimuli may cause
differential automatic activations of cortical regions involved in speech production.
Also, it has been suggested that the activation of the motor cortex may refl ect a
mediating role of the motor cortex in speech [28-30] . perception Moreover, studies
using either functional magnetic r esonance i magi ng ( f MRI ) or t r anscr ani al
magnet i c stimulation (TMS) have confirmed the role of the motor cortex in speech
perception. For example, in a speech perception task, strong activation in the motor
cortex can be induced only when participants perceive the target [24,31] speech .
Some studies using TMS of the motor cortex have demonstrated that sti mul ati on of
speech-rel ated [32-34] regions affects speech perception . For example, using TMS to
suppress the left premotor cortex, which is activated both during speech production
and speech perception (Fig. 2), Meister et al. found that participants with a
suppressed premotor cortex were impaired in discriminating voiceless stop consonants
under white-noise masking conditions. Thus, they suggested that the premotor cortex
is essentially [33] involved in speech perception . However, the results of some
clinical studies appear not to support the view that there is an association between
i mpai rment of speech percept i on and i mpai rment of speech production. For
example, patients with expressive aphasia exhibit impairment of speech production but
not [35] speech perception or comprehension . Also, although pati ents wi th recepti
ve aphasi a exhi bi t i mpai rment of speech perception and comprehension, they can
speak [36,37] fl uently . The dissociations in expressive and receptive aphasi a
support another vi ew that speech percepti on and producti on are two di sti nct
processes. Moreover, patients with lesions in Broca's area perform well in both
word-comprehension and syllable-identification tests, but patients with temporal
lobule damage perform poorly in [38] these tests . These studies also negate the role
of motor regions in speech perception, but support the view that temporal regions
rather than motor areas are important in [16,17] speech perception . Research i n chi
l d devel opment has al so shown dissociations between speech perception and
speech<component x="313.08" y="52.54" width="239.43" height="277.55" page="1"
page_width="612.0" page_height="792.0"></component><component x="62.21" y="49.58"
width="239.5" height="626.05" page="2" page_width="612.0"
page_height="792.0"></component><component x="315.92" y="637.58" width="239.17"
height="38.05" page="2" page_width="612.0" page_height="792.0"></component><component
x="315.92" y="49.69" width="239.2" height="528.1" page="2" page_width="612.0"
page_height="792.0"></component><component x="59.39" y="483.54" width="240.32"
height="192.1" page="3" page_width="612.0" page_height="792.0"></component><component
x="313.09" y="483.56" width="239.15" height="192.02" page="3" page_width="612.0"
page_height="792.0"></component><component x="62.22" y="52.88" width="239.48"
height="622.75" page="4" page_width="612.0"
page_height="792.0"></component></section>
  <section line_height="8.37" font="JMCDNP+Arial-BoldMT" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.11" name_ratio="0.30303030303030304" word_count="66"
lateness="0.5714285714285714" reference_score="6.66">Fig. 2. Representative fMRI
activation in the premotor cortex (PMC) associ ated wi th di scri mi nati ng voi cel
ess stop consonants in single syllables masked by white noise i n two representati ve
parti ci pants. Regi ons sel ected for stimulation are shown in bright colors.
Arrowheads [33] with permission). indicate the location of the central sulcus
(adapted from Meister et al.<component x="315.92" y="332.5" width="237.85"
height="76.19" page="4" page_width="612.0" page_height="792.0"></component></section>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.05"
year_ratio="0.0" cap_ratio="0.03" name_ratio="0.208" word_count="500"
lateness="0.7142857142857143" reference_score="6.19">production. Children born with
hearing loss can learn to speak i f they gai n enough posi ti ve somatosensory
feedback, even though the l earni ng process i s much [39] . Also, children with
severe harder than in healthy children dysarthria are unable to produce meaningful
sentences, [40] . but they can accurately understand spoken content Furthermore,
infants usually learn to understand speech first and then begin to learn how to
produce their own [ 41,42] . These st udi es i ndi cat e t hat di ssoci at i ons
words bet ween speech per cept i on and speech pr oduct i on occur duri ng devel
opment. As speech percepti on and speech production do not appear at the same time
during development, motor cortical areas may not be as important for speech
perception as the Motor Theory proposes. As revi ewed above, some fMRI and TMS studi
es support the view that motor cortical areas are important in speech perception,
while clinical and developmental studi es have shown si gni fi cant di ssoci ati ons
between speech perception and speech production. Also note that some fMRI studies did
not reveal an increased activation in motor cortical regions during speech perception
and [19,43,44] . comprehension The different results in the studies described above
may be due t o di ff er ent t ask demands. The Hi ckok and Poeppel study showed that
when the task load is hi gh, requi ri ng both speech i denti fi cati on and speech
categorization, the activated frontal region extends to the [17] . Also, when speech
signals are distorted, premotor cortex [45,46] . Interestingly, the motor cortex is
markedly activated [31,47] , and non-verbal si gnal s can acti vate motor areas there
is no difference in activation magnitude in the motor cortex between perceiving
speech and perceiving non[31] . Some studies have further shown that verbal sounds
blurred speech causes even stronger activation in the [45] and bilateral premotor
cortex, compared to clear speech perceiving a foreign language causes larger
activation in [25] . Also, lowthe motor cortex than the native language frequency
words induce higher activation in the motor [48] . Thus, facing unfamiliar cortex
than high-frequency words stimuli (such as distorted speech, a foreign language, or
low-frequency words), the motor cortex may play a role in facilitating the
association with the auditory system to improve speech perception. More
interestingly, in a mixed vi sual and audi tory task, weaker vi sual sti mul i evoke
stronger activation in the motor cortex than clear pictures [49] , suggesting that a
heavy-load task, such of speakers as analyzing distorted auditory or visual signals,
requires involvement of the motor cortex. These studies suggest that whether the
motor system is involved in speech perception is task-load dependent. In future, this
assumption will be tested to confi rm whether the dissociations between speech
perception and speech production under either clinical or developmental conditions
are task-load related.<component x="315.92" y="52.43" width="239.2" height="248.07"
page="4" page_width="612.0" page_height="792.0"></component><component x="59.38"
y="189.56" width="239.35" height="486.07" page="5" page_width="612.0"
page_height="792.0"></component></section>
  <section line_height="11.16" font="JMCDNP+Arial-BoldMT" letter_ratio="0.08"
year_ratio="0.0" cap_ratio="0.29" name_ratio="0.07142857142857142" word_count="14"
lateness="0.7142857142857143" reference_score="12.43">Speech Per cept i on under "
Cockt ai l Par t y" Conditions<component x="59.39" y="142.35" width="236.08"
height="29.16" page="5" page_width="612.0" page_height="792.0"></component></section>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.04"
year_ratio="0.0" cap_ratio="0.01" name_ratio="0.2033096926713948" word_count="423"
lateness="0.7142857142857143" reference_score="5.57">Speech perception is not just
for hearing speech sounds, but more essentially, for recognizing and understanding
speech signals, requiring that multisensory modalities interact. In fact, speech
understanding and speech hearing [40] . do not share the same brain network,
including the motor areas In a noisy environment (like a cocktail party), although
there are many acoustic sources from various directions, listeners are still able to
identify and follow target speech sounds i n t hi s hi gh per cept ual - l oad si t
uat i on. How can l i steners separate vari ous speakers' si gnal s and understand
target sentences? Although this "cocktail party" [50] has not been fully solved,
problem advanced by Cherry several lines of evidence suggest that the motor system
plays a role in solving this problem when the perceptual load is high. First,
observing a speaker's articulator movements can induce better understanding of
speech. Listeners perceive speech in noise-masking or speech-masking environments
more accurately when they can see speaker's articulatory [7,9] . In addition, organ
movement than when they cannot signals from the motor system help a listener to track
[51,52] . It has been suggested a speaker talking over time that one of the functions
of motor activation is tracking the talker 's speed and rhythm over time, and
provides the timing signals to the auditory cortex. Particularly in a conversation,
the monitoring role of the motor system in interacting with the auditory system over
time can induce [53] . fl uent conversation Under "cocktail-party" conditions,
listeners are able to take advantage of certain perceptual cues to facilitate t hei r
sel ect i ve at t ent i on t o t arget speech. Sel ect i ve attention allocates more
cognitive resources to the motor representation of speech so that a listener can
capture a speaker's intention and improve speech recognition. Under noise-masking
conditions, selective attention affects both active and passive listening. As Alho et
al. have reported, attention modulates the magnitude of activation of the left
premotor cortex, which infl uences the performance of [10] . phonetic categorization
In patients with schizophrenia, both speech-perception deficits and increased
vulnerability to masking stimuli generally occur. More specifically, speech
recognition in both fi rst-episode and chronic patients with schizophrenia is more
vulnerable to masking stimuli, particularly speech[54] . Thus, whether masking
stimuli, than in healthy people functional impairments of motor cortical regions
contribute to the enhanced vulnerability to speech-masking stimuli in patients with
schizophrenia will be an important research issue in the future.<component x="59.39"
y="49.73" width="239.17" height="80.06" page="5" page_width="612.0"
page_height="792.0"></component><component x="313.08" y="50.68" width="239.17"
height="624.95" page="5" page_width="612.0"
page_height="792.0"></component></section>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.02"
year_ratio="0.0" cap_ratio="0.0" name_ratio="0.2916666666666667" word_count="96"
lateness="0.8571428571428571" reference_score="5.44">Thi s r evi ew summar i zes t he
st udi es showi ng t hat interactions between the auditory system and the motor
system are related to speech perception. The anatomical and functional connections
between the auditory and motor systems are important for improving speech
recognition, particularly under diffi cult listening conditions (such as the
cocktail-party environment). With the involvement of the motor system, the listener
can better identify the speaker's intention and follow the target stream. Thus,
investigation of the auditory-motor association in speech perception is important for
solving the "cocktail party" problem.<component x="62.22" y="496.93" width="239.18"
height="155.03" page="6" page_width="612.0"
page_height="792.0"></component></section>
  <section line_height="8.93" font="JMCDMN+ArialMT" letter_ratio="0.33"
year_ratio="0.03" cap_ratio="0.51" name_ratio="0.2972972972972973" word_count="37"
lateness="0.8571428571428571" reference_score="23.37">Thi s revi ew was supported by
the Nati onal Basi c Research Development Program of China (2009CB320901,
2011CB707805, 2013CB329304), the National Natural Science Foundation of China
(31170985, 91120001, 61121002), and "985" project grants from Peking
University.<component x="62.22" y="396.48" width="238.88" height="60.93" page="6"
page_width="612.0" page_height="792.0"></component></section>
  <section line_height="8.93" font="JMCDMN+ArialMT" letter_ratio="0.23"
year_ratio="0.0" cap_ratio="0.38" name_ratio="0.1857627118644068" word_count="1475"
lateness="1.0" reference_score="20.14">[1] Liberman AM, Delattre P, Cooper FS. The
role of selected stimulus-variables in the perception of the unvoiced stop -
consonants. Am J Psychol 1952, 65: 497 516. [2] Liberman AM, Cooper FS, Shankweiler
DP, Studdert KM. - Perception of the speech code. Psychol Rev 1967, 74: 431 461. [3]
Liberman AM. Speech: A Special Code. Cambridge, MA: The MIT Press 1996. [4] Kent RD,
Mi ni f i e FD. Coart i cul at i on i n recent speech - production models. J Phon
1977, 5: 115 133. [5] Liberman AM, Mattingly IG. The motor theory of speech -
perception revised. Cognition 1985, 21: 1 36. [6] McGurk H, MacDonald J. Hearing lips
and seeing voices. - Nature 1976, 264: 746 748. [7] Sumby WH, Pol l ack I . Vi sual
cont r i but i on t o speech intelligibility in noise. J Acoust Soc Am 1954, 26: 212.
[8] Rudmann DS, McCarley JS, Kramer AF. Bimodal displays i mprove speech comprehensi
on i n envi ronment s wi t h - multiple speakers. Hum Fac Erg Soc P 2003, 45: 329
336. [9] Wu C, Cao S, Wu X, Li L. Tempor al l y pr e-pr esent ed lipreading cues
release speech from informational masking. J - Acoust Soc Am 2013, 133: 281 285. [10]
Al ho J, Sat o M, Sams M, Schwar t z JL, Ti i t i nen H, J&#xE4;&#xE4;skel&#xE4;inen
IP. Enhanced early-latency electromagnetic act i vi t y i n t he l ef t premot or
cort ex i s associ at ed wi t h successful phonetic categorization. Neuroimage 2012,
60: - 1937 1946. [11] Callan D, Callan A, Gamez M, Sato MA, Kawato M. Premotor cortex
mediates perceptual performance. Neuroimage 2010, - 51: 844 858. [12] Schrei ner CE,
Wi ner JA. Audi t ory cort ex mapmaki ng: - principles, projections, and plasticity.
Neuron 2007, 56: 356 365. [13] Recanzone GH, Sutter ML. The biological basis of
audition. - Annu Rev Psychol 2008, 59: 119 142. [14] Belin P, Zatorre RJ. Adaptation
to speaker's voice in right - anterior temporal lobe. Neuroreport 2003, 14: 2105
2109. [15] Scott SK, Blank CC, Rosen S, Wise RJ. Identification of a pathway for
intelligible speech in the left temporal lobe. Brain - 2000, 123: 2400 2406. [16]
Hickok G, Poeppel D. Towards a functional neuroanatomy of - speech perception. Trends
Cogn Sci 2000, 4: 131 138. [17] Hickok G, Poeppel D. The cortical organization of
speech - processing. Nat Neurosci 2007, 8: 393 402. [18] Baddeley A, Lewis V, Vallar
G. Exploring the articulatory loop. - Q J Exp Psychol 1984, 36: 233 252. [19] Wi se
RJ, Scot t SK, Bl ank SC, Mummer y CJ, Mur phy K, Warburt on EA. Separat e neural
subsyst ems wi t hi n - Wernicke's area. Brain 2001, 124: 83 95. [20] Andersen RA,
Buneo CA. Intenti onal maps i n posteri or - parietal cortex. Annu Rev Neurosci 2002,
25: 189 220. [21] Wolpert DM, Doya K, Kawato M. A unifying computational framework
for motor control and social interaction. Philos - Trans R Soc Lond B Biol Sci 2003,
358: 593 602. [22] Adank P, Devlin JT. On-line plasticity in spoken sentence
comprehensi on: Adapti ng to ti me-compressed speech. Neuroimage 2010, 49: 1124. [23]
Londei A, D'Ausi l i o A, Basso D, Sesti eri C, Gratta CD, Romani GL, et al.
Sensory-motor brain network connectivity - for speech comprehension. Hum Brain Mapp
2010, 31: 567 580. [24] Wi l son SM. Li steni ng to speech acti vates motor areas -
involved in speech production. Nat Neurosci 2004, 7: 701 702. [25] Wilson SM,
Iacoboni M. Neural responses to non-native phonemes var yi ng i n pr oduci bi l i t
y: evi dence f or t he sensorimotor nature of speech perception. Neuroimage - 2006,
33: 316 325. [26] Fadiga L, Craighero L, Buccino G, Rizzolatti G. Speech listening
specifically modulates the excitability of tongue - muscles: a TMS study. Eur J
Neurosci 2002, 15: 399 402. [27] Pulverm&#xFC;ller F, Huss M, Kherif F, del Prado
Martin FM, Hauk O, Shtyrov Y. Motor cortex maps articulatory features of - speech
sounds. Proc Natl Acad Sci U S A 2006, 103: 7865 7870. [28] Bever TG, Poeppel D.
Analysis by synthesis: a (re-) emerging program of research for language and vision.
Biolinguistics - 2010, 4: 174 200. [29] Cal l an DE, Jones JA, Cal l an AM,
Akahane-Yamada R. Phonetic perceptual identification by native-and secondlanguage
speakers differentially activates brain regions i nvol ved wi t h acoust i c phonet i
c processi ng and t hose i nvol ved wi t h art i cul at ory-audi t ory/orosensory i
nt ernal - models. Neuroimage 2004, 22: 1182 1194. [30] Hi ckok G, Houde J, Rong F.
Sensori mot or i nt egrat i on i n speech processi ng: computati onal basi s and
neural - organization. Neuron 2011, 69: 407 422. [31] Watkins KE, Strafella AP, Paus
T. Seeing and hearing speech excites the motor system involved in speech production.
- Neuropsychologia 2003, 41: 989 994. [32] D'Ausilio A, Pulverm&#xFC;ller F, Salmas
P, Bufalari I, Begliomini C, Fadiga L. The motor somatotopy of speech perception.
Curr - Biol 2009, 19: 381 385. [33] Meister IG, Wilson SM, Deblieck C, Wu AD,
Iacoboni M. The essential role of premotor cortex in speech perception. Curr - Biol
2007, 17: 1692 1696. [34] Watkins K, Paus T. Modulation of motor excitability during
speech perception: the role of Broca's area. J Cogn Neurosci - 2004, 16: 978 987.
[35] Mohr JP, Pessin MS, Finkelstein S, Funkenstein HH, Duncan GW, Davi s KR. Broca
aphasi a Pathol ogi c and cl i ni cal . - Neurology 1978, 28: 311 311. [36] Crinion
JT, Warburton EA, Lambon-Ralph MA, Howard D, Wise RJ. Listening to narrative speech
after aphasic stroke: the role of the left anterior temporal lobe. Cereb Cortex 2006,
16: 1116 -1125. [37] Bogen JE, Bogen GM. Wernick's region-Where is it? Ann NY - Acad
Sci, 1976, 280: 834 843. [38] Bak er E, Bl ums t ei n SE, Goodgl as s H. I nt er ac t
i on between phonol ogi cal and semanti c factors i n audi tory - comprehension.
Neuropsychologia 1981, 19: 1 15. [39] Bishop D, Mogford-Bevan K. Language Development
in Exceptional Circumstances. Psychology Press 1993. [40] Bishop CW, Miller LM. A
multisensory cortical network for understanding speech in noise. J Cogn Neurosci
2009, 21: - 1790 1804. [41] Werker JF, Yeung HH. Infant speech perception bootstraps
- word learning. Trends Cogn Sci 2005, 9: 519 527. [42] Tsao FM, Liu HM, Kuhl PK.
Speech perception in infancy predicts language development in the second year of
life: a - longitudinal study. Child Dev 2004, 75: 1067 1084. [43] Basso A, Casati G,
Vignolo LA. Phonemic identification defect in aphasia. Cortex 1977, 13: 85. [44]
Scott SK, Rosen S, Lang H, Wise RJ. Neural correlates of intelligibility in speech
investigated with noise vocoded speech-a positron emission tomography study. J Acoust
Soc Am 2006, 120: 1075. [45] Davis MH, Johnsrude IS. Hierarchical processing in
spoken - language comprehension. J Neurosci 2003, 23: 3423 3431. [46] Uppenkamp S,
Johnsrude IS, Norris D, Marslen-Wilson W, Patterson RD. Locating the initial stages
of speech? Sound processing in human temporal cortex. Neuroimage 2006, 31: - 1284
1296. [47] Warren JE, Sauter DA, Ei sner F, Wi l and J, Dresner M, Wise RJ, et al.
Positive emotions preferentially engage an - auditory-motor "mirror" system. J
Neurosci 2006, 26: 13067 13075. [48] Roy AC, Cr ai gher o L, Fabbr i - Des t r o M,
Fadi ga L. Phonological and lexical motor facilitation during speech listening: A
transcranial magnetic stimulation study. J Physiol - Paris 2008, 102: 101 105. [49]
Fridriksson J, Moss J, Davis B, Baylis GC, Bonilha L, Rorden C. Motor speech
perception modulates the cortical language - areas. Neuroimage 2008, 41: 605 613.
[50] Cherry EC. Some experiments on the recognition of speech, with one and with two
ears. J Acoust Soc Am 1953, 25: 975. [51] McFarl and DH. Respi rat ory markers of
conversat i onal interaction. J Speech Lang Hear Res 2001, 44: 128. [52] Pickering
MJ, Garrod S. Do people use language production to make predictions during
comprehension? Trends Cogn Sci - 2007, 11: 105 110. [53] Scott SK, McGettigan C,
Eisner F. A little more conversation, a little less action-candidate roles for the
motor cortex in - speech perception. Nat Rev Neurosci 2009, 10: 295 302. [54] Wu C,
Cao S, Zhou F, Wang C, Wu X, Li L. Masking of - speech in people with fi rst-episode
schizophrenia and people with chronic schizophrenia. Schizophr Res 2012a, 134: 33
41.<component x="62.2" y="54.05" width="238.93" height="271.35" page="6"
page_width="612.0" page_height="792.0"></component><component x="315.85" y="54.19"
width="238.97" height="621.48" page="6" page_width="612.0"
page_height="792.0"></component><component x="59.38" y="141.82" width="239.15"
height="533.77" page="7" page_width="612.0"
page_height="792.0"></component><component x="313.08" y="141.71" width="238.95"
height="534.04" page="7" page_width="612.0"
page_height="792.0"></component></section>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.02"
year_ratio="0.0" cap_ratio="0.0" name_ratio="0.2564102564102564" word_count="117"
lateness="0.14285714285714285" reference_score="0.29">How listeners process the
acoustic signals of speech is a hot question. Traditionally, studies of this question
have mainly focused on the functions of the auditory system. However, speech
processing is not the pure and simple analysis of speech sound signals, but a quite
complicated integrated process involving multisensory modalities and even the motor
system. In this review, we focus on the interaction between the auditory system and
the motor system in speech perception and emphasize that the motor processing
component plays an essential role: activation of the perceptual-motor loop enables
listeners to both track the speaker over time and form the intention to speak,
especially under adverse listening conditions, such as a noisy and reverberating
environment.<component x="59.39" y="114.33" width="239.17" height="192.1" page="1"
page_width="612.0" page_height="792.0"></component></section>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.04"
year_ratio="0.0" cap_ratio="0.02" name_ratio="0.20920245398773007" word_count="1630"
lateness="0.5714285714285714" reference_score="4.76">in a reading-machine study. In
their experiments, although bl i nd peopl e coul d recogni ze i ndependent l i ngui
st i c units, they could not perceive alphabetic sequences and understand synthesized
speech, because the linguistic units [3] they perceived tended to merge into a blur .
This problem related to speech perception is called coarticulation, in which speech
acoustic signals are highly context-sensitive; a single phoneme can be influenced by
its surrounding [2] phonemes . However, normal listeners are able to conquer [4]
coarticulation and perceive the original phonemes well . Based on the results,
Liberman and colleagues assumed that what we really perceive when hearing speech
signals is not only sound waves, but also body "gestures" that reflect the speaker's
intention. Liberman proposed three [1] hypotheses in both a weak and a strong version
of the [5] Motor Theory . (1) The object of speech perception is the "gesture"; (2)
speech processing is special and requires a specific phonetic module; and (3)
activation of the motor cortex is involved in speech perception. When Liberman
advanced the Motor Theory, he asked a critical question, "when articulation and sound
wave go their separate ways, which way does perception go?". The answer he provided
was that perception goes with [1] . In more detail, the theory suggests that the
articulation speech sound wave that we perceive carries the speaker's information
indirectly, and there is a direct way to transmit i nformati on, that i s through the
"gesture" beari ng the speaker's intention. In other words, perceiving the "gesture"
is just perceiving the actual movement of the speaker's vocal tract, including motion
of the larynx, tongue, and [1] . Our understanding of this theory is that although
lips the listener may not be aware of tracking movement of the vocal tract, he/she
automatically uses this motor cue to recognize the speaker's intention, just as in
imitative behavior. When a speaker talks, the listener tries to follow his speech
style in mind and make a prediction before the speaker says the next word. Thus, the
speaker and the listener must converge on the same "linguistic currency", the
"gesture", to communicate. It is well known that "gesture" information can affect
speech perception in different ways, such as the McGurk effect. When the listener
sees the speaker producing t he syl l abl e ( / ga/) whi l e l i st eni ng t o anot
her syl l abl e ( / ba/), the mouth movement may mislead the listener into [6] . This
visuomotor cue hearing a different syllable (/da/) strongly influences what we
actually hear. Also, another study focused on the role of articulatory organ movement
[7] . Listeners perceive speech more in a noisy environment accurately when they can
see the speaker's articulatory organ movement than when they cannot. Al so, under
adverse listening conditions, lip-reading associated with the target sentence can act
as a cue to improve listener [ 8,9] . Thus, percei vi ng " gest ure" recogni t i on
of speech signals provides visuomotor cues, which help listeners take advantage of
the speaker's motor actions during speech in an adverse noisy environment and
facilitate the perceptual performance. In other words, listeners actively, rather
than passively, receive speech information. Supporting this view, Alho et al.
reported that stronger activation in the left premotor cortex is associated with
better identifi cation of syllables that are embedded in noise, and the cortical
activation is quite different between active and passive [10] . Also, Calla et al.
reported stronger activity in listening [11] . However, it is still not correct
trials over incorrect trials within both the ventral premotor cortex and Broca's area
clear whether the enhanced activity of the cortical areas is specifi c to speech
perceptual performance or just refl ects an increase in general processing load. To
confi rm the involvement of the motor system in speech perception, evidence of both
anatomical and functional links between the motor and auditory systems is needed. I
ndeed, some model s emphasi ze t he audi t ory-mot or link in speech perception. For
example, the dual-stream processing model suggests that there are two pathways i n
audi t i on: one i s t he vent ral pat hway down t o t he temporal lobe regulating
"what" in acoustic information, and the other is the dorsal pathway from primary
sensory areas up to the posterior cortex regulating "how" speech [12,13] . It is also
known that the ventral production takes place pathway is involved in analyzing
phonetic characters, [14,15] , and the acoustic features, and speech intelligibility
dorsal pathway is associated with sensorimotor mapping [16,17] , speech between
auditory and motor representations [14,18] [19] , and silent articulatory organ
movement . production Although this dual-stream model proposes that each of the
pathways plays a specifi c role in speech perception, how the streams interact with
each other is still not clear. The other model, the forward-inverse model, proposes
that the motor cortical regions predict the consequences of mot or commands and revi
se t he si gnal s wi t h t he [20,21] . In more detail, before motor changing
environment commands reach the effectors, the forward-inverse model produces
predicted sensory consequences of the motor commands, and then compares the predicted
results with the real sensory information. This comparison provides more i nformati
on for the central system to produce a more appropri ate performance. Wi th ti me del
ays and interruptions from the surroundings, the motor commands need to be up-dated
from time to time in order to produce the desi red outcome. Thus, when a speech si
gnal i s distorted by environmental noise and/or time delays, the motor
representation of the previous signals modifies the current auditory representation
through inverse mapping. Due to the role of motor representation in revising
distorted signals, listeners can recognize the speaker's intention and predict the
outcome of motor commands before making responses. In other words, anticipation of a
motor signal can be combined with both signal characteristics and the speaker's
articulatory information, producing a more desirable response. Based on the basic
principles of the dual-stream processing and forward-inverse models, we propose that
further-developed models should emphasize how the auditory-motor interaction is
modulated by both processing load (due to complex inputs) and prediction/ estimation
(due to task goals and feedback) (Fig. 1). So far, co-activations between auditory
and motor regions in speech perception have been clearly demonstrated. When exposed
to novel speech distortions, such as timecompressed sentences, listeners can rapidly
distinguish distorted sentences from normal-speed sentences, with increased
activation associations between the auditory [22] . Moreover, cortices and the left
ventral premotor cortex compared to listening to pseudo-words and reversedwords,
listening to normal words induces broad activation connectivity in the auditory-motor
network, which may [23] . Further be useful for facilitating semantic processing
investigation is needed to verify whether this enhanced dynamic auditory-motor
network promotes the transition from a sound stream into a series of meaningful
motorbased units and results in speech comprehension. I n addi t i on t o t he wel l
- known f act t hat speech production is tightly related to the motor cortex, some
[24-30] . For example, when listeners studies have shown that the motor cortex is
activated in speech perception tasks hear a lip-related phoneme [p] or a
tongue-related phoneme [26,27] , suggesting [t], motor regions are activated
differentially that different speech stimuli activate motor cortical regions with
different patterns. In other words, listening to various verbal stimuli may cause
differential automatic activations of cortical regions involved in speech production.
Also, it has been suggested that the activation of the motor cortex may refl ect a
mediating role of the motor cortex in speech [28-30] . perception Moreover, studies
using either functional magnetic r esonance i magi ng ( f MRI ) or t r anscr ani al
magnet i c stimulation (TMS) have confirmed the role of the motor cortex in speech
perception. For example, in a speech perception task, strong activation in the motor
cortex can be induced only when participants perceive the target [24,31] speech .
Some studies using TMS of the motor cortex have demonstrated that sti mul ati on of
speech-rel ated [32-34] regions affects speech perception . For example, using TMS to
suppress the left premotor cortex, which is activated both during speech production
and speech perception (Fig. 2), Meister et al. found that participants with a
suppressed premotor cortex were impaired in discriminating voiceless stop consonants
under white-noise masking conditions. Thus, they suggested that the premotor cortex
is essentially [33] involved in speech perception . However, the results of some
clinical studies appear not to support the view that there is an association between
i mpai rment of speech percept i on and i mpai rment of speech production. For
example, patients with expressive aphasia exhibit impairment of speech production but
not [35] speech perception or comprehension . Also, although pati ents wi th recepti
ve aphasi a exhi bi t i mpai rment of speech perception and comprehension, they can
speak [36,37] fl uently . The dissociations in expressive and receptive aphasi a
support another vi ew that speech percepti on and producti on are two di sti nct
processes. Moreover, patients with lesions in Broca's area perform well in both
word-comprehension and syllable-identification tests, but patients with temporal
lobule damage perform poorly in [38] these tests . These studies also negate the role
of motor regions in speech perception, but support the view that temporal regions
rather than motor areas are important in [16,17] speech perception . Research i n chi
l d devel opment has al so shown dissociations between speech perception and
speech<component x="313.08" y="52.54" width="239.43" height="277.55" page="1"
page_width="612.0" page_height="792.0"></component><component x="62.21" y="49.58"
width="239.5" height="626.05" page="2" page_width="612.0"
page_height="792.0"></component><component x="315.92" y="637.58" width="239.17"
height="38.05" page="2" page_width="612.0" page_height="792.0"></component><component
x="315.92" y="49.69" width="239.2" height="528.1" page="2" page_width="612.0"
page_height="792.0"></component><component x="59.39" y="483.54" width="240.32"
height="192.1" page="3" page_width="612.0" page_height="792.0"></component><component
x="313.09" y="483.56" width="239.15" height="192.02" page="3" page_width="612.0"
page_height="792.0"></component><component x="62.22" y="52.88" width="239.48"
height="622.75" page="4" page_width="612.0"
page_height="792.0"></component></section>
  <section line_height="8.37" font="JMCDNP+Arial-BoldMT" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.11" name_ratio="0.30303030303030304" word_count="66"
lateness="0.5714285714285714" reference_score="6.66">Fig. 2. Representative fMRI
activation in the premotor cortex (PMC) associ ated wi th di scri mi nati ng voi cel
ess stop consonants in single syllables masked by white noise i n two representati ve
parti ci pants. Regi ons sel ected for stimulation are shown in bright colors.
Arrowheads [33] with permission). indicate the location of the central sulcus
(adapted from Meister et al.<component x="315.92" y="332.5" width="237.85"
height="76.19" page="4" page_width="612.0" page_height="792.0"></component></section>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.05"
year_ratio="0.0" cap_ratio="0.03" name_ratio="0.208" word_count="500"
lateness="0.7142857142857143" reference_score="6.19">production. Children born with
hearing loss can learn to speak i f they gai n enough posi ti ve somatosensory
feedback, even though the l earni ng process i s much [39] . Also, children with
severe harder than in healthy children dysarthria are unable to produce meaningful
sentences, [40] . but they can accurately understand spoken content Furthermore,
infants usually learn to understand speech first and then begin to learn how to
produce their own [ 41,42] . These st udi es i ndi cat e t hat di ssoci at i ons
words bet ween speech per cept i on and speech pr oduct i on occur duri ng devel
opment. As speech percepti on and speech production do not appear at the same time
during development, motor cortical areas may not be as important for speech
perception as the Motor Theory proposes. As revi ewed above, some fMRI and TMS studi
es support the view that motor cortical areas are important in speech perception,
while clinical and developmental studi es have shown si gni fi cant di ssoci ati ons
between speech perception and speech production. Also note that some fMRI studies did
not reveal an increased activation in motor cortical regions during speech perception
and [19,43,44] . comprehension The different results in the studies described above
may be due t o di ff er ent t ask demands. The Hi ckok and Poeppel study showed that
when the task load is hi gh, requi ri ng both speech i denti fi cati on and speech
categorization, the activated frontal region extends to the [17] . Also, when speech
signals are distorted, premotor cortex [45,46] . Interestingly, the motor cortex is
markedly activated [31,47] , and non-verbal si gnal s can acti vate motor areas there
is no difference in activation magnitude in the motor cortex between perceiving
speech and perceiving non[31] . Some studies have further shown that verbal sounds
blurred speech causes even stronger activation in the [45] and bilateral premotor
cortex, compared to clear speech perceiving a foreign language causes larger
activation in [25] . Also, lowthe motor cortex than the native language frequency
words induce higher activation in the motor [48] . Thus, facing unfamiliar cortex
than high-frequency words stimuli (such as distorted speech, a foreign language, or
low-frequency words), the motor cortex may play a role in facilitating the
association with the auditory system to improve speech perception. More
interestingly, in a mixed vi sual and audi tory task, weaker vi sual sti mul i evoke
stronger activation in the motor cortex than clear pictures [49] , suggesting that a
heavy-load task, such of speakers as analyzing distorted auditory or visual signals,
requires involvement of the motor cortex. These studies suggest that whether the
motor system is involved in speech perception is task-load dependent. In future, this
assumption will be tested to confi rm whether the dissociations between speech
perception and speech production under either clinical or developmental conditions
are task-load related.<component x="315.92" y="52.43" width="239.2" height="248.07"
page="4" page_width="612.0" page_height="792.0"></component><component x="59.38"
y="189.56" width="239.35" height="486.07" page="5" page_width="612.0"
page_height="792.0"></component></section>
  <section line_height="11.16" font="JMCDNP+Arial-BoldMT" letter_ratio="0.08"
year_ratio="0.0" cap_ratio="0.29" name_ratio="0.07142857142857142" word_count="14"
lateness="0.7142857142857143" reference_score="12.43">Speech Per cept i on under "
Cockt ai l Par t y" Conditions<component x="59.39" y="142.35" width="236.08"
height="29.16" page="5" page_width="612.0" page_height="792.0"></component></section>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.04"
year_ratio="0.0" cap_ratio="0.01" name_ratio="0.2033096926713948" word_count="423"
lateness="0.7142857142857143" reference_score="5.57">Speech perception is not just
for hearing speech sounds, but more essentially, for recognizing and understanding
speech signals, requiring that multisensory modalities interact. In fact, speech
understanding and speech hearing [40] . do not share the same brain network,
including the motor areas In a noisy environment (like a cocktail party), although
there are many acoustic sources from various directions, listeners are still able to
identify and follow target speech sounds i n t hi s hi gh per cept ual - l oad si t
uat i on. How can l i steners separate vari ous speakers' si gnal s and understand
target sentences? Although this "cocktail party" [50] has not been fully solved,
problem advanced by Cherry several lines of evidence suggest that the motor system
plays a role in solving this problem when the perceptual load is high. First,
observing a speaker's articulator movements can induce better understanding of
speech. Listeners perceive speech in noise-masking or speech-masking environments
more accurately when they can see speaker's articulatory [7,9] . In addition, organ
movement than when they cannot signals from the motor system help a listener to track
[51,52] . It has been suggested a speaker talking over time that one of the functions
of motor activation is tracking the talker 's speed and rhythm over time, and
provides the timing signals to the auditory cortex. Particularly in a conversation,
the monitoring role of the motor system in interacting with the auditory system over
time can induce [53] . fl uent conversation Under "cocktail-party" conditions,
listeners are able to take advantage of certain perceptual cues to facilitate t hei r
sel ect i ve at t ent i on t o t arget speech. Sel ect i ve attention allocates more
cognitive resources to the motor representation of speech so that a listener can
capture a speaker's intention and improve speech recognition. Under noise-masking
conditions, selective attention affects both active and passive listening. As Alho et
al. have reported, attention modulates the magnitude of activation of the left
premotor cortex, which infl uences the performance of [10] . phonetic categorization
In patients with schizophrenia, both speech-perception deficits and increased
vulnerability to masking stimuli generally occur. More specifically, speech
recognition in both fi rst-episode and chronic patients with schizophrenia is more
vulnerable to masking stimuli, particularly speech[54] . Thus, whether masking
stimuli, than in healthy people functional impairments of motor cortical regions
contribute to the enhanced vulnerability to speech-masking stimuli in patients with
schizophrenia will be an important research issue in the future.<component x="59.39"
y="49.73" width="239.17" height="80.06" page="5" page_width="612.0"
page_height="792.0"></component><component x="313.08" y="50.68" width="239.17"
height="624.95" page="5" page_width="612.0"
page_height="792.0"></component></section>
  <section line_height="10.04" font="JMCDMN+ArialMT" letter_ratio="0.02"
year_ratio="0.0" cap_ratio="0.0" name_ratio="0.2916666666666667" word_count="96"
lateness="0.8571428571428571" reference_score="5.44">Thi s r evi ew summar i zes t he
st udi es showi ng t hat interactions between the auditory system and the motor
system are related to speech perception. The anatomical and functional connections
between the auditory and motor systems are important for improving speech
recognition, particularly under diffi cult listening conditions (such as the
cocktail-party environment). With the involvement of the motor system, the listener
can better identify the speaker's intention and follow the target stream. Thus,
investigation of the auditory-motor association in speech perception is important for
solving the "cocktail party" problem.<component x="62.22" y="496.93" width="239.18"
height="155.03" page="6" page_width="612.0"
page_height="792.0"></component></section>
  <section line_height="8.93" font="JMCDMN+ArialMT" letter_ratio="0.33"
year_ratio="0.03" cap_ratio="0.51" name_ratio="0.2972972972972973" word_count="37"
lateness="0.8571428571428571" reference_score="23.37">Thi s revi ew was supported by
the Nati onal Basi c Research Development Program of China (2009CB320901,
2011CB707805, 2013CB329304), the National Natural Science Foundation of China
(31170985, 91120001, 61121002), and "985" project grants from Peking
University.<component x="62.22" y="396.48" width="238.88" height="60.93" page="6"
page_width="612.0" page_height="792.0"></component></section>
  <section line_height="8.93" font="JMCDMN+ArialMT" letter_ratio="0.23"
year_ratio="0.0" cap_ratio="0.38" name_ratio="0.1857627118644068" word_count="1475"
lateness="1.0" reference_score="20.14">[1] Liberman AM, Delattre P, Cooper FS. The
role of selected stimulus-variables in the perception of the unvoiced stop -
consonants. Am J Psychol 1952, 65: 497 516. [2] Liberman AM, Cooper FS, Shankweiler
DP, Studdert KM. - Perception of the speech code. Psychol Rev 1967, 74: 431 461. [3]
Liberman AM. Speech: A Special Code. Cambridge, MA: The MIT Press 1996. [4] Kent RD,
Mi ni f i e FD. Coart i cul at i on i n recent speech - production models. J Phon
1977, 5: 115 133. [5] Liberman AM, Mattingly IG. The motor theory of speech -
perception revised. Cognition 1985, 21: 1 36. [6] McGurk H, MacDonald J. Hearing lips
and seeing voices. - Nature 1976, 264: 746 748. [7] Sumby WH, Pol l ack I . Vi sual
cont r i but i on t o speech intelligibility in noise. J Acoust Soc Am 1954, 26: 212.
[8] Rudmann DS, McCarley JS, Kramer AF. Bimodal displays i mprove speech comprehensi
on i n envi ronment s wi t h - multiple speakers. Hum Fac Erg Soc P 2003, 45: 329
336. [9] Wu C, Cao S, Wu X, Li L. Tempor al l y pr e-pr esent ed lipreading cues
release speech from informational masking. J - Acoust Soc Am 2013, 133: 281 285. [10]
Al ho J, Sat o M, Sams M, Schwar t z JL, Ti i t i nen H, J&#xE4;&#xE4;skel&#xE4;inen
IP. Enhanced early-latency electromagnetic act i vi t y i n t he l ef t premot or
cort ex i s associ at ed wi t h successful phonetic categorization. Neuroimage 2012,
60: - 1937 1946. [11] Callan D, Callan A, Gamez M, Sato MA, Kawato M. Premotor cortex
mediates perceptual performance. Neuroimage 2010, - 51: 844 858. [12] Schrei ner CE,
Wi ner JA. Audi t ory cort ex mapmaki ng: - principles, projections, and plasticity.
Neuron 2007, 56: 356 365. [13] Recanzone GH, Sutter ML. The biological basis of
audition. - Annu Rev Psychol 2008, 59: 119 142. [14] Belin P, Zatorre RJ. Adaptation
to speaker's voice in right - anterior temporal lobe. Neuroreport 2003, 14: 2105
2109. [15] Scott SK, Blank CC, Rosen S, Wise RJ. Identification of a pathway for
intelligible speech in the left temporal lobe. Brain - 2000, 123: 2400 2406. [16]
Hickok G, Poeppel D. Towards a functional neuroanatomy of - speech perception. Trends
Cogn Sci 2000, 4: 131 138. [17] Hickok G, Poeppel D. The cortical organization of
speech - processing. Nat Neurosci 2007, 8: 393 402. [18] Baddeley A, Lewis V, Vallar
G. Exploring the articulatory loop. - Q J Exp Psychol 1984, 36: 233 252. [19] Wi se
RJ, Scot t SK, Bl ank SC, Mummer y CJ, Mur phy K, Warburt on EA. Separat e neural
subsyst ems wi t hi n - Wernicke's area. Brain 2001, 124: 83 95. [20] Andersen RA,
Buneo CA. Intenti onal maps i n posteri or - parietal cortex. Annu Rev Neurosci 2002,
25: 189 220. [21] Wolpert DM, Doya K, Kawato M. A unifying computational framework
for motor control and social interaction. Philos - Trans R Soc Lond B Biol Sci 2003,
358: 593 602. [22] Adank P, Devlin JT. On-line plasticity in spoken sentence
comprehensi on: Adapti ng to ti me-compressed speech. Neuroimage 2010, 49: 1124. [23]
Londei A, D'Ausi l i o A, Basso D, Sesti eri C, Gratta CD, Romani GL, et al.
Sensory-motor brain network connectivity - for speech comprehension. Hum Brain Mapp
2010, 31: 567 580. [24] Wi l son SM. Li steni ng to speech acti vates motor areas -
involved in speech production. Nat Neurosci 2004, 7: 701 702. [25] Wilson SM,
Iacoboni M. Neural responses to non-native phonemes var yi ng i n pr oduci bi l i t
y: evi dence f or t he sensorimotor nature of speech perception. Neuroimage - 2006,
33: 316 325. [26] Fadiga L, Craighero L, Buccino G, Rizzolatti G. Speech listening
specifically modulates the excitability of tongue - muscles: a TMS study. Eur J
Neurosci 2002, 15: 399 402. [27] Pulverm&#xFC;ller F, Huss M, Kherif F, del Prado
Martin FM, Hauk O, Shtyrov Y. Motor cortex maps articulatory features of - speech
sounds. Proc Natl Acad Sci U S A 2006, 103: 7865 7870. [28] Bever TG, Poeppel D.
Analysis by synthesis: a (re-) emerging program of research for language and vision.
Biolinguistics - 2010, 4: 174 200. [29] Cal l an DE, Jones JA, Cal l an AM,
Akahane-Yamada R. Phonetic perceptual identification by native-and secondlanguage
speakers differentially activates brain regions i nvol ved wi t h acoust i c phonet i
c processi ng and t hose i nvol ved wi t h art i cul at ory-audi t ory/orosensory i
nt ernal - models. Neuroimage 2004, 22: 1182 1194. [30] Hi ckok G, Houde J, Rong F.
Sensori mot or i nt egrat i on i n speech processi ng: computati onal basi s and
neural - organization. Neuron 2011, 69: 407 422. [31] Watkins KE, Strafella AP, Paus
T. Seeing and hearing speech excites the motor system involved in speech production.
- Neuropsychologia 2003, 41: 989 994. [32] D'Ausilio A, Pulverm&#xFC;ller F, Salmas
P, Bufalari I, Begliomini C, Fadiga L. The motor somatotopy of speech perception.
Curr - Biol 2009, 19: 381 385. [33] Meister IG, Wilson SM, Deblieck C, Wu AD,
Iacoboni M. The essential role of premotor cortex in speech perception. Curr - Biol
2007, 17: 1692 1696. [34] Watkins K, Paus T. Modulation of motor excitability during
speech perception: the role of Broca's area. J Cogn Neurosci - 2004, 16: 978 987.
[35] Mohr JP, Pessin MS, Finkelstein S, Funkenstein HH, Duncan GW, Davi s KR. Broca
aphasi a Pathol ogi c and cl i ni cal . - Neurology 1978, 28: 311 311. [36] Crinion
JT, Warburton EA, Lambon-Ralph MA, Howard D, Wise RJ. Listening to narrative speech
after aphasic stroke: the role of the left anterior temporal lobe. Cereb Cortex 2006,
16: 1116 -1125. [37] Bogen JE, Bogen GM. Wernick's region-Where is it? Ann NY - Acad
Sci, 1976, 280: 834 843. [38] Bak er E, Bl ums t ei n SE, Goodgl as s H. I nt er ac t
i on between phonol ogi cal and semanti c factors i n audi tory - comprehension.
Neuropsychologia 1981, 19: 1 15. [39] Bishop D, Mogford-Bevan K. Language Development
in Exceptional Circumstances. Psychology Press 1993. [40] Bishop CW, Miller LM. A
multisensory cortical network for understanding speech in noise. J Cogn Neurosci
2009, 21: - 1790 1804. [41] Werker JF, Yeung HH. Infant speech perception bootstraps
- word learning. Trends Cogn Sci 2005, 9: 519 527. [42] Tsao FM, Liu HM, Kuhl PK.
Speech perception in infancy predicts language development in the second year of
life: a - longitudinal study. Child Dev 2004, 75: 1067 1084. [43] Basso A, Casati G,
Vignolo LA. Phonemic identification defect in aphasia. Cortex 1977, 13: 85. [44]
Scott SK, Rosen S, Lang H, Wise RJ. Neural correlates of intelligibility in speech
investigated with noise vocoded speech-a positron emission tomography study. J Acoust
Soc Am 2006, 120: 1075. [45] Davis MH, Johnsrude IS. Hierarchical processing in
spoken - language comprehension. J Neurosci 2003, 23: 3423 3431. [46] Uppenkamp S,
Johnsrude IS, Norris D, Marslen-Wilson W, Patterson RD. Locating the initial stages
of speech? Sound processing in human temporal cortex. Neuroimage 2006, 31: - 1284
1296. [47] Warren JE, Sauter DA, Ei sner F, Wi l and J, Dresner M, Wise RJ, et al.
Positive emotions preferentially engage an - auditory-motor "mirror" system. J
Neurosci 2006, 26: 13067 13075. [48] Roy AC, Cr ai gher o L, Fabbr i - Des t r o M,
Fadi ga L. Phonological and lexical motor facilitation during speech listening: A
transcranial magnetic stimulation study. J Physiol - Paris 2008, 102: 101 105. [49]
Fridriksson J, Moss J, Davis B, Baylis GC, Bonilha L, Rorden C. Motor speech
perception modulates the cortical language - areas. Neuroimage 2008, 41: 605 613.
[50] Cherry EC. Some experiments on the recognition of speech, with one and with two
ears. J Acoust Soc Am 1953, 25: 975. [51] McFarl and DH. Respi rat ory markers of
conversat i onal interaction. J Speech Lang Hear Res 2001, 44: 128. [52] Pickering
MJ, Garrod S. Do people use language production to make predictions during
comprehension? Trends Cogn Sci - 2007, 11: 105 110. [53] Scott SK, McGettigan C,
Eisner F. A little more conversation, a little less action-candidate roles for the
motor cortex in - speech perception. Nat Rev Neurosci 2009, 10: 295 302. [54] Wu C,
Cao S, Zhou F, Wang C, Wu X, Li L. Masking of - speech in people with fi rst-episode
schizophrenia and people with chronic schizophrenia. Schizophr Res 2012a, 134: 33
41.<component x="62.2" y="54.05" width="238.93" height="271.35" page="6"
page_width="612.0" page_height="792.0"></component><component x="315.85" y="54.19"
width="238.97" height="621.48" page="6" page_width="612.0"
page_height="792.0"></component><component x="59.38" y="141.82" width="239.15"
height="533.77" page="7" page_width="612.0"
page_height="792.0"></component><component x="313.08" y="141.71" width="238.95"
height="534.04" page="7" page_width="612.0"
page_height="792.0"></component></section>
  <reference>Thi s revi ew was supported by the Nati onal Basi c Research Development
Program of China (2009CB320901, 2011CB707805, 2013CB329304), the National Natural
Science Foundation of China (31170985, 91120001, 61121002), and "985" project grants
from Peking University.</reference>
  <reference order="1">Liberman AM, Delattre P, Cooper FS. The role of selected
stimulus-variables in the perception of the unvoiced stop - consonants. Am J Psychol
1952, 65: 497 516.</reference>
  <reference order="2">Liberman AM, Cooper FS, Shankweiler DP, Studdert KM. -
Perception of the speech code. Psychol Rev 1967, 74: 431 461.</reference>
  <reference order="3">Liberman AM. Speech: A Special Code. Cambridge, MA: The MIT
Press 1996.</reference>
  <reference order="4">Kent RD, Mi ni f i e FD. Coart i cul at i on i n recent speech
- production models. J Phon 1977, 5: 115 133.</reference>
  <reference order="5">Liberman AM, Mattingly IG. The motor theory of speech -
perception revised. Cognition 1985, 21: 1 36.</reference>
  <reference order="6">McGurk H, MacDonald J. Hearing lips and seeing voices. -
Nature 1976, 264: 746 748.</reference>
  <reference order="7">Sumby WH, Pol l ack I . Vi sual cont r i but i on t o speech
intelligibility in noise. J Acoust Soc Am 1954, 26: 212.</reference>
  <reference order="8">Rudmann DS, McCarley JS, Kramer AF. Bimodal displays i mprove
speech comprehensi on i n envi ronment s wi t h - multiple speakers. Hum Fac Erg Soc
P 2003, 45: 329 336.</reference>
  <reference order="9">Wu C, Cao S, Wu X, Li L. Tempor al l y pr e-pr esent ed
lipreading cues release speech from informational masking. J - Acoust Soc Am 2013,
133: 281 285.</reference>
  <reference order="10">Al ho J, Sat o M, Sams M, Schwar t z JL, Ti i t i nen H,
J&#xE4;&#xE4;skel&#xE4;inen IP. Enhanced early-latency electromagnetic act i vi t y i
n t he l ef t premot or cort ex i s associ at ed wi t h successful phonetic
categorization. Neuroimage 2012, 60: - 1937 1946.</reference>
  <reference order="11">Callan D, Callan A, Gamez M, Sato MA, Kawato M. Premotor
cortex mediates perceptual performance. Neuroimage 2010, - 51: 844 858.</reference>
  <reference order="12">Schrei ner CE, Wi ner JA. Audi t ory cort ex mapmaki ng: -
principles, projections, and plasticity. Neuron 2007, 56: 356 365.</reference>
  <reference order="13">Recanzone GH, Sutter ML. The biological basis of audition. -
Annu Rev Psychol 2008, 59: 119 142.</reference>
  <reference order="14">Belin P, Zatorre RJ. Adaptation to speaker's voice in right -
anterior temporal lobe. Neuroreport 2003, 14: 2105 2109.</reference>
  <reference order="15">Scott SK, Blank CC, Rosen S, Wise RJ. Identification of a
pathway for intelligible speech in the left temporal lobe. Brain - 2000, 123: 2400
2406.</reference>
  <reference order="16">Hickok G, Poeppel D. Towards a functional neuroanatomy of -
speech perception. Trends Cogn Sci 2000, 4: 131 138.</reference>
  <reference order="17">Hickok G, Poeppel D. The cortical organization of speech -
processing. Nat Neurosci 2007, 8: 393 402.</reference>
  <reference order="18">Baddeley A, Lewis V, Vallar G. Exploring the articulatory
loop. - Q J Exp Psychol 1984, 36: 233 252.</reference>
  <reference order="19">Wi se RJ, Scot t SK, Bl ank SC, Mummer y CJ, Mur phy K,
Warburt on EA. Separat e neural subsyst ems wi t hi n - Wernicke's area. Brain 2001,
124: 83 95.</reference>
  <reference order="20">Andersen RA, Buneo CA. Intenti onal maps i n posteri or -
parietal cortex. Annu Rev Neurosci 2002, 25: 189 220.</reference>
  <reference order="21">Wolpert DM, Doya K, Kawato M. A unifying computational
framework for motor control and social interaction. Philos - Trans R Soc Lond B Biol
Sci 2003, 358: 593 602.</reference>
  <reference order="22">Adank P, Devlin JT. On-line plasticity in spoken sentence
comprehensi on: Adapti ng to ti me-compressed speech. Neuroimage 2010, 49:
1124.</reference>
  <reference order="23">Londei A, D'Ausi l i o A, Basso D, Sesti eri C, Gratta CD,
Romani GL, et al. Sensory-motor brain network connectivity - for speech
comprehension. Hum Brain Mapp 2010, 31: 567 580.</reference>
  <reference order="24">Wi l son SM. Li steni ng to speech acti vates motor areas -
involved in speech production. Nat Neurosci 2004, 7: 701 702.</reference>
  <reference order="25">Wilson SM, Iacoboni M. Neural responses to non-native
phonemes var yi ng i n pr oduci bi l i t y: evi dence f or t he sensorimotor nature
of speech perception. Neuroimage - 2006, 33: 316 325.</reference>
  <reference order="26">Fadiga L, Craighero L, Buccino G, Rizzolatti G. Speech
listening specifically modulates the excitability of tongue - muscles: a TMS study.
Eur J Neurosci 2002, 15: 399 402.</reference>
  <reference order="27">Pulverm&#xFC;ller F, Huss M, Kherif F, del Prado Martin FM,
Hauk O, Shtyrov Y. Motor cortex maps articulatory features of - speech sounds. Proc
Natl Acad Sci U S A 2006, 103: 7865 7870.</reference>
  <reference order="28">Bever TG, Poeppel D. Analysis by synthesis: a (re-) emerging
program of research for language and vision. Biolinguistics - 2010, 4: 174
200.</reference>
  <reference order="29">Cal l an DE, Jones JA, Cal l an AM, Akahane-Yamada R.
Phonetic perceptual identification by native-and secondlanguage speakers
differentially activates brain regions i nvol ved wi t h acoust i c phonet i c
processi ng and t hose i nvol ved wi t h art i cul at ory-audi t ory/orosensory i nt
ernal - models. Neuroimage 2004, 22: 1182 1194.</reference>
  <reference order="30">Hi ckok G, Houde J, Rong F. Sensori mot or i nt egrat i on i
n speech processi ng: computati onal basi s and neural - organization. Neuron 2011,
69: 407 422.</reference>
  <reference order="31">Watkins KE, Strafella AP, Paus T. Seeing and hearing speech
excites the motor system involved in speech production. - Neuropsychologia 2003, 41:
989 994.</reference>
  <reference order="32">D'Ausilio A, Pulverm&#xFC;ller F, Salmas P, Bufalari I,
Begliomini C, Fadiga L. The motor somatotopy of speech perception. Curr - Biol 2009,
19: 381 385.</reference>
  <reference order="33">Meister IG, Wilson SM, Deblieck C, Wu AD, Iacoboni M. The
essential role of premotor cortex in speech perception. Curr - Biol 2007, 17: 1692
1696.</reference>
  <reference order="34">Watkins K, Paus T. Modulation of motor excitability during
speech perception: the role of Broca's area. J Cogn Neurosci - 2004, 16: 978
987.</reference>
  <reference order="35">Mohr JP, Pessin MS, Finkelstein S, Funkenstein HH, Duncan GW,
Davi s KR. Broca aphasi a Pathol ogi c and cl i ni cal . - Neurology 1978, 28: 311
311.</reference>
  <reference order="36">Crinion JT, Warburton EA, Lambon-Ralph MA, Howard D, Wise RJ.
Listening to narrative speech after aphasic stroke: the role of the left anterior
temporal lobe. Cereb Cortex 2006, 16: 1116 -1125.</reference>
  <reference order="37">Bogen JE, Bogen GM. Wernick's region-Where is it? Ann NY -
Acad Sci, 1976, 280: 834 843.</reference>
  <reference order="38">Bak er E, Bl ums t ei n SE, Goodgl as s H. I nt er ac t i on
between phonol ogi cal and semanti c factors i n audi tory - comprehension.
Neuropsychologia 1981, 19: 1 15.</reference>
  <reference order="39">Bishop D, Mogford-Bevan K. Language Development in
Exceptional Circumstances. Psychology Press 1993.</reference>
  <reference order="40">Bishop CW, Miller LM. A multisensory cortical network for
understanding speech in noise. J Cogn Neurosci 2009, 21: - 1790 1804.</reference>
  <reference order="41">Werker JF, Yeung HH. Infant speech perception bootstraps -
word learning. Trends Cogn Sci 2005, 9: 519 527.</reference>
  <reference order="42">Tsao FM, Liu HM, Kuhl PK. Speech perception in infancy
predicts language development in the second year of life: a - longitudinal study.
Child Dev 2004, 75: 1067 1084.</reference>
  <reference order="43">Basso A, Casati G, Vignolo LA. Phonemic identification defect
in aphasia. Cortex 1977, 13: 85.</reference>
  <reference order="44">Scott SK, Rosen S, Lang H, Wise RJ. Neural correlates of
intelligibility in speech investigated with noise vocoded speech-a positron emission
tomography study. J Acoust Soc Am 2006, 120: 1075.</reference>
  <reference order="45">Davis MH, Johnsrude IS. Hierarchical processing in spoken -
language comprehension. J Neurosci 2003, 23: 3423 3431.</reference>
  <reference order="46">Uppenkamp S, Johnsrude IS, Norris D, Marslen-Wilson W,
Patterson RD. Locating the initial stages of speech? Sound processing in human
temporal cortex. Neuroimage 2006, 31: - 1284 1296.</reference>
  <reference order="47">Warren JE, Sauter DA, Ei sner F, Wi l and J, Dresner M, Wise
RJ, et al. Positive emotions preferentially engage an - auditory-motor "mirror"
system. J Neurosci 2006, 26: 13067 13075.</reference>
  <reference order="48">Roy AC, Cr ai gher o L, Fabbr i - Des t r o M, Fadi ga L.
Phonological and lexical motor facilitation during speech listening: A transcranial
magnetic stimulation study. J Physiol - Paris 2008, 102: 101 105.</reference>
  <reference order="49">Fridriksson J, Moss J, Davis B, Baylis GC, Bonilha L, Rorden
C. Motor speech perception modulates the cortical language - areas. Neuroimage 2008,
41: 605 613.</reference>
  <reference order="50">Cherry EC. Some experiments on the recognition of speech,
with one and with two ears. J Acoust Soc Am 1953, 25: 975.</reference>
  <reference order="51">McFarl and DH. Respi rat ory markers of conversat i onal
interaction. J Speech Lang Hear Res 2001, 44: 128.</reference>
  <reference order="52">Pickering MJ, Garrod S. Do people use language production to
make predictions during comprehension? Trends Cogn Sci - 2007, 11: 105
110.</reference>
  <reference order="53">Scott SK, McGettigan C, Eisner F. A little more conversation,
a little less action-candidate roles for the motor cortex in - speech perception. Nat
Rev Neurosci 2009, 10: 295 302.</reference>
  <reference order="54">Wu C, Cao S, Zhou F, Wang C, Wu X, Li L. Masking of - speech
in people with fi rst-episode schizophrenia and people with chronic schizophrenia.
Schizophr Res 2012a, 134: 33 41.</reference>
  <reference>Thi s revi ew was supported by the Nati onal Basi c Research Development
Program of China (2009CB320901, 2011CB707805, 2013CB329304), the National Natural
Science Foundation of China (31170985, 91120001, 61121002), and "985" project grants
from Peking University.</reference>
  <reference order="1">Liberman AM, Delattre P, Cooper FS. The role of selected
stimulus-variables in the perception of the unvoiced stop - consonants. Am J Psychol
1952, 65: 497 516.</reference>
  <reference order="2">Liberman AM, Cooper FS, Shankweiler DP, Studdert KM. -
Perception of the speech code. Psychol Rev 1967, 74: 431 461.</reference>
  <reference order="3">Liberman AM. Speech: A Special Code. Cambridge, MA: The MIT
Press 1996.</reference>
  <reference order="4">Kent RD, Mi ni f i e FD. Coart i cul at i on i n recent speech
- production models. J Phon 1977, 5: 115 133.</reference>
  <reference order="5">Liberman AM, Mattingly IG. The motor theory of speech -
perception revised. Cognition 1985, 21: 1 36.</reference>
  <reference order="6">McGurk H, MacDonald J. Hearing lips and seeing voices. -
Nature 1976, 264: 746 748.</reference>
  <reference order="7">Sumby WH, Pol l ack I . Vi sual cont r i but i on t o speech
intelligibility in noise. J Acoust Soc Am 1954, 26: 212.</reference>
  <reference order="8">Rudmann DS, McCarley JS, Kramer AF. Bimodal displays i mprove
speech comprehensi on i n envi ronment s wi t h - multiple speakers. Hum Fac Erg Soc
P 2003, 45: 329 336.</reference>
  <reference order="9">Wu C, Cao S, Wu X, Li L. Tempor al l y pr e-pr esent ed
lipreading cues release speech from informational masking. J - Acoust Soc Am 2013,
133: 281 285.</reference>
  <reference order="10">Al ho J, Sat o M, Sams M, Schwar t z JL, Ti i t i nen H,
J&#xE4;&#xE4;skel&#xE4;inen IP. Enhanced early-latency electromagnetic act i vi t y i
n t he l ef t premot or cort ex i s associ at ed wi t h successful phonetic
categorization. Neuroimage 2012, 60: - 1937 1946.</reference>
  <reference order="11">Callan D, Callan A, Gamez M, Sato MA, Kawato M. Premotor
cortex mediates perceptual performance. Neuroimage 2010, - 51: 844 858.</reference>
  <reference order="12">Schrei ner CE, Wi ner JA. Audi t ory cort ex mapmaki ng: -
principles, projections, and plasticity. Neuron 2007, 56: 356 365.</reference>
  <reference order="13">Recanzone GH, Sutter ML. The biological basis of audition. -
Annu Rev Psychol 2008, 59: 119 142.</reference>
  <reference order="14">Belin P, Zatorre RJ. Adaptation to speaker's voice in right -
anterior temporal lobe. Neuroreport 2003, 14: 2105 2109.</reference>
  <reference order="15">Scott SK, Blank CC, Rosen S, Wise RJ. Identification of a
pathway for intelligible speech in the left temporal lobe. Brain - 2000, 123: 2400
2406.</reference>
  <reference order="16">Hickok G, Poeppel D. Towards a functional neuroanatomy of -
speech perception. Trends Cogn Sci 2000, 4: 131 138.</reference>
  <reference order="17">Hickok G, Poeppel D. The cortical organization of speech -
processing. Nat Neurosci 2007, 8: 393 402.</reference>
  <reference order="18">Baddeley A, Lewis V, Vallar G. Exploring the articulatory
loop. - Q J Exp Psychol 1984, 36: 233 252.</reference>
  <reference order="19">Wi se RJ, Scot t SK, Bl ank SC, Mummer y CJ, Mur phy K,
Warburt on EA. Separat e neural subsyst ems wi t hi n - Wernicke's area. Brain 2001,
124: 83 95.</reference>
  <reference order="20">Andersen RA, Buneo CA. Intenti onal maps i n posteri or -
parietal cortex. Annu Rev Neurosci 2002, 25: 189 220.</reference>
  <reference order="21">Wolpert DM, Doya K, Kawato M. A unifying computational
framework for motor control and social interaction. Philos - Trans R Soc Lond B Biol
Sci 2003, 358: 593 602.</reference>
  <reference order="22">Adank P, Devlin JT. On-line plasticity in spoken sentence
comprehensi on: Adapti ng to ti me-compressed speech. Neuroimage 2010, 49:
1124.</reference>
  <reference order="23">Londei A, D'Ausi l i o A, Basso D, Sesti eri C, Gratta CD,
Romani GL, et al. Sensory-motor brain network connectivity - for speech
comprehension. Hum Brain Mapp 2010, 31: 567 580.</reference>
  <reference order="24">Wi l son SM. Li steni ng to speech acti vates motor areas -
involved in speech production. Nat Neurosci 2004, 7: 701 702.</reference>
  <reference order="25">Wilson SM, Iacoboni M. Neural responses to non-native
phonemes var yi ng i n pr oduci bi l i t y: evi dence f or t he sensorimotor nature
of speech perception. Neuroimage - 2006, 33: 316 325.</reference>
  <reference order="26">Fadiga L, Craighero L, Buccino G, Rizzolatti G. Speech
listening specifically modulates the excitability of tongue - muscles: a TMS study.
Eur J Neurosci 2002, 15: 399 402.</reference>
  <reference order="27">Pulverm&#xFC;ller F, Huss M, Kherif F, del Prado Martin FM,
Hauk O, Shtyrov Y. Motor cortex maps articulatory features of - speech sounds. Proc
Natl Acad Sci U S A 2006, 103: 7865 7870.</reference>
  <reference order="28">Bever TG, Poeppel D. Analysis by synthesis: a (re-) emerging
program of research for language and vision. Biolinguistics - 2010, 4: 174
200.</reference>
  <reference order="29">Cal l an DE, Jones JA, Cal l an AM, Akahane-Yamada R.
Phonetic perceptual identification by native-and secondlanguage speakers
differentially activates brain regions i nvol ved wi t h acoust i c phonet i c
processi ng and t hose i nvol ved wi t h art i cul at ory-audi t ory/orosensory i nt
ernal - models. Neuroimage 2004, 22: 1182 1194.</reference>
  <reference order="30">Hi ckok G, Houde J, Rong F. Sensori mot or i nt egrat i on i
n speech processi ng: computati onal basi s and neural - organization. Neuron 2011,
69: 407 422.</reference>
  <reference order="31">Watkins KE, Strafella AP, Paus T. Seeing and hearing speech
excites the motor system involved in speech production. - Neuropsychologia 2003, 41:
989 994.</reference>
  <reference order="32">D'Ausilio A, Pulverm&#xFC;ller F, Salmas P, Bufalari I,
Begliomini C, Fadiga L. The motor somatotopy of speech perception. Curr - Biol 2009,
19: 381 385.</reference>
  <reference order="33">Meister IG, Wilson SM, Deblieck C, Wu AD, Iacoboni M. The
essential role of premotor cortex in speech perception. Curr - Biol 2007, 17: 1692
1696.</reference>
  <reference order="34">Watkins K, Paus T. Modulation of motor excitability during
speech perception: the role of Broca's area. J Cogn Neurosci - 2004, 16: 978
987.</reference>
  <reference order="35">Mohr JP, Pessin MS, Finkelstein S, Funkenstein HH, Duncan GW,
Davi s KR. Broca aphasi a Pathol ogi c and cl i ni cal . - Neurology 1978, 28: 311
311.</reference>
  <reference order="36">Crinion JT, Warburton EA, Lambon-Ralph MA, Howard D, Wise RJ.
Listening to narrative speech after aphasic stroke: the role of the left anterior
temporal lobe. Cereb Cortex 2006, 16: 1116 -1125.</reference>
  <reference order="37">Bogen JE, Bogen GM. Wernick's region-Where is it? Ann NY -
Acad Sci, 1976, 280: 834 843.</reference>
  <reference order="38">Bak er E, Bl ums t ei n SE, Goodgl as s H. I nt er ac t i on
between phonol ogi cal and semanti c factors i n audi tory - comprehension.
Neuropsychologia 1981, 19: 1 15.</reference>
  <reference order="39">Bishop D, Mogford-Bevan K. Language Development in
Exceptional Circumstances. Psychology Press 1993.</reference>
  <reference order="40">Bishop CW, Miller LM. A multisensory cortical network for
understanding speech in noise. J Cogn Neurosci 2009, 21: - 1790 1804.</reference>
  <reference order="41">Werker JF, Yeung HH. Infant speech perception bootstraps -
word learning. Trends Cogn Sci 2005, 9: 519 527.</reference>
  <reference order="42">Tsao FM, Liu HM, Kuhl PK. Speech perception in infancy
predicts language development in the second year of life: a - longitudinal study.
Child Dev 2004, 75: 1067 1084.</reference>
  <reference order="43">Basso A, Casati G, Vignolo LA. Phonemic identification defect
in aphasia. Cortex 1977, 13: 85.</reference>
  <reference order="44">Scott SK, Rosen S, Lang H, Wise RJ. Neural correlates of
intelligibility in speech investigated with noise vocoded speech-a positron emission
tomography study. J Acoust Soc Am 2006, 120: 1075.</reference>
  <reference order="45">Davis MH, Johnsrude IS. Hierarchical processing in spoken -
language comprehension. J Neurosci 2003, 23: 3423 3431.</reference>
  <reference order="46">Uppenkamp S, Johnsrude IS, Norris D, Marslen-Wilson W,
Patterson RD. Locating the initial stages of speech? Sound processing in human
temporal cortex. Neuroimage 2006, 31: - 1284 1296.</reference>
  <reference order="47">Warren JE, Sauter DA, Ei sner F, Wi l and J, Dresner M, Wise
RJ, et al. Positive emotions preferentially engage an - auditory-motor "mirror"
system. J Neurosci 2006, 26: 13067 13075.</reference>
  <reference order="48">Roy AC, Cr ai gher o L, Fabbr i - Des t r o M, Fadi ga L.
Phonological and lexical motor facilitation during speech listening: A transcranial
magnetic stimulation study. J Physiol - Paris 2008, 102: 101 105.</reference>
  <reference order="49">Fridriksson J, Moss J, Davis B, Baylis GC, Bonilha L, Rorden
C. Motor speech perception modulates the cortical language - areas. Neuroimage 2008,
41: 605 613.</reference>
  <reference order="50">Cherry EC. Some experiments on the recognition of speech,
with one and with two ears. J Acoust Soc Am 1953, 25: 975.</reference>
  <reference order="51">McFarl and DH. Respi rat ory markers of conversat i onal
interaction. J Speech Lang Hear Res 2001, 44: 128.</reference>
  <reference order="52">Pickering MJ, Garrod S. Do people use language production to
make predictions during comprehension? Trends Cogn Sci - 2007, 11: 105
110.</reference>
  <reference order="53">Scott SK, McGettigan C, Eisner F. A little more conversation,
a little less action-candidate roles for the motor cortex in - speech perception. Nat
Rev Neurosci 2009, 10: 295 302.</reference>
  <reference order="54">Wu C, Cao S, Zhou F, Wang C, Wu X, Li L. Masking of - speech
in people with fi rst-episode schizophrenia and people with chronic schizophrenia.
Schizophr Res 2012a, 134: 33 41.</reference>
  <resolved_reference>Thi s revi ew was supported by the Nati onal Basi c Research
Development Program of China (2009CB320901, 2011CB707805, 2013CB329304), the National
Natural Science Foundation of China (31170985, 91120001, 61121002), and "985" project
grants from Peking University.</resolved_reference>
  <resolved_reference order="1">Liberman AM, Delattre P, Cooper FS. The role of
selected stimulus-variables in the perception of the unvoiced stop - consonants. Am J
Psychol 1952, 65: 497 516.</resolved_reference>
  <resolved_reference order="2">Liberman AM, Cooper FS, Shankweiler DP, Studdert KM.
- Perception of the speech code. Psychol Rev 1967, 74: 431 461.</resolved_reference>
  <resolved_reference order="3">Liberman AM. Speech: A Special Code. Cambridge, MA:
The MIT Press 1996.</resolved_reference>
  <resolved_reference order="4">Kent RD, Mi ni f i e FD. Coart i cul at i on i n
recent speech - production models. J Phon 1977, 5: 115 133.</resolved_reference>
  <resolved_reference order="5">Liberman AM, Mattingly IG. The motor theory of speech
- perception revised. Cognition 1985, 21: 1 36.</resolved_reference>
  <resolved_reference order="6">McGurk H, MacDonald J. Hearing lips and seeing
voices. - Nature 1976, 264: 746 748.</resolved_reference>
  <resolved_reference order="7">Sumby WH, Pol l ack I . Vi sual cont r i but i on t o
speech intelligibility in noise. J Acoust Soc Am 1954, 26: 212.</resolved_reference>
  <resolved_reference order="8">Rudmann DS, McCarley JS, Kramer AF. Bimodal displays
i mprove speech comprehensi on i n envi ronment s wi t h - multiple speakers. Hum Fac
Erg Soc P 2003, 45: 329 336.</resolved_reference>
  <resolved_reference order="9">Wu C, Cao S, Wu X, Li L. Tempor al l y pr e-pr esent
ed lipreading cues release speech from informational masking. J - Acoust Soc Am 2013,
133: 281 285.</resolved_reference>
  <resolved_reference order="10">Al ho J, Sat o M, Sams M, Schwar t z JL, Ti i t i
nen H, J&#xE4;&#xE4;skel&#xE4;inen IP. Enhanced early-latency electromagnetic act i
vi t y i n t he l ef t premot or cort ex i s associ at ed wi t h successful phonetic
categorization. Neuroimage 2012, 60: - 1937 1946.</resolved_reference>
  <resolved_reference order="11">Callan D, Callan A, Gamez M, Sato MA, Kawato M.
Premotor cortex mediates perceptual performance. Neuroimage 2010, - 51: 844
858.</resolved_reference>
  <resolved_reference order="12">Schrei ner CE, Wi ner JA. Audi t ory cort ex mapmaki
ng: - principles, projections, and plasticity. Neuron 2007, 56: 356
365.</resolved_reference>
  <resolved_reference order="13">Recanzone GH, Sutter ML. The biological basis of
audition. - Annu Rev Psychol 2008, 59: 119 142.</resolved_reference>
  <resolved_reference order="14">Belin P, Zatorre RJ. Adaptation to speaker's voice
in right - anterior temporal lobe. Neuroreport 2003, 14: 2105
2109.</resolved_reference>
  <resolved_reference order="15">Scott SK, Blank CC, Rosen S, Wise RJ. Identification
of a pathway for intelligible speech in the left temporal lobe. Brain - 2000, 123:
2400 2406.</resolved_reference>
  <resolved_reference order="16">Hickok G, Poeppel D. Towards a functional
neuroanatomy of - speech perception. Trends Cogn Sci 2000, 4: 131
138.</resolved_reference>
  <resolved_reference order="17">Hickok G, Poeppel D. The cortical organization of
speech - processing. Nat Neurosci 2007, 8: 393 402.</resolved_reference>
  <resolved_reference order="18">Baddeley A, Lewis V, Vallar G. Exploring the
articulatory loop. - Q J Exp Psychol 1984, 36: 233 252.</resolved_reference>
  <resolved_reference order="19">Wi se RJ, Scot t SK, Bl ank SC, Mummer y CJ, Mur phy
K, Warburt on EA. Separat e neural subsyst ems wi t hi n - Wernicke's area. Brain
2001, 124: 83 95.</resolved_reference>
  <resolved_reference order="20">Andersen RA, Buneo CA. Intenti onal maps i n posteri
or - parietal cortex. Annu Rev Neurosci 2002, 25: 189 220.</resolved_reference>
  <resolved_reference order="21">Wolpert DM, Doya K, Kawato M. A unifying
computational framework for motor control and social interaction. Philos - Trans R
Soc Lond B Biol Sci 2003, 358: 593 602.</resolved_reference>
  <resolved_reference order="22">Adank P, Devlin JT. On-line plasticity in spoken
sentence comprehensi on: Adapti ng to ti me-compressed speech. Neuroimage 2010, 49:
1124.</resolved_reference>
  <resolved_reference order="23">Londei A, D'Ausi l i o A, Basso D, Sesti eri C,
Gratta CD, Romani GL, et al. Sensory-motor brain network connectivity - for speech
comprehension. Hum Brain Mapp 2010, 31: 567 580.</resolved_reference>
  <resolved_reference order="24">Wi l son SM. Li steni ng to speech acti vates motor
areas - involved in speech production. Nat Neurosci 2004, 7: 701
702.</resolved_reference>
  <resolved_reference order="25">Wilson SM, Iacoboni M. Neural responses to
non-native phonemes var yi ng i n pr oduci bi l i t y: evi dence f or t he
sensorimotor nature of speech perception. Neuroimage - 2006, 33: 316
325.</resolved_reference>
  <resolved_reference order="26">Fadiga L, Craighero L, Buccino G, Rizzolatti G.
Speech listening specifically modulates the excitability of tongue - muscles: a TMS
study. Eur J Neurosci 2002, 15: 399 402.</resolved_reference>
  <resolved_reference order="27">Pulverm&#xFC;ller F, Huss M, Kherif F, del Prado
Martin FM, Hauk O, Shtyrov Y. Motor cortex maps articulatory features of - speech
sounds. Proc Natl Acad Sci U S A 2006, 103: 7865 7870.</resolved_reference>
  <resolved_reference order="28">Bever TG, Poeppel D. Analysis by synthesis: a (re-)
emerging program of research for language and vision. Biolinguistics - 2010, 4: 174
200.</resolved_reference>
  <resolved_reference order="29">Cal l an DE, Jones JA, Cal l an AM, Akahane-Yamada
R. Phonetic perceptual identification by native-and secondlanguage speakers
differentially activates brain regions i nvol ved wi t h acoust i c phonet i c
processi ng and t hose i nvol ved wi t h art i cul at ory-audi t ory/orosensory i nt
ernal - models. Neuroimage 2004, 22: 1182 1194.</resolved_reference>
  <resolved_reference order="30">Hi ckok G, Houde J, Rong F. Sensori mot or i nt
egrat i on i n speech processi ng: computati onal basi s and neural - organization.
Neuron 2011, 69: 407 422.</resolved_reference>
  <resolved_reference order="31">Watkins KE, Strafella AP, Paus T. Seeing and hearing
speech excites the motor system involved in speech production. - Neuropsychologia
2003, 41: 989 994.</resolved_reference>
  <resolved_reference order="32">D'Ausilio A, Pulverm&#xFC;ller F, Salmas P, Bufalari
I, Begliomini C, Fadiga L. The motor somatotopy of speech perception. Curr - Biol
2009, 19: 381 385.</resolved_reference>
  <resolved_reference order="33">Meister IG, Wilson SM, Deblieck C, Wu AD, Iacoboni
M. The essential role of premotor cortex in speech perception. Curr - Biol 2007, 17:
1692 1696.</resolved_reference>
  <resolved_reference order="34">Watkins K, Paus T. Modulation of motor excitability
during speech perception: the role of Broca's area. J Cogn Neurosci - 2004, 16: 978
987.</resolved_reference>
  <resolved_reference order="35">Mohr JP, Pessin MS, Finkelstein S, Funkenstein HH,
Duncan GW, Davi s KR. Broca aphasi a Pathol ogi c and cl i ni cal . - Neurology 1978,
28: 311 311.</resolved_reference>
  <resolved_reference order="36">Crinion JT, Warburton EA, Lambon-Ralph MA, Howard D,
Wise RJ. Listening to narrative speech after aphasic stroke: the role of the left
anterior temporal lobe. Cereb Cortex 2006, 16: 1116 -1125.</resolved_reference>
  <resolved_reference order="37">Bogen JE, Bogen GM. Wernick's region-Where is it?
Ann NY - Acad Sci, 1976, 280: 834 843.</resolved_reference>
  <resolved_reference order="38">Bak er E, Bl ums t ei n SE, Goodgl as s H. I nt er
ac t i on between phonol ogi cal and semanti c factors i n audi tory - comprehension.
Neuropsychologia 1981, 19: 1 15.</resolved_reference>
  <resolved_reference order="39">Bishop D, Mogford-Bevan K. Language Development in
Exceptional Circumstances. Psychology Press 1993.</resolved_reference>
  <resolved_reference order="40">Bishop CW, Miller LM. A multisensory cortical
network for understanding speech in noise. J Cogn Neurosci 2009, 21: - 1790
1804.</resolved_reference>
  <resolved_reference order="41">Werker JF, Yeung HH. Infant speech perception
bootstraps - word learning. Trends Cogn Sci 2005, 9: 519 527.</resolved_reference>
  <resolved_reference order="42">Tsao FM, Liu HM, Kuhl PK. Speech perception in
infancy predicts language development in the second year of life: a - longitudinal
study. Child Dev 2004, 75: 1067 1084.</resolved_reference>
  <resolved_reference order="43">Basso A, Casati G, Vignolo LA. Phonemic
identification defect in aphasia. Cortex 1977, 13: 85.</resolved_reference>
  <resolved_reference order="44">Scott SK, Rosen S, Lang H, Wise RJ. Neural
correlates of intelligibility in speech investigated with noise vocoded speech-a
positron emission tomography study. J Acoust Soc Am 2006, 120:
1075.</resolved_reference>
  <resolved_reference order="45">Davis MH, Johnsrude IS. Hierarchical processing in
spoken - language comprehension. J Neurosci 2003, 23: 3423 3431.</resolved_reference>
  <resolved_reference order="46">Uppenkamp S, Johnsrude IS, Norris D, Marslen-Wilson
W, Patterson RD. Locating the initial stages of speech? Sound processing in human
temporal cortex. Neuroimage 2006, 31: - 1284 1296.</resolved_reference>
  <resolved_reference order="47">Warren JE, Sauter DA, Ei sner F, Wi l and J, Dresner
M, Wise RJ, et al. Positive emotions preferentially engage an - auditory-motor
"mirror" system. J Neurosci 2006, 26: 13067 13075.</resolved_reference>
  <resolved_reference order="48">Roy AC, Cr ai gher o L, Fabbr i - Des t r o M, Fadi
ga L. Phonological and lexical motor facilitation during speech listening: A
transcranial magnetic stimulation study. J Physiol - Paris 2008, 102: 101
105.</resolved_reference>
  <resolved_reference order="49">Fridriksson J, Moss J, Davis B, Baylis GC, Bonilha
L, Rorden C. Motor speech perception modulates the cortical language - areas.
Neuroimage 2008, 41: 605 613.</resolved_reference>
  <resolved_reference order="50">Cherry EC. Some experiments on the recognition of
speech, with one and with two ears. J Acoust Soc Am 1953, 25:
975.</resolved_reference>
  <resolved_reference order="51">McFarl and DH. Respi rat ory markers of conversat i
onal interaction. J Speech Lang Hear Res 2001, 44: 128.</resolved_reference>
  <resolved_reference order="52">Pickering MJ, Garrod S. Do people use language
production to make predictions during comprehension? Trends Cogn Sci - 2007, 11: 105
110.</resolved_reference>
  <resolved_reference order="53">Scott SK, McGettigan C, Eisner F. A little more
conversation, a little less action-candidate roles for the motor cortex in - speech
perception. Nat Rev Neurosci 2009, 10: 295 302.</resolved_reference>
  <resolved_reference order="54">Wu C, Cao S, Zhou F, Wang C, Wu X, Li L. Masking of
- speech in people with fi rst-episode schizophrenia and people with chronic
schizophrenia. Schizophr Res 2012a, 134: 33 41.</resolved_reference>
  <page width="612" height="792" number="1">
    <header x="59.39" y="701.54" width="493.27" height="20.49"></header>
  </page>
  <page width="612" height="792" number="2">
    <header x="62.21" y="702.08" width="493.19" height="11.16"></header>
  </page>
  <page width="612" height="792" number="3">
    <header x="59.39" y="702.16" width="492.84" height="11.16"></header>
  </page>
  <page width="612" height="792" number="4">
    <header x="62.22" y="702.08" width="492.9" height="11.16"></header>
  </page>
  <page width="612" height="792" number="5">
    <header x="59.38" y="702.16" width="492.88" height="11.16"></header>
  </page>
  <page width="612" height="792" number="6">
    <header x="62.2" y="702.08" width="492.63" height="11.16"></header>
  </page>
  <page width="612" height="792" number="7">
    <header x="59.38" y="702.16" width="492.64" height="11.16"></header>
  </page>
</pdf>
