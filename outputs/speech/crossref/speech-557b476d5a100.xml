<?xml version="1.0"?>
<pdf>
  <title line_height="18.26" font="AdvP193F">Effects of Temporal Fine Structure on
the Lateralization of Speech and on Speech Understanding in Noise</title>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.07" year_ratio="0.0"
cap_ratio="0.11" name_ratio="0.19617224880382775" word_count="209"
lateness="0.09090909090909091" reference_score="6.42">This study evaluated the role
of temporal fine structure in the lateralization and understanding of speech in six
normal-hearing listeners. Interaural time differences (ITDs) were introduced to
invoke lateralization. Speech reception thresholds (SRTs) were evaluated in
backgrounds of two-talker babble and speech-shaped noise. Two-syllable words with m
ITDs of 0 and 700 s were used as targets. A vocoder technique, which systematically
randomized fine structure, was used to evaluate the effects of fine structure on
these tasks. Randomization of temporal fine structure was found to significantly
reduce the ability of normal-hearing listeners to lateralize words, although for many
listeners, good lateralization performance was achieved with as much as 80%
fine-structure randomization. Most listeners demonstrated some rudimentary ability to
lateralize with 100% fine-structure randomization. When ITDs were m 0 s,
randomization of fine structure had a much greater effect on SRT in two-talker babble
than in speech-shaped noise. Binaural advantages were also observed. In steady noise,
the difference in SRT m between words with 0- vs 700- s ITDs was, on average, 6 dB
with no fine-structure randomization and 2 dB with 100% fine-structure randomization.
In two-talker babble this difference was 1.9 dB and, for most listeners, showed
little effect of the degree of finestructure randomization. These results suggest
that<component x="72.0" y="110.37" width="233.17" height="332.22" page="1"
page_width="593.97" page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.06" year_ratio="0.0"
cap_ratio="0.08" name_ratio="0.16216216216216217" word_count="37"
lateness="0.09090909090909091" reference_score="5.66">(1) improved delivery of
temporal fine structure would improve speech understanding in noise for implant
recipients, (2) bilateral implant recipients might benefit from temporal envelope
ITDs, and (3) improved delivery of temporal information could improve binaural
benefits.<component x="329.04" y="397.29" width="233.08" height="69.23" page="1"
page_width="593.97" page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.08" year_ratio="0.0"
cap_ratio="0.12" name_ratio="0.2398921832884097" word_count="371"
lateness="0.18181818181818182" reference_score="7.27">Interaural time differences
(ITDs) contribute to important real-world tasks such as localization ability
(Rayleigh 1907; Wightman and Kistler 1992) and binaural unmasking (Carhart et al.
1967; Bronkhorst and Plomp 1988; Culling et al. 2004). Real environmental sounds
provide ITDs with both envelope and G fine structure. At low frequencies ( 1.5 kHz)
for stimuli longer than 100 ms, fine-structure ITDs dominate perception (Tobias and
Schubert 1959); however, both envelope and fine-structure ITDs contribute to
lateralization ability (Klumpp and Eady 1956; Yost et al. 1971; Henning 1974;
McFadden and Pasanen 1976; Van de Par and Kohlrausch 1997), binaural unmasking (Van
de Par and Kohlrausch 1997; Long et al. 2006), and segregation ability (Drennan et
al. 2003; Best et al. 2004). Common cochlear implant sound processing strategies do
not explicitly encode temporal fine-structure information, but only the envelope
information. While some fine-structure information for low frequencies is passed
through the temporal envelope, most temporal fine-structure information is lost in
processing. Previous observations that envelope ITDs contribute to lateralization and
segregation in normal-hearing listeners is beneficial for bilateral implantees
because this means it would be theoretically possible for implantees to glean some
benefit from interaural timing differences. Temporal fine structure is also known to
provide information, which help normal-hearing humans perceive music (Smith et al.
2002), speech in noise (Kong et al. 2005), and tonal languages (Xu and Pfingst 2003).
Hence, improved delivery of temporal fine structure should help monaural and binaural
implantees. This study evaluates the role of fine structure in practical tasks such
as the lateralization of speech and speech understanding in noise. A key motivation
is to better understand how improved delivery of fine structure could improve hearing
in implantees. Insights into the role of fine structure in practical hearing tasks
could lead to improvements in cochlear implant sound processing. In this study, we
presented vocoder-processed sounds to normal-hearing listeners. The vocoder divided
the signal into six band-pass channels. A signal processing technique enabled graded
randomization of the fine structure, but preserved the temporal envelope of the
waveforms. The procedure offers the unique capability to systematically vary the
extent of the randomization of the fine structure to quantify the effect of temporal
fine structure on human auditory processing capabilities. This study<component
x="329.04" y="48.18" width="233.16" height="248.6" page="1" page_width="593.97"
page_height="792.0"></component><component x="31.86" y="347.01" width="233.14"
height="368.11" page="2" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.04" year_ratio="0.0"
cap_ratio="0.0" name_ratio="0.2631578947368421" word_count="38"
lateness="0.18181818181818182" reference_score="3.93">served two purposes, one
scientific and one clinical: (1) to determine the extent to which temporal fine
structure contributes to lateralization and speech understanding in noise, and (2) to
evaluate how improved fine-structure delivery might improve these
capabilities.<component x="288.85" y="645.83" width="233.13" height="69.28" page="2"
page_width="593.97" page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.12" year_ratio="0.01"
cap_ratio="0.16" name_ratio="0.19875776397515527" word_count="161"
lateness="0.18181818181818182" reference_score="11.3">Bilateral cochlear implant
simulations were presented to normal-hearing listeners who had thresholds of less
than 25 dB HL at all audiometric frequencies. Six listeners participated in the
study. The stimuli were presented over TDH-50P headphones via a Macintosh G4 laptop
in a quiet room. _ Speech levels were calibrated at 65 dBA. Listeners ages ranged
from 26-38 with a mean of 32.3 years. They included two women and four men who
volunteered their time for the study. The study was approved by the University of
Washington Institutional Review Board. A diagram of the fine-structure randomization
procedure is shown in Figure 1. The stimulus, X(t), was passed through a bank of 6
band-pass FIR filters. The filters covered the logarithmically spaced frequency
ranges of 80-308, 308-788, 788-1794, 1794- 3906, 3906-8338, and 8,338-17,640 Hz. A
Hilbert transform was used to extract the envelope and fine structure of each filter.
A random component was added to the Hilbert phase and then was weighted by<component
x="288.85" y="347.0" width="233.17" height="248.55" page="2" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.08" year_ratio="0.01"
cap_ratio="0.14" name_ratio="0.2972972972972973" word_count="148"
lateness="0.2727272727272727" reference_score="9.32">a noise factor, NF, which varied
from 0 to 1. The NF represents the extent of randomization of the fine structure such
that NF=1 was 100% fine-structure randomization and NF=0 was only filtered, keeping
the fine structure identical to the original signal. This NF concept was first
introduced by Rubinstein and Turner (2003). In signal processing terms, the NF
determined the extent of randomization of the Hilbert phase from 0 to 100%. A
sequence of identically distributed uniform random variables p from 0 to 1, r (t),
was multiplied by 2 times the NF i and added to the Hilbert phase of the original
stimulus (see Eq. 1). The randomized fine structure was filtered by B (t), and the
output was multiplied by i the Hilbert envelope of the original stimulus. This
procedure is represented analytically by the following equation operating on the
output of a single channel:<component x="72.0" y="502.4" width="233.16"
height="212.72" page="3" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.08" year_ratio="0.0"
cap_ratio="0.12" name_ratio="0.24263431542461006" word_count="577"
lateness="0.36363636363636365" reference_score="8.46">in which y (t) is the output
stimulus, x (t) is the filtered i i stimulus, H(x (t)) is the Hilbert transform, B
(t) is the i i B ^ impulse response of the ith band pass filter, * indicates
convolution, r (t) is a sequence of uniformly i distributed random variables from 0
to 1, and n is the NF. All six channels are summed to create the output signal Y(t).
Randomization of phase was independent for the two ears and for each band. Using this
approach, psychophysical abilities were evaluated as a function of the NFs ranging
from 0 (no randomization, i.e., the original stimulus filtered) to 1 (complete
randomization equivalent to a traditional 6-channel, vocoder-type, noise-band
cochlear implant simulation, e.g., Shannon et al. 1995). In experiments with
background noise, ITDs were introduced to the signal before NF processing. The sum of
the signal and noise (X(t)) was then processed using Eq. 1. The process of
introducing fine-structure randomization and refiltering could alter the envelope. B
^ When comparing the target envelope before processing and the output envelope for
single pass bands, the correlations were 0.98-0.99. Thus, the effect of
fine-structure randomization on the envelope was slight. Lateralization B B ^ ^ Two
spondees, padlock and stairway, were chosen, because they had robust low-frequency
energy. A 6 4 repeated-measures design was used with 6 NFs( and 4 repetitions. The
spondees were presented to listeners using NFs of 0, 0.5, 0.7, 0.8, 0.9, and 1. The
Binaural intelligibility level difference The binaural intelligibility level
difference (BILD) refers to an intelligibility advantage a listener can obtain when
listening to speech in noise if the binaural timing or phase of the speech differs
from that of the noise (Bronkhorst and Plomp 1988). A speech reception threshold
(SRT) is the signal to noise ratio (S/N) at which speech is intelligible. In this
case, S/N for the 50% intelligibility level (the SRT) was determined for speech in
two conditions in which the ITDs of the speech differed. Binaural intelligibility
level differences were calculated by determining the difference between the SRT for m
spondees with 0 and 700- s ITDs. This was done four times with two types of
background noise, steadystate, speech-shaped noise, and two-talker babble ( ( with a
variety of NFs. The final analysis was 4 2 5 using 4 repetitions, 2 types of noise
background, and 5 NFs. On each trial, normal-hearing listeners identified 1 of 12
equally difficult spondees (Harris 1991) presented in one of the two noise
backgrounds. The babble consisted of one male and one female talker using a sentence
from the SPIN test (Bilger et al. 1984). The target spondees were all spoken by a
female talker, different from the female talker in the babble. To minimize variance
that might result from variable difficulty by using different babble backgrounds on
each trial, i.e., to get the least noisy measure of SRT in the babble, the same
babble background was used on every trial. The male talker B ^ spoke the sentence
Name two uses for ice, and the B female talker spoke the sentence Bill might discuss
^ the foam. The target speech (the spondee) was delayed from the onset of the babble
by 500 ms. In the steady noise background, the same noise was used on every trial,
and the spondees were delayed by 500 ms relative to the start of the noise. Both the
target and noise were processed with fine-structure<component x="72.0" y="144.67"
width="233.22" height="284.49" page="3" page_width="593.97"
page_height="792.0"></component><component x="72.0" y="48.17" width="233.14"
height="76.58" page="3" page_width="593.97"
page_height="792.0"></component><component x="329.04" y="48.12" width="233.13"
height="315.71" page="3" page_width="593.97"
page_height="792.0"></component><component x="31.86" y="562.15" width="233.11"
height="152.96" page="4" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.11" year_ratio="0.0"
cap_ratio="0.14" name_ratio="0.1574074074074074" word_count="108"
lateness="0.36363636363636365" reference_score="9.63">(Hilbert phase) randomization,
independently processed for the two ears. The spondees were presented m with ITDs of
0 or 700 s. Noise factors were 0, 0.5, 0.75, 0.875, and 1. A one-down, one-up
adaptive tracking procedure was used in which noise levels were tracked in 2-dB
increments to determine an SRT representing 50% correct. In the NF=0 condition using
babble background, the S/N ratio _ dropped below 40 dB. In this case, the listeners
were permitted to lower the overall level about 5 dB because background noise was
quite loud. The 12spondee closed set discrimination task and tracking procedure were
the same as used by Turner et al.<component x="288.85" y="562.15" width="233.16"
height="152.96" page="4" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.09" year_ratio="0.01"
cap_ratio="0.17" name_ratio="0.1953125" word_count="256"
lateness="0.45454545454545453" reference_score="12.78">(2004). One run consisted of
14 reversals in which the threshold was the mean of the last 10 reversals. Four
tracking histories were completed for each condition. The order of presentation was
randomized in the following way: one of the NFs was selected randomly, then listeners
completed all four runs (two in babble and two in steady noise, with ITDs=0 and m 700
s) presented in a random order using that specific NF. Then, a different NF was
selected randomly, and listeners completed the four conditions (two noise backgrounds
and two ITDs) in a newly randomized order. This procedure continued until all
conditions were finished. Each listener had a different randomized order of
presentation for both the NFs and the four conditions run with each NF. Listeners
completed all NF conditions for the first repetition before moving on to the second
repetition. RESULTS Lateralization Figure 2 shows the individual lateralization
results as a function of the NF. Figure 3 shows the mean lateralization results.
Error bars in all figures show ( the 95% confidence interval. A 6 4 repeated measures
ANOVA (6 NFs and 4 repetition times) demonstrated that, as expected, there was a
signifiG cant effect of NF (F =17.831, p 0.0005). There was 5,25 no effect of
repetition time demonstrating there was 2 no learning trend in this task. The mean r
for lateralization was above chance for NF=1 (p =0.0093), with 100% fine-structure
randomization, suggesting that most listeners could lateralize without finestructure
ITD information. This is consistent with previous observations that normal-hearing
listeners<component x="72.0" y="514.36" width="233.14" height="200.75" page="5"
page_width="593.97" page_height="792.0"></component><component x="72.0" y="287.19"
width="233.14" height="202.24" page="5" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.12" year_ratio="0.01"
cap_ratio="0.17" name_ratio="0.21568627450980393" word_count="459"
lateness="0.45454545454545453" reference_score="12.7">can detect the ITD of the
envelope alone (McFadden and Pasanen 1976). There were also substantial variations
among listeners when 50% or more of the fine structure was randomized. A few
listeners (L1 and L4) were only slightly affected by 50% finestructure randomization,
whereas others (L3, L5, L6, and L7) were greatly affected by this randomization.
Speech understanding Figure 4 shows individual data from the speech-in-noise m
experiments in which the ITD=0 s. Figure 5 shows ( ( mean data. A 2 5 4
repeated-measures ANOVA (2 noise backgrounds, 5 NFs, and 4 repetition times)
demonstrated that there was a main effect of the NF G (F =126.5, p 0.0005), an
interaction between NF 4,20 G and noise background (F =34.308), p 0.0005), and a 4,20
main effect of the noise background (F =96.306, 1,4 G p 0.0005). The main effect of
noise background demonstrated that speech understanding in babble was usually better
than speech understanding in speech-shaped noise. The interaction demonstrated that
fine-structure randomization improved SRTs much more in babble than in steady-state
noise. As reflected in the interaction, the difference in SRT between the two
background noises was not significant when the NF was 1 (100% fine-structure
randomization). We note that in babble, the thresholds for NF=0 _ _ were extremely
low, in the range of 35 to 40 dB S/N. These results were slightly lower than those of
Turner _ et al. (2004) who found 30 dB for a similar condition. The primary
difference between studies was that the present study used more reversals and more
repetitions to determine a threshold. Also, different groups of listeners could have
different capabilities. m For ITD=0 s, there was a main effect of repetition G number
(F =7.951, p 0.002); an interaction be3,15 tween repetition number and noise
background G (F =5.222, p 0.011); a weak interaction between 3,15 G repetition and NF
(F =1.914, p 0.05); and a three12,60 way interaction among repetition time, NF, and
noise G background (F =2.280, p 0.018). The effects of 12,60 repetition time
indicated that there was some improvement over time in the SRT; however, the
interactions suggest that this improvement over time was limited to higher NFs in the
babble background. For NFs of 0.75, 0.875, and 1 in the babble background, SRTs
improved by about 6 dB from the first to the fourth time of testing, suggesting that
for the spondees presented in babble, the listeners learned to make use of envelope
cues without fine structure or learned how to listen in the silent gaps. In all the
other conditions, for speech-shaped noise with all NFs and for two-talker babble
backgrounds with NF=0 or 0.5, there was little effect of repetition time. We also
found similar learning trends in real<component x="329.04" y="633.92" width="233.12"
height="81.19" page="5" page_width="593.97"
page_height="792.0"></component><component x="329.04" y="48.12" width="233.23"
height="566.75" page="5" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.13" year_ratio="0.0"
cap_ratio="0.42" name_ratio="0.2247191011235955" word_count="89"
lateness="0.5454545454545454" reference_score="16.43">cochlear implantees using the
same methods for evaluation of SRTs (Won et al. 2007, submitted). Binaural
intelligibility level difference Figure 6 shows individual BILDs based on ITDs for
spondees in babble and speech-shaped noise as a function of the NF. The BILD is
calculated by m subtracting the SRT for ITD=700 s from the SRT m for ITD=0 s. Figure
7 shows mean BILD data. The result shows the extent to which fine structure
contributes to ITD-only binaural advantages in nor( ( mal-hearing listeners. A 2 5 4
repeated-measures<component x="31.86" y="179.76" width="233.05" height="21.44"
page="6" page_width="593.97" page_height="792.0"></component><component x="31.86"
y="48.29" width="233.1" height="112.47" page="6" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.1" year_ratio="0.0"
cap_ratio="0.19" name_ratio="0.2320675105485232" word_count="237"
lateness="0.6363636363636364" reference_score="12.25">ANOVA (2 noise backgrounds, 5
NFs, and 4 repetition times) was conducted. A main effect of noise G background (F
=13.799, p 0.014) and a main effect 1,5 G of NF (F =5.441, p 0.004) were observed.
All other 4,20 effects, including the effect of repetition time and associated
interactions, were not significant. This lack of interaction of the BILD with the
main factor of repetition time suggested that any learning that occurred was
statistically equivalent for 0- and 700m s ITDs. Binaural intelligibility level
differences were generally larger in speech-shaped noise than in a babble background,
which was shown by the main effect of noise background. Binaural intelligibility
level differences decrease as the amount of fine structure decreases (i.e., as the NF
increases), demonstrated by the main effect of NF. The BILD for NF=0 in speech-shaped
noise was about 6 dB on average, consistent with previous observations (e.g., Carhart
et al. 1967; Bronkhorst and Plomp 1988). In two-talker babble, the effect of fine
structure on the BILD was highly variable among listeners and did not appear to
change much as fine-structure randomization increased, averaging about 1.9 dB across
all NFs. Binaural intelligibility level differences for speechshaped noise were more
consistent among listeners and declined monotonically from about 6 dB for NF=0 to 1.1
dB for NF=1. Thus, the effect of fine structure for binaural cues appeared to be
greater in speech-shaped noise than in two-talker babble.<component x="288.85"
y="48.29" width="233.16" height="152.91" page="6" page_width="593.97"
page_height="792.0"></component><component x="72.0" y="526.32" width="233.13"
height="188.79" page="7" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.05" year_ratio="0.0"
cap_ratio="0.06" name_ratio="0.20388349514563106" word_count="103"
lateness="0.6363636363636364" reference_score="8.65">In the first experiment,
lateralization became more difficult with increased fine-structure randomization
(Figs. 2 and 3). The results demonstrated the dominance of fine structure (relative
to envelope) in lateralization based on ITDs. There was some lateralization ability
even with 100% fine-structure randomization, but performance was greatly enhanced by
fine structure. The result might also underestimate the effect of fine structure
because the interaural level differences were 0, which could push the percept toward
center, although center bias 2 was only apparent in the high-NF conditions when r
values were low. The results from the listeners least affected by finestructure
randomization paralleled results from<component x="72.0" y="299.15" width="233.15"
height="176.83" page="7" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.08" year_ratio="0.0"
cap_ratio="0.14" name_ratio="0.2544731610337972" word_count="503"
lateness="0.7272727272727273" reference_score="11.48">Jeffress et al. (1962) in which
listeners centered noises by adjusting the ITD of noises at the two ears. They found
that listeners could center a noise image well when the interaural correlation was as
low as 0.2. The fine structure of the noise bands in the present experiment were
individually uncorrelated, making the experimental conditions similar to those of
Jeffress et al., but the stimuli in the present experiment had some interaural
correlation, even at NF=1 because the temporal envelopes in each band matched. The
listeners showed some lateralization ability even when the NF was 1, suggesting
sensitivity to envelope ITDs. With current processing schemes, using acoustic
presentations and unsynchronized bilateral processors, implant users can detect
envelope ITDs as demonstrated with click trains (Laback et al. 2004). This suggests
that lateralization in implantees based on ITDs is possible and increased delivery of
fine structure would enhance the utility of ITD cues. For those implanted
bilaterally, the place of current delivery for a specific frequency might be
mismatched between the two ears, possibly resulting in decreased coincident detection
in the medial superior olive (Jeffress 1948, 1958). To date, commercial cochlear
implants are not synchronized bilaterally, so there is a potential for bilateral
drift of ITDs based on the slight variations in the pulse rates between implants.
However, the problem is alleviated with higher pulse rates, e.g., above about 2,000
pps because the ITDs of individual pulses are not discernable. Also, if an individual
were deaf during a critical period in development, the binaural hearing system might
not have developed normally. Nevertheless, sensitivity to ITDs was demonstrated in
implantees (Long et al. 2003; Van Hoesel and Tyler 2003; Laback et al. 2004) and,
given the dominance of fine structure for lateralization in normal-hearing listeners,
improving the delivery of fine structure could greatly enhance the utility of ITD
information in bilateral implantees. m For the case in which ITD=0 s, the effect of
randomization of fine structure was much greater in babble than in speech-shaped
noise (Figs. 4 and 5). In babble, improved spectral and temporal information would
enhance the ability of listeners to segregate the male and female voices based on
fundamental frequency (F0) (Brokx and Nooteboom 1982; Assmann and Summerfield 1990;
Culling and Darwin 1993; Bird and Darwin 1998; Qin and Oxenham 2005). Hearing the
individual F0s of each voice requires good spectral resolution and accurate
perception of the temporal fine structure, which contributes to the perception of
periodicity pitch for the low-frequency, resolved harmonics (Plomp 1967; Houtsma and
Smurzynski 1990; Meddis and _ O Mard 1997). Voices can be segregated based on the
pitch manifested from the encoding of temporal fine structure (Qin and Oxenham 2003;
Kong et al. 2005; Qin and Oxenham 2006). The effect of fine structure was less in
speech-shaped noise because there was no pitch-basis to segregate the target speech
from the background. Thus, fine-structure randomization appeared to significantly
reduce the ability to segregate based on F0. Normal-hearing listeners benefit both
from increased spectral and temporal information with<component x="329.04" y="48.12"
width="233.17" height="666.99" page="7" page_width="593.97"
page_height="792.0"></component><component x="31.86" y="574.11" width="233.11"
height="141.0" page="8" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.06" year_ratio="0.0"
cap_ratio="0.1" name_ratio="0.25555555555555554" word_count="90"
lateness="0.7272727272727273" reference_score="10.15">increased fine structure, but
we would not expect the extent of spectral information to increase as dramatically in
cochlear implant users because nerve survival and current spread are likely to limit
the number of channels that can be resolved. Previous studies have demonstrated a
limit in the spectral processing capability of cochlear implantees to about nine
channels (e.g., Fishman et al. 1997; Dorman et al. 1998; Friesen et al. 2001).
Whereas decreases in SRT with ITD=0 could result from temporal and spectral
degradation, decreases in binaural unmasking with increased fine-structure<component
x="288.85" y="574.12" width="233.16" height="141.0" page="8" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="7.64" font="NIEOKG+Helvetica" letter_ratio="0.56"
year_ratio="0.0" cap_ratio="0.0" name_ratio="0" word_count="5"
lateness="0.8181818181818182" reference_score="5.8">8 6 4 2 0<component x="94.51"
y="695.64" width="4.6" height="7.64" page="9" page_width="593.97"
page_height="792.0"></component><component x="94.51" y="667.87" width="4.6"
height="7.64" page="9" page_width="593.97" page_height="792.0"></component><component
x="94.51" y="640.1" width="4.6" height="7.64" page="9" page_width="593.97"
page_height="792.0"></component><component x="94.51" y="612.34" width="4.6"
height="7.64" page="9" page_width="593.97" page_height="792.0"></component><component
x="94.51" y="584.57" width="4.6" height="7.64" page="9" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="5.1" font="NIEOKG+Helvetica" letter_ratio="0.29"
year_ratio="0.0" cap_ratio="1.0" name_ratio="0.16666666666666666" word_count="6"
lateness="0.8181818181818182" reference_score="10.88">Steady Noise Babble BILD =
0<component x="247.64" y="669.77" width="32.77" height="19.91" page="9"
page_width="593.97" page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.06" year_ratio="0.0"
cap_ratio="0.1" name_ratio="0.24364406779661016" word_count="472"
lateness="0.9090909090909091" reference_score="11.86">The present study compared SRTs
between steadystate background and babble in which the babble was the same on every
trial. The purpose of using the same noise background was to maintain consistency in
the difficulty of the background noise. Trial-to-trial changes in the background
noises would add a source of variance to the measurement of the SRT that was
undesirable. With the babble background, however, listeners could learn to listen in
the gaps. In the high NF condition in babble, there was about 6 dB of improvement, on
average, in SRT over time. The NF=1 condition was similar to previous studies (Qin
and Oxenham 2003; Stickney et al. 2004), which used multichannel, noise-excited
vocoders, with no binaural cues. Qin and Oxenham demonstrated that SRTs were better
for steady noise than for the singletalker background noise, and Stickney et al.
demonstrated similar, and sometimes better performance with the steady background.
Our study showed slightly better performance (although not significant) for the
babble background than for steadystate background. The use of the same background
noise on each trial could account for the differences, as these two previous studies
used a speech masker, which differed on each trial. Also, we used two-talker babble,
whereas Qin and Oxenham and Stickney et al. used one-talker background noise. The
number of talkers can have a big effect on the extent of masking (Miller 1947). In
addition, our listeners used a closed set speech test whereas the other studies used
open set. Finally, our study used a Hilbert vocoder, but the other studies used a
rectification-and-low-pass-filter approach. All of these factors could contribute to
differences among studies. The results suggested that improved delivery of temporal
fine structure using a cochlear implant could improve the ability of implantees to
localize by providing improved ITD encoding, and improve the ability of implantees to
segregate speech from noise. Implantees have previously been shown to have more
difficulty understanding spondees in babble versus steady backgrounds (Turner et al.
2004), but our recent (unpublished) results with 20 implant listeners have shown SRTs
in babble and steady-state noise are about the _ same (mean SRT in babble 5.6 dB and
mean SRT in _ steady-state, speech-shaped noise 6.6 dB). The best _ performance for
an implantee in steady noise was 15 dB, corresponding to normal-hearing performance
in Figure 5 at NF equal to about 0.85. This suggests that in steady noise better
implant users receive some finestructure information. Improvement in the delivery of
fine-structure information would be expected to enhance performance. Rubinstein et
al. (1999) has proposed an approach for improving temporal encoding, which was shown
neurophysiologically to yield responses that more closely resemble normal-hearing
than those generated from traditional processing schemes (Litvak et al. 2003). The
procedures described herein could be useful in evaluating strategies for improving
temporal delivery in any cochlear implant device.<component x="329.05" y="48.12"
width="233.21" height="666.99" page="9" page_width="593.97"
page_height="792.0"></component><component x="31.86" y="657.79" width="233.1"
height="57.32" page="10" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="8.53" font="AdvP83FD" letter_ratio="0.16" year_ratio="0.0"
cap_ratio="0.48" name_ratio="0.3670886075949367" word_count="79"
lateness="0.9090909090909091" reference_score="20.16">The authors are grateful for
the dedicated efforts of our listeners. We thank Chad Ruffin for assistance in the
creation of Figure 1. Leah Drennan and two anonymous reviewers provided helpful
comments on previous versions of this manuscript. JHW appreciates the mentorship of
SM Lee and SH Hong. This work was supported by NIH grants R01-DC007525, a subcontract
of P50-DC00242, T32DC00018 (VKD), the University of Washington, and grants from the
Korean Science and Engineering Foundation, and Hanyang University (JHW).<component
x="31.86" y="503.35" width="233.13" height="107.17" page="10" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="7.58" font="AdvP83FD" letter_ratio="0.32" year_ratio="0.02"
cap_ratio="0.88" name_ratio="0.12727272727272726" word_count="1155" lateness="1.0"
reference_score="17.37">SSMANN UMMERFIELD A PF, S Q. Modeling the perception of
concurrent vowels: vowels with different fundamental frequencies. J. Acoust. Soc. Am.
88:680-697, 1990. EST CHAIK V ARLILE B V, S A , C S. Separation of concurrent
broadband sound sources by human listeners. J. Acoust. Soc. Am. 115:324- 336, 2004.
ILGER UETZEL ABINOWITZ ZECZKOWSKI B RC, N JM, R WM, R C. Standardization of a test of
speech perception in noise. J. Speech Hear. Res. 27:32-48, 1984. IRD ARWIN B J, D CJ.
Effects of a difference in fundamental frequency in separating two sentences. In:
Palmer AR, Rees A, Summerfield AQ and Meddis R (eds) Psychophysical and Physiological
Advances in Hearing. London, Whurr, pp. 263-269, 1998. ROKX OOTEBOOM B JPL, N SG.
Intonation and the perceptual separation of simultaneous voices. J. Phon. 10:23-36,
1982. RONKHORST LOMP B AW, P R. The effect of head-induced interaural time and level
differences on speech intelligibility in noise. J. Acoust. Soc. Am. 83:1508-1516,
1988. ARHART ILLMAN OHNSON C R, T TW, J KR. Release of masking for speech through
interaural time delay. J. Acoust. Soc. Am. 42:124-138, 1967. ULLING ARWIN C JF, D CJ.
Perceptual separation of simultaneous vowels: within and across-formant grouping by
F0. J. Acoust. Soc. Am. 93:3454-3467, 1993. ULLING AWLEY ITOVSKY C JF, H ML, L RY.
The role of head-induced interaural time and level differences in the speech
reception threshold for multiple interfering sound sources. J. Acoust. Soc. Am.
116:1057-1065, 2004. ORMAN OIZOU ITZKE U D MF, L PC, F J, T Z. The recognition of
sentences in noise by normal-hearing listeners using simulations of cochlear-implant
signal processors with 6-20 channels. J. Acoust. Soc. Am. 104:3583-3585, 1998. RENNAN
ATEHOUSE EVER D WR, G S, L C. Perceptual segregation of competing speech sounds: the
role of spatial location. J. Acoust. Soc. Am. 114:2178-2189, 2003. F ISHMAN HANNON
LATTERY K, S RV, S WH. Speech recognition as a function of the number of electrodes
used in the SPEAK cochlear implant speech processor. J. Speech Hear. Res. 32:524-535,
1997. RIESEN HANNON ASKENT ANG F LM, S RV, B D, W X. Speech recognition in noise as a
function of the number of spectral channels: comparison of acoustic hearing and
cochlear implants. J. Acoust. Soc. Am. 110:1150-1163, 2001. OOD ILKEY G MD, G RH.
Sound localization in noise. The effect of signal-to-noise ratio. J. Acoust. Soc. Am.
99:1108-1117, 1996. ARRIS H RW. Speech audiometry materials compact disk. Provo, UT,
Brigham Young University, pp. 1991. ENNING H GB. Detectability of interaural delay in
high-frequency complex waveforms. J. Acoust. Soc. Am. 55:1974. OUTSMA MURZYNSKI H
AJM, S J. Pitch identification and discrimination for complex tones with many
harmonics. J. Acoust. Soc. Am. 87:304-310, 1990. EFFRESS J LA. A place theory of
sound localization. J. Comp. Physiol. Psychol. 41:35-39, 1948. EFFRESS J LA. Medial
geniculate body-a disavowal. J. Acoust. Soc. Am. 30:802-803, 1958. EFFRESS LODGETT
EATHERAGE J LA, B HC, D BH. Effect of interaural correlation on the precision of
centering a noise. J. Acoust. Soc. Am. 34:1122-1123, 1962. LUMPP ADY K RG, E HR. Some
measurements of interaural time difference thresholds. J. Acoust. Soc. Am.
28:859-860, 1956. ONG TICKNEY ENG K Y-Y, S GS, Z F-G. Speech and melody recognition
in binaurally combined acoustic and electric hearing. J. Acoust. Soc. Am.
117:1351-1361, 2005. ABACK OK AUMGARTNER EUTSCH CHMID L B, P S-M, B W-D, D WA, S K.
Sensitivity to interaural level and envelope differences of two bilateral cochlear
implant listeners using clinical sound processors. Ear Hear. 25:488-500, 2004. ITVAK
ELGUTTE DDINGTON L L, D B, E D. Improved neural representation of vowels in electric
stimulation using desynchronizing pulse trains. J. Acoust. Soc. Am. 114:2099-2111,
2003. ONG ARLYON ITOVSKY OWNS L CJ, C RP, L RY, D DH. Binaural unmasking with
bilateral cochlear implants. J. Assoc. Res. Otolaryngol. 7:352-360, 2006. ONG
DDINGTON OLBURN ABINOWITZ L CJ, E DK, C HS, R WM. Binaural sensitivity as a function
of interaural electrode position with a bilateral cochlear implant user. J. Acoust.
Soc. Am. 114:1565- 1574, 2003. C ADDEN ASANEN M F D, P EG. Lateralization at high
frequencies based on interaural time differences. J. Acoust. Soc. Am. 59:634-639,
1976. _ EDDIS ARD M R, O M L. A unitary model of pitch perception. J. Acoust. Soc.
Am. 102:1811-1820, 1997. ILLER M GA. The masking of speech. Psychol. Bull.
44:105-129, 1947. LOMP R. Pitch of complex tones. J. Acoust. Soc. Am. 41:1526-1533, P
1967. IN XENHAM Q MK, O AJ. Effects of simulated cochlear-implant processing on
speech reception in fluctuating maskers. J. Acoust. Soc. Am. 114:446-454, 2003. IN
XENHAM Q MK, O AJ. Effects of envelope-vocoder processing on F0 discrimination and
concurrent-vowel identification. Ear Hear. 26:451-460, 2005. IN XENHAM Q MK, O AJ.
Effects of introducing unprocessed lowfrequency information on the reception of
envelope-vocoder processed speech. J. Acoust. Soc. Am. 119:2417-2426, 2006. AYLEIGH R
L. On our perception of sound direction. Philos. Mag. 74:214-231, 1907. UBINSTEIN
URNER R JT, T CW. A novel acoustic simulation of cochlear implant hearing: effects of
temporal fine structure. First International IEEE EMBS Conference on Neural
Engineering, IEEE Press, 142-145, 2003. R UBINSTEIN ILSON INLEY BBAS JT, W BS, F CC,
A PJ. Pseudospontaneous activity: stochastic independence of auditory nerve fibers
with electrical stimulation. Hear. Res. 127:108-118, 1999. HANNON ENG AMATH YGONSKI
KELID S RV, Z F-G, K V, W J, E M. Speech recognition with primarily temporal cues.
Science 270:303-304, 1995. MITH ELGUTTE XENHAM S ZM, D B, O AJ. Chimaeric sounds
reveal dichotomies in auditory perception. Nature 416:87-90, 2002. TICKNEY ENG
ITOVSKY SSMANN S GS, Z F-G, L R, A P. Cochlear implant speech recognition with speech
maskers. J. Acoust. Soc. Am. 116:1081-1091, 2004. OBIAS CHUBERT T JV, S ED. Effective
onset duration of auditory stimuli. J. Acoust. Soc. Am. 31:1595-1605, 1959. URNER
ANTZ IDAL EHRENS ENRY T CW, G BJ, V C, B A, H BA. Speech recognition in noise for
cochlear implant listeners: Benefits of residual acoustic hearing. J. Acoust. Soc.
Am. 115:1729-1735, 2004. V AN DE AR OHLRAUSCH P S, K A. A new approach to comparing
binaural masking level differences at low and high frequencies. J. Acoust. Soc. Am.
101:1671-1680, 1997. AN OESEL YLER V H RJM, T RS. Speech perception, localization and
lateralization with bilateral cochlear implants. J. Acoust. Soc. Am. 113:1617-1630,
2003. IGHTMAN ISTLER W FL, K DJ. The dominant role of low frequency interaural time
differences in sound localization. J. Acoust. Soc. Am. 91:1648-1661, 1992. ON RENNAN
UBINSTEIN W JH, D W, R J. Spectral ripple resolution and speech perception in babble
and speech-shaped noise by cochlear implant listeners. Presented at the 30th annual
midwinter meeting of the Association for Research in Otolaryngology, vol. 30, pp.
304, 2007. U FINGST X L, P BE. Relative importance of temporal envelope and fine
structure in lexical-tone perception. J. Acoust. Soc. Am. 114:3024-3027, 2003. Y OST
IGHTMAN REEN WA, W FL, G DM. Lateralization of filtered clicks. J. Acoust. Soc. Am.
39:1526-1531, 1971.<component x="31.86" y="69.97" width="233.19" height="386.12"
page="10" page_width="593.97" page_height="792.0"></component><component x="288.85"
y="69.91" width="233.24" height="645.15" page="10" page_width="593.97"
page_height="792.0"></component><component x="72.0" y="558.72" width="233.2"
height="157.02" page="11" page_width="593.97"
page_height="792.0"></component><component x="329.04" y="558.72" width="233.17"
height="157.02" page="11" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.07" year_ratio="0.0"
cap_ratio="0.11" name_ratio="0.19617224880382775" word_count="209"
lateness="0.09090909090909091" reference_score="6.42">This study evaluated the role
of temporal fine structure in the lateralization and understanding of speech in six
normal-hearing listeners. Interaural time differences (ITDs) were introduced to
invoke lateralization. Speech reception thresholds (SRTs) were evaluated in
backgrounds of two-talker babble and speech-shaped noise. Two-syllable words with m
ITDs of 0 and 700 s were used as targets. A vocoder technique, which systematically
randomized fine structure, was used to evaluate the effects of fine structure on
these tasks. Randomization of temporal fine structure was found to significantly
reduce the ability of normal-hearing listeners to lateralize words, although for many
listeners, good lateralization performance was achieved with as much as 80%
fine-structure randomization. Most listeners demonstrated some rudimentary ability to
lateralize with 100% fine-structure randomization. When ITDs were m 0 s,
randomization of fine structure had a much greater effect on SRT in two-talker babble
than in speech-shaped noise. Binaural advantages were also observed. In steady noise,
the difference in SRT m between words with 0- vs 700- s ITDs was, on average, 6 dB
with no fine-structure randomization and 2 dB with 100% fine-structure randomization.
In two-talker babble this difference was 1.9 dB and, for most listeners, showed
little effect of the degree of finestructure randomization. These results suggest
that<component x="72.0" y="110.37" width="233.17" height="332.22" page="1"
page_width="593.97" page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.06" year_ratio="0.0"
cap_ratio="0.08" name_ratio="0.16216216216216217" word_count="37"
lateness="0.09090909090909091" reference_score="5.66">(1) improved delivery of
temporal fine structure would improve speech understanding in noise for implant
recipients, (2) bilateral implant recipients might benefit from temporal envelope
ITDs, and (3) improved delivery of temporal information could improve binaural
benefits.<component x="329.04" y="397.29" width="233.08" height="69.23" page="1"
page_width="593.97" page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.08" year_ratio="0.0"
cap_ratio="0.12" name_ratio="0.2398921832884097" word_count="371"
lateness="0.18181818181818182" reference_score="7.27">Interaural time differences
(ITDs) contribute to important real-world tasks such as localization ability
(Rayleigh 1907; Wightman and Kistler 1992) and binaural unmasking (Carhart et al.
1967; Bronkhorst and Plomp 1988; Culling et al. 2004). Real environmental sounds
provide ITDs with both envelope and G fine structure. At low frequencies ( 1.5 kHz)
for stimuli longer than 100 ms, fine-structure ITDs dominate perception (Tobias and
Schubert 1959); however, both envelope and fine-structure ITDs contribute to
lateralization ability (Klumpp and Eady 1956; Yost et al. 1971; Henning 1974;
McFadden and Pasanen 1976; Van de Par and Kohlrausch 1997), binaural unmasking (Van
de Par and Kohlrausch 1997; Long et al. 2006), and segregation ability (Drennan et
al. 2003; Best et al. 2004). Common cochlear implant sound processing strategies do
not explicitly encode temporal fine-structure information, but only the envelope
information. While some fine-structure information for low frequencies is passed
through the temporal envelope, most temporal fine-structure information is lost in
processing. Previous observations that envelope ITDs contribute to lateralization and
segregation in normal-hearing listeners is beneficial for bilateral implantees
because this means it would be theoretically possible for implantees to glean some
benefit from interaural timing differences. Temporal fine structure is also known to
provide information, which help normal-hearing humans perceive music (Smith et al.
2002), speech in noise (Kong et al. 2005), and tonal languages (Xu and Pfingst 2003).
Hence, improved delivery of temporal fine structure should help monaural and binaural
implantees. This study evaluates the role of fine structure in practical tasks such
as the lateralization of speech and speech understanding in noise. A key motivation
is to better understand how improved delivery of fine structure could improve hearing
in implantees. Insights into the role of fine structure in practical hearing tasks
could lead to improvements in cochlear implant sound processing. In this study, we
presented vocoder-processed sounds to normal-hearing listeners. The vocoder divided
the signal into six band-pass channels. A signal processing technique enabled graded
randomization of the fine structure, but preserved the temporal envelope of the
waveforms. The procedure offers the unique capability to systematically vary the
extent of the randomization of the fine structure to quantify the effect of temporal
fine structure on human auditory processing capabilities. This study<component
x="329.04" y="48.18" width="233.16" height="248.6" page="1" page_width="593.97"
page_height="792.0"></component><component x="31.86" y="347.01" width="233.14"
height="368.11" page="2" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.04" year_ratio="0.0"
cap_ratio="0.0" name_ratio="0.2631578947368421" word_count="38"
lateness="0.18181818181818182" reference_score="3.93">served two purposes, one
scientific and one clinical: (1) to determine the extent to which temporal fine
structure contributes to lateralization and speech understanding in noise, and (2) to
evaluate how improved fine-structure delivery might improve these
capabilities.<component x="288.85" y="645.83" width="233.13" height="69.28" page="2"
page_width="593.97" page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.12" year_ratio="0.01"
cap_ratio="0.16" name_ratio="0.19875776397515527" word_count="161"
lateness="0.18181818181818182" reference_score="11.3">Bilateral cochlear implant
simulations were presented to normal-hearing listeners who had thresholds of less
than 25 dB HL at all audiometric frequencies. Six listeners participated in the
study. The stimuli were presented over TDH-50P headphones via a Macintosh G4 laptop
in a quiet room. _ Speech levels were calibrated at 65 dBA. Listeners ages ranged
from 26-38 with a mean of 32.3 years. They included two women and four men who
volunteered their time for the study. The study was approved by the University of
Washington Institutional Review Board. A diagram of the fine-structure randomization
procedure is shown in Figure 1. The stimulus, X(t), was passed through a bank of 6
band-pass FIR filters. The filters covered the logarithmically spaced frequency
ranges of 80-308, 308-788, 788-1794, 1794- 3906, 3906-8338, and 8,338-17,640 Hz. A
Hilbert transform was used to extract the envelope and fine structure of each filter.
A random component was added to the Hilbert phase and then was weighted by<component
x="288.85" y="347.0" width="233.17" height="248.55" page="2" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.08" year_ratio="0.01"
cap_ratio="0.14" name_ratio="0.2972972972972973" word_count="148"
lateness="0.2727272727272727" reference_score="9.32">a noise factor, NF, which varied
from 0 to 1. The NF represents the extent of randomization of the fine structure such
that NF=1 was 100% fine-structure randomization and NF=0 was only filtered, keeping
the fine structure identical to the original signal. This NF concept was first
introduced by Rubinstein and Turner (2003). In signal processing terms, the NF
determined the extent of randomization of the Hilbert phase from 0 to 100%. A
sequence of identically distributed uniform random variables p from 0 to 1, r (t),
was multiplied by 2 times the NF i and added to the Hilbert phase of the original
stimulus (see Eq. 1). The randomized fine structure was filtered by B (t), and the
output was multiplied by i the Hilbert envelope of the original stimulus. This
procedure is represented analytically by the following equation operating on the
output of a single channel:<component x="72.0" y="502.4" width="233.16"
height="212.72" page="3" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.08" year_ratio="0.0"
cap_ratio="0.12" name_ratio="0.24263431542461006" word_count="577"
lateness="0.36363636363636365" reference_score="8.46">in which y (t) is the output
stimulus, x (t) is the filtered i i stimulus, H(x (t)) is the Hilbert transform, B
(t) is the i i B ^ impulse response of the ith band pass filter, * indicates
convolution, r (t) is a sequence of uniformly i distributed random variables from 0
to 1, and n is the NF. All six channels are summed to create the output signal Y(t).
Randomization of phase was independent for the two ears and for each band. Using this
approach, psychophysical abilities were evaluated as a function of the NFs ranging
from 0 (no randomization, i.e., the original stimulus filtered) to 1 (complete
randomization equivalent to a traditional 6-channel, vocoder-type, noise-band
cochlear implant simulation, e.g., Shannon et al. 1995). In experiments with
background noise, ITDs were introduced to the signal before NF processing. The sum of
the signal and noise (X(t)) was then processed using Eq. 1. The process of
introducing fine-structure randomization and refiltering could alter the envelope. B
^ When comparing the target envelope before processing and the output envelope for
single pass bands, the correlations were 0.98-0.99. Thus, the effect of
fine-structure randomization on the envelope was slight. Lateralization B B ^ ^ Two
spondees, padlock and stairway, were chosen, because they had robust low-frequency
energy. A 6 4 repeated-measures design was used with 6 NFs( and 4 repetitions. The
spondees were presented to listeners using NFs of 0, 0.5, 0.7, 0.8, 0.9, and 1. The
Binaural intelligibility level difference The binaural intelligibility level
difference (BILD) refers to an intelligibility advantage a listener can obtain when
listening to speech in noise if the binaural timing or phase of the speech differs
from that of the noise (Bronkhorst and Plomp 1988). A speech reception threshold
(SRT) is the signal to noise ratio (S/N) at which speech is intelligible. In this
case, S/N for the 50% intelligibility level (the SRT) was determined for speech in
two conditions in which the ITDs of the speech differed. Binaural intelligibility
level differences were calculated by determining the difference between the SRT for m
spondees with 0 and 700- s ITDs. This was done four times with two types of
background noise, steadystate, speech-shaped noise, and two-talker babble ( ( with a
variety of NFs. The final analysis was 4 2 5 using 4 repetitions, 2 types of noise
background, and 5 NFs. On each trial, normal-hearing listeners identified 1 of 12
equally difficult spondees (Harris 1991) presented in one of the two noise
backgrounds. The babble consisted of one male and one female talker using a sentence
from the SPIN test (Bilger et al. 1984). The target spondees were all spoken by a
female talker, different from the female talker in the babble. To minimize variance
that might result from variable difficulty by using different babble backgrounds on
each trial, i.e., to get the least noisy measure of SRT in the babble, the same
babble background was used on every trial. The male talker B ^ spoke the sentence
Name two uses for ice, and the B female talker spoke the sentence Bill might discuss
^ the foam. The target speech (the spondee) was delayed from the onset of the babble
by 500 ms. In the steady noise background, the same noise was used on every trial,
and the spondees were delayed by 500 ms relative to the start of the noise. Both the
target and noise were processed with fine-structure<component x="72.0" y="144.67"
width="233.22" height="284.49" page="3" page_width="593.97"
page_height="792.0"></component><component x="72.0" y="48.17" width="233.14"
height="76.58" page="3" page_width="593.97"
page_height="792.0"></component><component x="329.04" y="48.12" width="233.13"
height="315.71" page="3" page_width="593.97"
page_height="792.0"></component><component x="31.86" y="562.15" width="233.11"
height="152.96" page="4" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.11" year_ratio="0.0"
cap_ratio="0.14" name_ratio="0.1574074074074074" word_count="108"
lateness="0.36363636363636365" reference_score="9.63">(Hilbert phase) randomization,
independently processed for the two ears. The spondees were presented m with ITDs of
0 or 700 s. Noise factors were 0, 0.5, 0.75, 0.875, and 1. A one-down, one-up
adaptive tracking procedure was used in which noise levels were tracked in 2-dB
increments to determine an SRT representing 50% correct. In the NF=0 condition using
babble background, the S/N ratio _ dropped below 40 dB. In this case, the listeners
were permitted to lower the overall level about 5 dB because background noise was
quite loud. The 12spondee closed set discrimination task and tracking procedure were
the same as used by Turner et al.<component x="288.85" y="562.15" width="233.16"
height="152.96" page="4" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.09" year_ratio="0.01"
cap_ratio="0.17" name_ratio="0.1953125" word_count="256"
lateness="0.45454545454545453" reference_score="12.78">(2004). One run consisted of
14 reversals in which the threshold was the mean of the last 10 reversals. Four
tracking histories were completed for each condition. The order of presentation was
randomized in the following way: one of the NFs was selected randomly, then listeners
completed all four runs (two in babble and two in steady noise, with ITDs=0 and m 700
s) presented in a random order using that specific NF. Then, a different NF was
selected randomly, and listeners completed the four conditions (two noise backgrounds
and two ITDs) in a newly randomized order. This procedure continued until all
conditions were finished. Each listener had a different randomized order of
presentation for both the NFs and the four conditions run with each NF. Listeners
completed all NF conditions for the first repetition before moving on to the second
repetition. RESULTS Lateralization Figure 2 shows the individual lateralization
results as a function of the NF. Figure 3 shows the mean lateralization results.
Error bars in all figures show ( the 95% confidence interval. A 6 4 repeated measures
ANOVA (6 NFs and 4 repetition times) demonstrated that, as expected, there was a
signifiG cant effect of NF (F =17.831, p 0.0005). There was 5,25 no effect of
repetition time demonstrating there was 2 no learning trend in this task. The mean r
for lateralization was above chance for NF=1 (p =0.0093), with 100% fine-structure
randomization, suggesting that most listeners could lateralize without finestructure
ITD information. This is consistent with previous observations that normal-hearing
listeners<component x="72.0" y="514.36" width="233.14" height="200.75" page="5"
page_width="593.97" page_height="792.0"></component><component x="72.0" y="287.19"
width="233.14" height="202.24" page="5" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.12" year_ratio="0.01"
cap_ratio="0.17" name_ratio="0.21568627450980393" word_count="459"
lateness="0.45454545454545453" reference_score="12.7">can detect the ITD of the
envelope alone (McFadden and Pasanen 1976). There were also substantial variations
among listeners when 50% or more of the fine structure was randomized. A few
listeners (L1 and L4) were only slightly affected by 50% finestructure randomization,
whereas others (L3, L5, L6, and L7) were greatly affected by this randomization.
Speech understanding Figure 4 shows individual data from the speech-in-noise m
experiments in which the ITD=0 s. Figure 5 shows ( ( mean data. A 2 5 4
repeated-measures ANOVA (2 noise backgrounds, 5 NFs, and 4 repetition times)
demonstrated that there was a main effect of the NF G (F =126.5, p 0.0005), an
interaction between NF 4,20 G and noise background (F =34.308), p 0.0005), and a 4,20
main effect of the noise background (F =96.306, 1,4 G p 0.0005). The main effect of
noise background demonstrated that speech understanding in babble was usually better
than speech understanding in speech-shaped noise. The interaction demonstrated that
fine-structure randomization improved SRTs much more in babble than in steady-state
noise. As reflected in the interaction, the difference in SRT between the two
background noises was not significant when the NF was 1 (100% fine-structure
randomization). We note that in babble, the thresholds for NF=0 _ _ were extremely
low, in the range of 35 to 40 dB S/N. These results were slightly lower than those of
Turner _ et al. (2004) who found 30 dB for a similar condition. The primary
difference between studies was that the present study used more reversals and more
repetitions to determine a threshold. Also, different groups of listeners could have
different capabilities. m For ITD=0 s, there was a main effect of repetition G number
(F =7.951, p 0.002); an interaction be3,15 tween repetition number and noise
background G (F =5.222, p 0.011); a weak interaction between 3,15 G repetition and NF
(F =1.914, p 0.05); and a three12,60 way interaction among repetition time, NF, and
noise G background (F =2.280, p 0.018). The effects of 12,60 repetition time
indicated that there was some improvement over time in the SRT; however, the
interactions suggest that this improvement over time was limited to higher NFs in the
babble background. For NFs of 0.75, 0.875, and 1 in the babble background, SRTs
improved by about 6 dB from the first to the fourth time of testing, suggesting that
for the spondees presented in babble, the listeners learned to make use of envelope
cues without fine structure or learned how to listen in the silent gaps. In all the
other conditions, for speech-shaped noise with all NFs and for two-talker babble
backgrounds with NF=0 or 0.5, there was little effect of repetition time. We also
found similar learning trends in real<component x="329.04" y="633.92" width="233.12"
height="81.19" page="5" page_width="593.97"
page_height="792.0"></component><component x="329.04" y="48.12" width="233.23"
height="566.75" page="5" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.13" year_ratio="0.0"
cap_ratio="0.42" name_ratio="0.2247191011235955" word_count="89"
lateness="0.5454545454545454" reference_score="16.43">cochlear implantees using the
same methods for evaluation of SRTs (Won et al. 2007, submitted). Binaural
intelligibility level difference Figure 6 shows individual BILDs based on ITDs for
spondees in babble and speech-shaped noise as a function of the NF. The BILD is
calculated by m subtracting the SRT for ITD=700 s from the SRT m for ITD=0 s. Figure
7 shows mean BILD data. The result shows the extent to which fine structure
contributes to ITD-only binaural advantages in nor( ( mal-hearing listeners. A 2 5 4
repeated-measures<component x="31.86" y="179.76" width="233.05" height="21.44"
page="6" page_width="593.97" page_height="792.0"></component><component x="31.86"
y="48.29" width="233.1" height="112.47" page="6" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.1" year_ratio="0.0"
cap_ratio="0.19" name_ratio="0.2320675105485232" word_count="237"
lateness="0.6363636363636364" reference_score="12.25">ANOVA (2 noise backgrounds, 5
NFs, and 4 repetition times) was conducted. A main effect of noise G background (F
=13.799, p 0.014) and a main effect 1,5 G of NF (F =5.441, p 0.004) were observed.
All other 4,20 effects, including the effect of repetition time and associated
interactions, were not significant. This lack of interaction of the BILD with the
main factor of repetition time suggested that any learning that occurred was
statistically equivalent for 0- and 700m s ITDs. Binaural intelligibility level
differences were generally larger in speech-shaped noise than in a babble background,
which was shown by the main effect of noise background. Binaural intelligibility
level differences decrease as the amount of fine structure decreases (i.e., as the NF
increases), demonstrated by the main effect of NF. The BILD for NF=0 in speech-shaped
noise was about 6 dB on average, consistent with previous observations (e.g., Carhart
et al. 1967; Bronkhorst and Plomp 1988). In two-talker babble, the effect of fine
structure on the BILD was highly variable among listeners and did not appear to
change much as fine-structure randomization increased, averaging about 1.9 dB across
all NFs. Binaural intelligibility level differences for speechshaped noise were more
consistent among listeners and declined monotonically from about 6 dB for NF=0 to 1.1
dB for NF=1. Thus, the effect of fine structure for binaural cues appeared to be
greater in speech-shaped noise than in two-talker babble.<component x="288.85"
y="48.29" width="233.16" height="152.91" page="6" page_width="593.97"
page_height="792.0"></component><component x="72.0" y="526.32" width="233.13"
height="188.79" page="7" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.05" year_ratio="0.0"
cap_ratio="0.06" name_ratio="0.20388349514563106" word_count="103"
lateness="0.6363636363636364" reference_score="8.65">In the first experiment,
lateralization became more difficult with increased fine-structure randomization
(Figs. 2 and 3). The results demonstrated the dominance of fine structure (relative
to envelope) in lateralization based on ITDs. There was some lateralization ability
even with 100% fine-structure randomization, but performance was greatly enhanced by
fine structure. The result might also underestimate the effect of fine structure
because the interaural level differences were 0, which could push the percept toward
center, although center bias 2 was only apparent in the high-NF conditions when r
values were low. The results from the listeners least affected by finestructure
randomization paralleled results from<component x="72.0" y="299.15" width="233.15"
height="176.83" page="7" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.08" year_ratio="0.0"
cap_ratio="0.14" name_ratio="0.2544731610337972" word_count="503"
lateness="0.7272727272727273" reference_score="11.48">Jeffress et al. (1962) in which
listeners centered noises by adjusting the ITD of noises at the two ears. They found
that listeners could center a noise image well when the interaural correlation was as
low as 0.2. The fine structure of the noise bands in the present experiment were
individually uncorrelated, making the experimental conditions similar to those of
Jeffress et al., but the stimuli in the present experiment had some interaural
correlation, even at NF=1 because the temporal envelopes in each band matched. The
listeners showed some lateralization ability even when the NF was 1, suggesting
sensitivity to envelope ITDs. With current processing schemes, using acoustic
presentations and unsynchronized bilateral processors, implant users can detect
envelope ITDs as demonstrated with click trains (Laback et al. 2004). This suggests
that lateralization in implantees based on ITDs is possible and increased delivery of
fine structure would enhance the utility of ITD cues. For those implanted
bilaterally, the place of current delivery for a specific frequency might be
mismatched between the two ears, possibly resulting in decreased coincident detection
in the medial superior olive (Jeffress 1948, 1958). To date, commercial cochlear
implants are not synchronized bilaterally, so there is a potential for bilateral
drift of ITDs based on the slight variations in the pulse rates between implants.
However, the problem is alleviated with higher pulse rates, e.g., above about 2,000
pps because the ITDs of individual pulses are not discernable. Also, if an individual
were deaf during a critical period in development, the binaural hearing system might
not have developed normally. Nevertheless, sensitivity to ITDs was demonstrated in
implantees (Long et al. 2003; Van Hoesel and Tyler 2003; Laback et al. 2004) and,
given the dominance of fine structure for lateralization in normal-hearing listeners,
improving the delivery of fine structure could greatly enhance the utility of ITD
information in bilateral implantees. m For the case in which ITD=0 s, the effect of
randomization of fine structure was much greater in babble than in speech-shaped
noise (Figs. 4 and 5). In babble, improved spectral and temporal information would
enhance the ability of listeners to segregate the male and female voices based on
fundamental frequency (F0) (Brokx and Nooteboom 1982; Assmann and Summerfield 1990;
Culling and Darwin 1993; Bird and Darwin 1998; Qin and Oxenham 2005). Hearing the
individual F0s of each voice requires good spectral resolution and accurate
perception of the temporal fine structure, which contributes to the perception of
periodicity pitch for the low-frequency, resolved harmonics (Plomp 1967; Houtsma and
Smurzynski 1990; Meddis and _ O Mard 1997). Voices can be segregated based on the
pitch manifested from the encoding of temporal fine structure (Qin and Oxenham 2003;
Kong et al. 2005; Qin and Oxenham 2006). The effect of fine structure was less in
speech-shaped noise because there was no pitch-basis to segregate the target speech
from the background. Thus, fine-structure randomization appeared to significantly
reduce the ability to segregate based on F0. Normal-hearing listeners benefit both
from increased spectral and temporal information with<component x="329.04" y="48.12"
width="233.17" height="666.99" page="7" page_width="593.97"
page_height="792.0"></component><component x="31.86" y="574.11" width="233.11"
height="141.0" page="8" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.06" year_ratio="0.0"
cap_ratio="0.1" name_ratio="0.25555555555555554" word_count="90"
lateness="0.7272727272727273" reference_score="10.15">increased fine structure, but
we would not expect the extent of spectral information to increase as dramatically in
cochlear implant users because nerve survival and current spread are likely to limit
the number of channels that can be resolved. Previous studies have demonstrated a
limit in the spectral processing capability of cochlear implantees to about nine
channels (e.g., Fishman et al. 1997; Dorman et al. 1998; Friesen et al. 2001).
Whereas decreases in SRT with ITD=0 could result from temporal and spectral
degradation, decreases in binaural unmasking with increased fine-structure<component
x="288.85" y="574.12" width="233.16" height="141.0" page="8" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="7.64" font="NIEOKG+Helvetica" letter_ratio="0.56"
year_ratio="0.0" cap_ratio="0.0" name_ratio="0" word_count="5"
lateness="0.8181818181818182" reference_score="5.8">8 6 4 2 0<component x="94.51"
y="695.64" width="4.6" height="7.64" page="9" page_width="593.97"
page_height="792.0"></component><component x="94.51" y="667.87" width="4.6"
height="7.64" page="9" page_width="593.97" page_height="792.0"></component><component
x="94.51" y="640.1" width="4.6" height="7.64" page="9" page_width="593.97"
page_height="792.0"></component><component x="94.51" y="612.34" width="4.6"
height="7.64" page="9" page_width="593.97" page_height="792.0"></component><component
x="94.51" y="584.57" width="4.6" height="7.64" page="9" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="5.1" font="NIEOKG+Helvetica" letter_ratio="0.29"
year_ratio="0.0" cap_ratio="1.0" name_ratio="0.16666666666666666" word_count="6"
lateness="0.8181818181818182" reference_score="10.88">Steady Noise Babble BILD =
0<component x="247.64" y="669.77" width="32.77" height="19.91" page="9"
page_width="593.97" page_height="792.0"></component></section>
  <section line_height="9.47" font="AdvP83FD" letter_ratio="0.06" year_ratio="0.0"
cap_ratio="0.1" name_ratio="0.24364406779661016" word_count="472"
lateness="0.9090909090909091" reference_score="11.86">The present study compared SRTs
between steadystate background and babble in which the babble was the same on every
trial. The purpose of using the same noise background was to maintain consistency in
the difficulty of the background noise. Trial-to-trial changes in the background
noises would add a source of variance to the measurement of the SRT that was
undesirable. With the babble background, however, listeners could learn to listen in
the gaps. In the high NF condition in babble, there was about 6 dB of improvement, on
average, in SRT over time. The NF=1 condition was similar to previous studies (Qin
and Oxenham 2003; Stickney et al. 2004), which used multichannel, noise-excited
vocoders, with no binaural cues. Qin and Oxenham demonstrated that SRTs were better
for steady noise than for the singletalker background noise, and Stickney et al.
demonstrated similar, and sometimes better performance with the steady background.
Our study showed slightly better performance (although not significant) for the
babble background than for steadystate background. The use of the same background
noise on each trial could account for the differences, as these two previous studies
used a speech masker, which differed on each trial. Also, we used two-talker babble,
whereas Qin and Oxenham and Stickney et al. used one-talker background noise. The
number of talkers can have a big effect on the extent of masking (Miller 1947). In
addition, our listeners used a closed set speech test whereas the other studies used
open set. Finally, our study used a Hilbert vocoder, but the other studies used a
rectification-and-low-pass-filter approach. All of these factors could contribute to
differences among studies. The results suggested that improved delivery of temporal
fine structure using a cochlear implant could improve the ability of implantees to
localize by providing improved ITD encoding, and improve the ability of implantees to
segregate speech from noise. Implantees have previously been shown to have more
difficulty understanding spondees in babble versus steady backgrounds (Turner et al.
2004), but our recent (unpublished) results with 20 implant listeners have shown SRTs
in babble and steady-state noise are about the _ same (mean SRT in babble 5.6 dB and
mean SRT in _ steady-state, speech-shaped noise 6.6 dB). The best _ performance for
an implantee in steady noise was 15 dB, corresponding to normal-hearing performance
in Figure 5 at NF equal to about 0.85. This suggests that in steady noise better
implant users receive some finestructure information. Improvement in the delivery of
fine-structure information would be expected to enhance performance. Rubinstein et
al. (1999) has proposed an approach for improving temporal encoding, which was shown
neurophysiologically to yield responses that more closely resemble normal-hearing
than those generated from traditional processing schemes (Litvak et al. 2003). The
procedures described herein could be useful in evaluating strategies for improving
temporal delivery in any cochlear implant device.<component x="329.05" y="48.12"
width="233.21" height="666.99" page="9" page_width="593.97"
page_height="792.0"></component><component x="31.86" y="657.79" width="233.1"
height="57.32" page="10" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="8.53" font="AdvP83FD" letter_ratio="0.16" year_ratio="0.0"
cap_ratio="0.48" name_ratio="0.3670886075949367" word_count="79"
lateness="0.9090909090909091" reference_score="20.16">The authors are grateful for
the dedicated efforts of our listeners. We thank Chad Ruffin for assistance in the
creation of Figure 1. Leah Drennan and two anonymous reviewers provided helpful
comments on previous versions of this manuscript. JHW appreciates the mentorship of
SM Lee and SH Hong. This work was supported by NIH grants R01-DC007525, a subcontract
of P50-DC00242, T32DC00018 (VKD), the University of Washington, and grants from the
Korean Science and Engineering Foundation, and Hanyang University (JHW).<component
x="31.86" y="503.35" width="233.13" height="107.17" page="10" page_width="593.97"
page_height="792.0"></component></section>
  <section line_height="7.58" font="AdvP83FD" letter_ratio="0.32" year_ratio="0.02"
cap_ratio="0.88" name_ratio="0.12727272727272726" word_count="1155" lateness="1.0"
reference_score="17.37">SSMANN UMMERFIELD A PF, S Q. Modeling the perception of
concurrent vowels: vowels with different fundamental frequencies. J. Acoust. Soc. Am.
88:680-697, 1990. EST CHAIK V ARLILE B V, S A , C S. Separation of concurrent
broadband sound sources by human listeners. J. Acoust. Soc. Am. 115:324- 336, 2004.
ILGER UETZEL ABINOWITZ ZECZKOWSKI B RC, N JM, R WM, R C. Standardization of a test of
speech perception in noise. J. Speech Hear. Res. 27:32-48, 1984. IRD ARWIN B J, D CJ.
Effects of a difference in fundamental frequency in separating two sentences. In:
Palmer AR, Rees A, Summerfield AQ and Meddis R (eds) Psychophysical and Physiological
Advances in Hearing. London, Whurr, pp. 263-269, 1998. ROKX OOTEBOOM B JPL, N SG.
Intonation and the perceptual separation of simultaneous voices. J. Phon. 10:23-36,
1982. RONKHORST LOMP B AW, P R. The effect of head-induced interaural time and level
differences on speech intelligibility in noise. J. Acoust. Soc. Am. 83:1508-1516,
1988. ARHART ILLMAN OHNSON C R, T TW, J KR. Release of masking for speech through
interaural time delay. J. Acoust. Soc. Am. 42:124-138, 1967. ULLING ARWIN C JF, D CJ.
Perceptual separation of simultaneous vowels: within and across-formant grouping by
F0. J. Acoust. Soc. Am. 93:3454-3467, 1993. ULLING AWLEY ITOVSKY C JF, H ML, L RY.
The role of head-induced interaural time and level differences in the speech
reception threshold for multiple interfering sound sources. J. Acoust. Soc. Am.
116:1057-1065, 2004. ORMAN OIZOU ITZKE U D MF, L PC, F J, T Z. The recognition of
sentences in noise by normal-hearing listeners using simulations of cochlear-implant
signal processors with 6-20 channels. J. Acoust. Soc. Am. 104:3583-3585, 1998. RENNAN
ATEHOUSE EVER D WR, G S, L C. Perceptual segregation of competing speech sounds: the
role of spatial location. J. Acoust. Soc. Am. 114:2178-2189, 2003. F ISHMAN HANNON
LATTERY K, S RV, S WH. Speech recognition as a function of the number of electrodes
used in the SPEAK cochlear implant speech processor. J. Speech Hear. Res. 32:524-535,
1997. RIESEN HANNON ASKENT ANG F LM, S RV, B D, W X. Speech recognition in noise as a
function of the number of spectral channels: comparison of acoustic hearing and
cochlear implants. J. Acoust. Soc. Am. 110:1150-1163, 2001. OOD ILKEY G MD, G RH.
Sound localization in noise. The effect of signal-to-noise ratio. J. Acoust. Soc. Am.
99:1108-1117, 1996. ARRIS H RW. Speech audiometry materials compact disk. Provo, UT,
Brigham Young University, pp. 1991. ENNING H GB. Detectability of interaural delay in
high-frequency complex waveforms. J. Acoust. Soc. Am. 55:1974. OUTSMA MURZYNSKI H
AJM, S J. Pitch identification and discrimination for complex tones with many
harmonics. J. Acoust. Soc. Am. 87:304-310, 1990. EFFRESS J LA. A place theory of
sound localization. J. Comp. Physiol. Psychol. 41:35-39, 1948. EFFRESS J LA. Medial
geniculate body-a disavowal. J. Acoust. Soc. Am. 30:802-803, 1958. EFFRESS LODGETT
EATHERAGE J LA, B HC, D BH. Effect of interaural correlation on the precision of
centering a noise. J. Acoust. Soc. Am. 34:1122-1123, 1962. LUMPP ADY K RG, E HR. Some
measurements of interaural time difference thresholds. J. Acoust. Soc. Am.
28:859-860, 1956. ONG TICKNEY ENG K Y-Y, S GS, Z F-G. Speech and melody recognition
in binaurally combined acoustic and electric hearing. J. Acoust. Soc. Am.
117:1351-1361, 2005. ABACK OK AUMGARTNER EUTSCH CHMID L B, P S-M, B W-D, D WA, S K.
Sensitivity to interaural level and envelope differences of two bilateral cochlear
implant listeners using clinical sound processors. Ear Hear. 25:488-500, 2004. ITVAK
ELGUTTE DDINGTON L L, D B, E D. Improved neural representation of vowels in electric
stimulation using desynchronizing pulse trains. J. Acoust. Soc. Am. 114:2099-2111,
2003. ONG ARLYON ITOVSKY OWNS L CJ, C RP, L RY, D DH. Binaural unmasking with
bilateral cochlear implants. J. Assoc. Res. Otolaryngol. 7:352-360, 2006. ONG
DDINGTON OLBURN ABINOWITZ L CJ, E DK, C HS, R WM. Binaural sensitivity as a function
of interaural electrode position with a bilateral cochlear implant user. J. Acoust.
Soc. Am. 114:1565- 1574, 2003. C ADDEN ASANEN M F D, P EG. Lateralization at high
frequencies based on interaural time differences. J. Acoust. Soc. Am. 59:634-639,
1976. _ EDDIS ARD M R, O M L. A unitary model of pitch perception. J. Acoust. Soc.
Am. 102:1811-1820, 1997. ILLER M GA. The masking of speech. Psychol. Bull.
44:105-129, 1947. LOMP R. Pitch of complex tones. J. Acoust. Soc. Am. 41:1526-1533, P
1967. IN XENHAM Q MK, O AJ. Effects of simulated cochlear-implant processing on
speech reception in fluctuating maskers. J. Acoust. Soc. Am. 114:446-454, 2003. IN
XENHAM Q MK, O AJ. Effects of envelope-vocoder processing on F0 discrimination and
concurrent-vowel identification. Ear Hear. 26:451-460, 2005. IN XENHAM Q MK, O AJ.
Effects of introducing unprocessed lowfrequency information on the reception of
envelope-vocoder processed speech. J. Acoust. Soc. Am. 119:2417-2426, 2006. AYLEIGH R
L. On our perception of sound direction. Philos. Mag. 74:214-231, 1907. UBINSTEIN
URNER R JT, T CW. A novel acoustic simulation of cochlear implant hearing: effects of
temporal fine structure. First International IEEE EMBS Conference on Neural
Engineering, IEEE Press, 142-145, 2003. R UBINSTEIN ILSON INLEY BBAS JT, W BS, F CC,
A PJ. Pseudospontaneous activity: stochastic independence of auditory nerve fibers
with electrical stimulation. Hear. Res. 127:108-118, 1999. HANNON ENG AMATH YGONSKI
KELID S RV, Z F-G, K V, W J, E M. Speech recognition with primarily temporal cues.
Science 270:303-304, 1995. MITH ELGUTTE XENHAM S ZM, D B, O AJ. Chimaeric sounds
reveal dichotomies in auditory perception. Nature 416:87-90, 2002. TICKNEY ENG
ITOVSKY SSMANN S GS, Z F-G, L R, A P. Cochlear implant speech recognition with speech
maskers. J. Acoust. Soc. Am. 116:1081-1091, 2004. OBIAS CHUBERT T JV, S ED. Effective
onset duration of auditory stimuli. J. Acoust. Soc. Am. 31:1595-1605, 1959. URNER
ANTZ IDAL EHRENS ENRY T CW, G BJ, V C, B A, H BA. Speech recognition in noise for
cochlear implant listeners: Benefits of residual acoustic hearing. J. Acoust. Soc.
Am. 115:1729-1735, 2004. V AN DE AR OHLRAUSCH P S, K A. A new approach to comparing
binaural masking level differences at low and high frequencies. J. Acoust. Soc. Am.
101:1671-1680, 1997. AN OESEL YLER V H RJM, T RS. Speech perception, localization and
lateralization with bilateral cochlear implants. J. Acoust. Soc. Am. 113:1617-1630,
2003. IGHTMAN ISTLER W FL, K DJ. The dominant role of low frequency interaural time
differences in sound localization. J. Acoust. Soc. Am. 91:1648-1661, 1992. ON RENNAN
UBINSTEIN W JH, D W, R J. Spectral ripple resolution and speech perception in babble
and speech-shaped noise by cochlear implant listeners. Presented at the 30th annual
midwinter meeting of the Association for Research in Otolaryngology, vol. 30, pp.
304, 2007. U FINGST X L, P BE. Relative importance of temporal envelope and fine
structure in lexical-tone perception. J. Acoust. Soc. Am. 114:3024-3027, 2003. Y OST
IGHTMAN REEN WA, W FL, G DM. Lateralization of filtered clicks. J. Acoust. Soc. Am.
39:1526-1531, 1971.<component x="31.86" y="69.97" width="233.19" height="386.12"
page="10" page_width="593.97" page_height="792.0"></component><component x="288.85"
y="69.91" width="233.24" height="645.15" page="10" page_width="593.97"
page_height="792.0"></component><component x="72.0" y="558.72" width="233.2"
height="157.02" page="11" page_width="593.97"
page_height="792.0"></component><component x="329.04" y="558.72" width="233.17"
height="157.02" page="11" page_width="593.97"
page_height="792.0"></component></section>
  <reference>A PF, S Q. Modeling the perception of concur- rent vowels: vowels with
different fundamental frequencies. J. Acoust. Soc. Am. 88:680-697, 1990. EST CHAIK V
ARLILE</reference>
  <reference>B V, S A , C S. Separation of concurrent broadband sound sources by
human listeners. J. Acoust. Soc. Am. 115:324- 336, 2004. ILGER UETZEL ABINOWITZ
ZECZKOWSKI</reference>
  <reference>B RC, N JM, R WM, R C. Standard- ization of a test of speech perception
in noise. J. Speech Hear. Res. 27:32-48, 1984. IRD ARWIN</reference>
  <reference>B J, D CJ. Effects of a difference in fundamental frequency in
separating two sentences. In: Palmer AR, Rees A, Summerfield AQ and Meddis R (eds)
Psychophysical and Physiological Advances in Hearing. London, Whurr, pp. 263-269,
1998. ROKX OOTEBOOM</reference>
  <reference>B JPL, N SG. Intonation and the perceptual separa- tion of simultaneous
voices. J. Phon. 10:23-36, 1982. RONKHORST LOMP</reference>
  <reference>B AW, P R. The effect of head-induced interaural time and level
differences on speech intelligibility in noise. J. Acoust. Soc. Am. 83:1508-1516,
1988. ARHART ILLMAN OHNSON</reference>
  <reference>C R, T TW, J KR. Release of masking for speech through interaural time
delay. J. Acoust. Soc. Am. 42:124-138, 1967. ULLING ARWIN</reference>
  <reference>C JF, D CJ. Perceptual separation of simultaneous vowels: within and
across-formant grouping by F0. J. Acoust. Soc. Am. 93:3454-3467, 1993. ULLING AWLEY
ITOVSKY</reference>
  <reference>C JF, H ML, L RY. The role of head-induced interaural time and level
differences in the speech reception threshold for multiple interfering sound sources.
J. Acoust. Soc. Am. 116:1057-1065, 2004. ORMAN OIZOU ITZKE U</reference>
  <reference>D MF, L PC, F J, T Z. The recognition of sentences in noise by
normal-hearing listeners using simula- tions of cochlear-implant signal processors
with 6-20 channels. J. Acoust. Soc. Am. 104:3583-3585, 1998. RENNAN ATEHOUSE
EVER</reference>
  <reference>D WR, G S, L C. Perceptual segregation of competing speech sounds: the
role of spatial location. J. Acoust. Soc. Am. 114:2178-2189, 2003.</reference>
  <reference>F ISHMAN HANNON LATTERY K, S RV, S WH. Speech recognition as a function
of the number of electrodes used in the SPEAK cochlear implant speech processor. J.
Speech Hear. Res. 32:524-535, 1997. RIESEN HANNON ASKENT ANG</reference>
  <reference>F LM, S RV, B D, W X. Speech recognition in noise as a function of the
number of spectral channels: comparison of acoustic hearing and cochlear implants. J.
Acoust. Soc. Am. 110:1150-1163, 2001. OOD ILKEY</reference>
  <reference>G MD, G RH. Sound localization in noise. The effect of signal-to-noise
ratio. J. Acoust. Soc. Am. 99:1108-1117, 1996. ARRIS</reference>
  <reference>H RW. Speech audiometry materials compact disk. Provo, UT, Brigham Young
University, pp. 1991. ENNING</reference>
  <reference>H GB. Detectability of interaural delay in high-frequency complex
waveforms. J. Acoust. Soc. Am. 55:1974. OUTSMA MURZYNSKI</reference>
  <reference>H AJM, S J. Pitch identification and discrimination for complex tones
with many harmonics. J. Acoust. Soc. Am. 87:304-310, 1990. EFFRESS</reference>
  <reference>J LA. A place theory of sound localization. J. Comp. Physiol. Psychol.
41:35-39, 1948. EFFRESS</reference>
  <reference>J LA. Medial geniculate body-a disavowal. J. Acoust. Soc. Am.
30:802-803, 1958. EFFRESS LODGETT EATHERAGE</reference>
  <reference>J LA, B HC, D BH. Effect of interaural correlation on the precision of
centering a noise. J. Acoust. Soc. Am. 34:1122-1123, 1962. LUMPP ADY</reference>
  <reference>K RG, E HR. Some measurements of interaural time difference thresholds.
J. Acoust. Soc. Am. 28:859-860, 1956. ONG TICKNEY ENG</reference>
  <reference>K Y-Y, S GS, Z F-G. Speech and melody recognition in binaurally combined
acoustic and electric hearing. J. Acoust. Soc. Am. 117:1351-1361, 2005. ABACK OK
AUMGARTNER EUTSCH CHMID</reference>
  <reference>L B, P S-M, B W-D, D WA, S K. Sensitivity to interaural level and
envelope differences of two bilateral cochlear implant listeners using clinical sound
pro- cessors. Ear Hear. 25:488-500, 2004. ITVAK ELGUTTE DDINGTON</reference>
  <reference>L L, D B, E D. Improved neural representa- tion of vowels in electric
stimulation using desynchronizing pulse trains. J. Acoust. Soc. Am. 114:2099-2111,
2003. ONG ARLYON ITOVSKY OWNS</reference>
  <reference>L CJ, C RP, L RY, D DH. Binaural unmasking with bilateral cochlear
implants. J. Assoc. Res. Otolaryngol. 7:352-360, 2006. ONG DDINGTON OLBURN
ABINOWITZ</reference>
  <reference>L CJ, E DK, C HS, R WM. Binaural sensitivity as a function of interaural
electrode position with a bilateral cochlear implant user. J. Acoust. Soc. Am.
114:1565- 1574, 2003. C ADDEN ASANEN</reference>
  <reference>M F D, P EG. Lateralization at high frequencies based on interaural time
differences. J. Acoust. Soc. Am. 59:634-639, 1976. _ EDDIS ARD</reference>
  <reference>M R, O M L. A unitary model of pitch perception. J. Acoust. Soc. Am.
102:1811-1820, 1997. ILLER</reference>
  <reference>M GA. The masking of speech. Psychol. Bull. 44:105-129, 1947. LOMP R.
Pitch of complex tones. J. Acoust. Soc. Am. 41:1526-1533,</reference>
  <reference>P 1967. IN XENHAM</reference>
  <reference>Q MK, O AJ. Effects of simulated cochlear-implant processing on speech
reception in fluctuating maskers. J. Acoust. Soc. Am. 114:446-454, 2003. IN
XENHAM</reference>
  <reference>Q MK, O AJ. Effects of envelope-vocoder processing on F0 discrimination
and concurrent-vowel identification. Ear Hear. 26:451-460, 2005. IN
XENHAM</reference>
  <reference>Q MK, O AJ. Effects of introducing unprocessed low- frequency
information on the reception of envelope-vocoder processed speech. J. Acoust. Soc.
Am. 119:2417-2426, 2006. AYLEIGH</reference>
  <reference>R L. On our perception of sound direction. Philos. Mag. 74:214-231,
1907. UBINSTEIN URNER</reference>
  <reference>R JT, T CW. A novel acoustic simulation of cochlear implant hearing:
effects of temporal fine structure. First International IEEE EMBS Conference on
Neural Engineering, IEEE Press, 142-145, 2003.</reference>
  <reference>R UBINSTEIN ILSON INLEY BBAS JT, W BS, F CC, A PJ. Pseudospontaneous
activity: stochastic independence of auditory nerve fibers with electrical
stimulation. Hear. Res. 127:108-118, 1999. HANNON ENG AMATH YGONSKI KELID</reference>
  <reference>S RV, Z F-G, K V, W J, E M. Speech recognition with primarily temporal
cues. Science 270:303-304, 1995. MITH ELGUTTE XENHAM</reference>
  <reference>S ZM, D B, O AJ. Chimaeric sounds reveal dichotomies in auditory
perception. Nature 416:87-90, 2002. TICKNEY ENG ITOVSKY SSMANN</reference>
  <reference>S GS, Z F-G, L R, A P. Cochlear implant speech recognition with speech
maskers. J. Acoust. Soc. Am. 116:1081-1091, 2004. OBIAS CHUBERT</reference>
  <reference>T JV, S ED. Effective onset duration of auditory stimuli. J. Acoust.
Soc. Am. 31:1595-1605, 1959. URNER ANTZ IDAL EHRENS ENRY</reference>
  <reference>T CW, G BJ, V C, B A, H BA. Speech recognition in noise for cochlear
implant listeners: Benefits of residual acoustic hearing. J. Acoust. Soc. Am.
115:1729-1735, 2004.</reference>
  <reference>V AN DE AR OHLRAUSCH P S, K A. A new approach to comparing binaural
masking level differences at low and high frequencies. J. Acoust. Soc. Am.
101:1671-1680, 1997. AN OESEL YLER</reference>
  <reference>V H RJM, T RS. Speech perception, localization and lateralization with
bilateral cochlear implants. J. Acoust. Soc. Am. 113:1617-1630, 2003. IGHTMAN
ISTLER</reference>
  <reference>W FL, K DJ. The dominant role of low frequency interaural time
differences in sound localization. J. Acoust. Soc. Am. 91:1648-1661, 1992. ON RENNAN
UBINSTEIN</reference>
  <reference>W JH, D W, R J. Spectral ripple resolution and speech perception in
babble and speech-shaped noise by cochlear implant listeners. Presented at the 30th
annual midwinter meeting of the Association for Research in Otolar- yngology, vol.
30, pp. 304, 2007. U FINGST</reference>
  <reference>X L, P BE. Relative importance of temporal envelope and fine structure
in lexical-tone perception. J. Acoust. Soc. Am. 114:3024-3027, 2003.</reference>
  <reference>Y OST IGHTMAN REEN WA, W FL, G DM. Lateralization of filtered clicks. J.
Acoust. Soc. Am. 39:1526-1531, 1971.</reference>
  <reference>A PF, S Q. Modeling the perception of concur- rent vowels: vowels with
different fundamental frequencies. J. Acoust. Soc. Am. 88:680-697, 1990. EST CHAIK V
ARLILE</reference>
  <reference>B V, S A , C S. Separation of concurrent broadband sound sources by
human listeners. J. Acoust. Soc. Am. 115:324- 336, 2004. ILGER UETZEL ABINOWITZ
ZECZKOWSKI</reference>
  <reference>B RC, N JM, R WM, R C. Standard- ization of a test of speech perception
in noise. J. Speech Hear. Res. 27:32-48, 1984. IRD ARWIN</reference>
  <reference>B J, D CJ. Effects of a difference in fundamental frequency in
separating two sentences. In: Palmer AR, Rees A, Summerfield AQ and Meddis R (eds)
Psychophysical and Physiological Advances in Hearing. London, Whurr, pp. 263-269,
1998. ROKX OOTEBOOM</reference>
  <reference>B JPL, N SG. Intonation and the perceptual separa- tion of simultaneous
voices. J. Phon. 10:23-36, 1982. RONKHORST LOMP</reference>
  <reference>B AW, P R. The effect of head-induced interaural time and level
differences on speech intelligibility in noise. J. Acoust. Soc. Am. 83:1508-1516,
1988. ARHART ILLMAN OHNSON</reference>
  <reference>C R, T TW, J KR. Release of masking for speech through interaural time
delay. J. Acoust. Soc. Am. 42:124-138, 1967. ULLING ARWIN</reference>
  <reference>C JF, D CJ. Perceptual separation of simultaneous vowels: within and
across-formant grouping by F0. J. Acoust. Soc. Am. 93:3454-3467, 1993. ULLING AWLEY
ITOVSKY</reference>
  <reference>C JF, H ML, L RY. The role of head-induced interaural time and level
differences in the speech reception threshold for multiple interfering sound sources.
J. Acoust. Soc. Am. 116:1057-1065, 2004. ORMAN OIZOU ITZKE U</reference>
  <reference>D MF, L PC, F J, T Z. The recognition of sentences in noise by
normal-hearing listeners using simula- tions of cochlear-implant signal processors
with 6-20 channels. J. Acoust. Soc. Am. 104:3583-3585, 1998. RENNAN ATEHOUSE
EVER</reference>
  <reference>D WR, G S, L C. Perceptual segregation of competing speech sounds: the
role of spatial location. J. Acoust. Soc. Am. 114:2178-2189, 2003.</reference>
  <reference>F ISHMAN HANNON LATTERY K, S RV, S WH. Speech recognition as a function
of the number of electrodes used in the SPEAK cochlear implant speech processor. J.
Speech Hear. Res. 32:524-535, 1997. RIESEN HANNON ASKENT ANG</reference>
  <reference>F LM, S RV, B D, W X. Speech recognition in noise as a function of the
number of spectral channels: comparison of acoustic hearing and cochlear implants. J.
Acoust. Soc. Am. 110:1150-1163, 2001. OOD ILKEY</reference>
  <reference>G MD, G RH. Sound localization in noise. The effect of signal-to-noise
ratio. J. Acoust. Soc. Am. 99:1108-1117, 1996. ARRIS</reference>
  <reference>H RW. Speech audiometry materials compact disk. Provo, UT, Brigham Young
University, pp. 1991. ENNING</reference>
  <reference>H GB. Detectability of interaural delay in high-frequency complex
waveforms. J. Acoust. Soc. Am. 55:1974. OUTSMA MURZYNSKI</reference>
  <reference>H AJM, S J. Pitch identification and discrimination for complex tones
with many harmonics. J. Acoust. Soc. Am. 87:304-310, 1990. EFFRESS</reference>
  <reference>J LA. A place theory of sound localization. J. Comp. Physiol. Psychol.
41:35-39, 1948. EFFRESS</reference>
  <reference>J LA. Medial geniculate body-a disavowal. J. Acoust. Soc. Am.
30:802-803, 1958. EFFRESS LODGETT EATHERAGE</reference>
  <reference>J LA, B HC, D BH. Effect of interaural correlation on the precision of
centering a noise. J. Acoust. Soc. Am. 34:1122-1123, 1962. LUMPP ADY</reference>
  <reference>K RG, E HR. Some measurements of interaural time difference thresholds.
J. Acoust. Soc. Am. 28:859-860, 1956. ONG TICKNEY ENG</reference>
  <reference>K Y-Y, S GS, Z F-G. Speech and melody recognition in binaurally combined
acoustic and electric hearing. J. Acoust. Soc. Am. 117:1351-1361, 2005. ABACK OK
AUMGARTNER EUTSCH CHMID</reference>
  <reference>L B, P S-M, B W-D, D WA, S K. Sensitivity to interaural level and
envelope differences of two bilateral cochlear implant listeners using clinical sound
pro- cessors. Ear Hear. 25:488-500, 2004. ITVAK ELGUTTE DDINGTON</reference>
  <reference>L L, D B, E D. Improved neural representa- tion of vowels in electric
stimulation using desynchronizing pulse trains. J. Acoust. Soc. Am. 114:2099-2111,
2003. ONG ARLYON ITOVSKY OWNS</reference>
  <reference>L CJ, C RP, L RY, D DH. Binaural unmasking with bilateral cochlear
implants. J. Assoc. Res. Otolaryngol. 7:352-360, 2006. ONG DDINGTON OLBURN
ABINOWITZ</reference>
  <reference>L CJ, E DK, C HS, R WM. Binaural sensitivity as a function of interaural
electrode position with a bilateral cochlear implant user. J. Acoust. Soc. Am.
114:1565- 1574, 2003. C ADDEN ASANEN</reference>
  <reference>M F D, P EG. Lateralization at high frequencies based on interaural time
differences. J. Acoust. Soc. Am. 59:634-639, 1976. _ EDDIS ARD</reference>
  <reference>M R, O M L. A unitary model of pitch perception. J. Acoust. Soc. Am.
102:1811-1820, 1997. ILLER</reference>
  <reference>M GA. The masking of speech. Psychol. Bull. 44:105-129, 1947. LOMP R.
Pitch of complex tones. J. Acoust. Soc. Am. 41:1526-1533,</reference>
  <reference>P 1967. IN XENHAM</reference>
  <reference>Q MK, O AJ. Effects of simulated cochlear-implant processing on speech
reception in fluctuating maskers. J. Acoust. Soc. Am. 114:446-454, 2003. IN
XENHAM</reference>
  <reference>Q MK, O AJ. Effects of envelope-vocoder processing on F0 discrimination
and concurrent-vowel identification. Ear Hear. 26:451-460, 2005. IN
XENHAM</reference>
  <reference>Q MK, O AJ. Effects of introducing unprocessed low- frequency
information on the reception of envelope-vocoder processed speech. J. Acoust. Soc.
Am. 119:2417-2426, 2006. AYLEIGH</reference>
  <reference>R L. On our perception of sound direction. Philos. Mag. 74:214-231,
1907. UBINSTEIN URNER</reference>
  <reference>R JT, T CW. A novel acoustic simulation of cochlear implant hearing:
effects of temporal fine structure. First International IEEE EMBS Conference on
Neural Engineering, IEEE Press, 142-145, 2003.</reference>
  <reference>R UBINSTEIN ILSON INLEY BBAS JT, W BS, F CC, A PJ. Pseudospontaneous
activity: stochastic independence of auditory nerve fibers with electrical
stimulation. Hear. Res. 127:108-118, 1999. HANNON ENG AMATH YGONSKI KELID</reference>
  <reference>S RV, Z F-G, K V, W J, E M. Speech recognition with primarily temporal
cues. Science 270:303-304, 1995. MITH ELGUTTE XENHAM</reference>
  <reference>S ZM, D B, O AJ. Chimaeric sounds reveal dichotomies in auditory
perception. Nature 416:87-90, 2002. TICKNEY ENG ITOVSKY SSMANN</reference>
  <reference>S GS, Z F-G, L R, A P. Cochlear implant speech recognition with speech
maskers. J. Acoust. Soc. Am. 116:1081-1091, 2004. OBIAS CHUBERT</reference>
  <reference>T JV, S ED. Effective onset duration of auditory stimuli. J. Acoust.
Soc. Am. 31:1595-1605, 1959. URNER ANTZ IDAL EHRENS ENRY</reference>
  <reference>T CW, G BJ, V C, B A, H BA. Speech recognition in noise for cochlear
implant listeners: Benefits of residual acoustic hearing. J. Acoust. Soc. Am.
115:1729-1735, 2004.</reference>
  <reference>V AN DE AR OHLRAUSCH P S, K A. A new approach to comparing binaural
masking level differences at low and high frequencies. J. Acoust. Soc. Am.
101:1671-1680, 1997. AN OESEL YLER</reference>
  <reference>V H RJM, T RS. Speech perception, localization and lateralization with
bilateral cochlear implants. J. Acoust. Soc. Am. 113:1617-1630, 2003. IGHTMAN
ISTLER</reference>
  <reference>W FL, K DJ. The dominant role of low frequency interaural time
differences in sound localization. J. Acoust. Soc. Am. 91:1648-1661, 1992. ON RENNAN
UBINSTEIN</reference>
  <reference>W JH, D W, R J. Spectral ripple resolution and speech perception in
babble and speech-shaped noise by cochlear implant listeners. Presented at the 30th
annual midwinter meeting of the Association for Research in Otolar- yngology, vol.
30, pp. 304, 2007. U FINGST</reference>
  <reference>X L, P BE. Relative importance of temporal envelope and fine structure
in lexical-tone perception. J. Acoust. Soc. Am. 114:3024-3027, 2003.</reference>
  <reference>Y OST IGHTMAN REEN WA, W FL, G DM. Lateralization of filtered clicks. J.
Acoust. Soc. Am. 39:1526-1531, 1971.</reference>
  <resolved_reference>A PF, S Q. Modeling the perception of concur- rent vowels:
vowels with different fundamental frequencies. J. Acoust. Soc. Am. 88:680-697, 1990.
EST CHAIK V ARLILE</resolved_reference>
  <resolved_reference>B V, S A , C S. Separation of concurrent broadband sound
sources by human listeners. J. Acoust. Soc. Am. 115:324- 336, 2004. ILGER UETZEL
ABINOWITZ ZECZKOWSKI</resolved_reference>
  <resolved_reference>B RC, N JM, R WM, R C. Standard- ization of a test of speech
perception in noise. J. Speech Hear. Res. 27:32-48, 1984. IRD
ARWIN</resolved_reference>
  <resolved_reference>B J, D CJ. Effects of a difference in fundamental frequency in
separating two sentences. In: Palmer AR, Rees A, Summerfield AQ and Meddis R (eds)
Psychophysical and Physiological Advances in Hearing. London, Whurr, pp. 263-269,
1998. ROKX OOTEBOOM</resolved_reference>
  <resolved_reference>B JPL, N SG. Intonation and the perceptual separa- tion of
simultaneous voices. J. Phon. 10:23-36, 1982. RONKHORST LOMP</resolved_reference>
  <resolved_reference>B AW, P R. The effect of head-induced interaural time and level
differences on speech intelligibility in noise. J. Acoust. Soc. Am. 83:1508-1516,
1988. ARHART ILLMAN OHNSON</resolved_reference>
  <resolved_reference>C R, T TW, J KR. Release of masking for speech through
interaural time delay. J. Acoust. Soc. Am. 42:124-138, 1967. ULLING
ARWIN</resolved_reference>
  <resolved_reference>C JF, D CJ. Perceptual separation of simultaneous vowels:
within and across-formant grouping by F0. J. Acoust. Soc. Am. 93:3454-3467, 1993.
ULLING AWLEY ITOVSKY</resolved_reference>
  <resolved_reference>C JF, H ML, L RY. The role of head-induced interaural time and
level differences in the speech reception threshold for multiple interfering sound
sources. J. Acoust. Soc. Am. 116:1057-1065, 2004. ORMAN OIZOU ITZKE
U</resolved_reference>
  <resolved_reference>D MF, L PC, F J, T Z. The recognition of sentences in noise by
normal-hearing listeners using simula- tions of cochlear-implant signal processors
with 6-20 channels. J. Acoust. Soc. Am. 104:3583-3585, 1998. RENNAN ATEHOUSE
EVER</resolved_reference>
  <resolved_reference>D WR, G S, L C. Perceptual segregation of competing speech
sounds: the role of spatial location. J. Acoust. Soc. Am. 114:2178-2189,
2003.</resolved_reference>
  <resolved_reference>F ISHMAN HANNON LATTERY K, S RV, S WH. Speech recognition as a
function of the number of electrodes used in the SPEAK cochlear implant speech
processor. J. Speech Hear. Res. 32:524-535, 1997. RIESEN HANNON ASKENT
ANG</resolved_reference>
  <resolved_reference>F LM, S RV, B D, W X. Speech recognition in noise as a function
of the number of spectral channels: comparison of acoustic hearing and cochlear
implants. J. Acoust. Soc. Am. 110:1150-1163, 2001. OOD ILKEY</resolved_reference>
  <resolved_reference>G MD, G RH. Sound localization in noise. The effect of
signal-to-noise ratio. J. Acoust. Soc. Am. 99:1108-1117, 1996.
ARRIS</resolved_reference>
  <resolved_reference>H RW. Speech audiometry materials compact disk. Provo, UT,
Brigham Young University, pp. 1991. ENNING</resolved_reference>
  <resolved_reference>H GB. Detectability of interaural delay in high-frequency
complex waveforms. J. Acoust. Soc. Am. 55:1974. OUTSMA MURZYNSKI</resolved_reference>
  <resolved_reference>H AJM, S J. Pitch identification and discrimination for complex
tones with many harmonics. J. Acoust. Soc. Am. 87:304-310, 1990.
EFFRESS</resolved_reference>
  <resolved_reference>J LA. A place theory of sound localization. J. Comp. Physiol.
Psychol. 41:35-39, 1948. EFFRESS</resolved_reference>
  <resolved_reference>J LA. Medial geniculate body-a disavowal. J. Acoust. Soc. Am.
30:802-803, 1958. EFFRESS LODGETT EATHERAGE</resolved_reference>
  <resolved_reference>J LA, B HC, D BH. Effect of interaural correlation on the
precision of centering a noise. J. Acoust. Soc. Am. 34:1122-1123, 1962. LUMPP
ADY</resolved_reference>
  <resolved_reference>K RG, E HR. Some measurements of interaural time difference
thresholds. J. Acoust. Soc. Am. 28:859-860, 1956. ONG TICKNEY
ENG</resolved_reference>
  <resolved_reference>K Y-Y, S GS, Z F-G. Speech and melody recognition in binaurally
combined acoustic and electric hearing. J. Acoust. Soc. Am. 117:1351-1361, 2005.
ABACK OK AUMGARTNER EUTSCH CHMID</resolved_reference>
  <resolved_reference>L B, P S-M, B W-D, D WA, S K. Sensitivity to interaural level
and envelope differences of two bilateral cochlear implant listeners using clinical
sound pro- cessors. Ear Hear. 25:488-500, 2004. ITVAK ELGUTTE
DDINGTON</resolved_reference>
  <resolved_reference>L L, D B, E D. Improved neural representa- tion of vowels in
electric stimulation using desynchronizing pulse trains. J. Acoust. Soc. Am.
114:2099-2111, 2003. ONG ARLYON ITOVSKY OWNS</resolved_reference>
  <resolved_reference>L CJ, C RP, L RY, D DH. Binaural unmasking with bilateral
cochlear implants. J. Assoc. Res. Otolaryngol. 7:352-360, 2006. ONG DDINGTON OLBURN
ABINOWITZ</resolved_reference>
  <resolved_reference>L CJ, E DK, C HS, R WM. Binaural sensitivity as a function of
interaural electrode position with a bilateral cochlear implant user. J. Acoust. Soc.
Am. 114:1565- 1574, 2003. C ADDEN ASANEN</resolved_reference>
  <resolved_reference>M F D, P EG. Lateralization at high frequencies based on
interaural time differences. J. Acoust. Soc. Am. 59:634-639, 1976. _ EDDIS
ARD</resolved_reference>
  <resolved_reference>M R, O M L. A unitary model of pitch perception. J. Acoust.
Soc. Am. 102:1811-1820, 1997. ILLER</resolved_reference>
  <resolved_reference>M GA. The masking of speech. Psychol. Bull. 44:105-129, 1947.
LOMP R. Pitch of complex tones. J. Acoust. Soc. Am.
41:1526-1533,</resolved_reference>
  <resolved_reference>P 1967. IN XENHAM</resolved_reference>
  <resolved_reference>Q MK, O AJ. Effects of simulated cochlear-implant processing on
speech reception in fluctuating maskers. J. Acoust. Soc. Am. 114:446-454, 2003. IN
XENHAM</resolved_reference>
  <resolved_reference>Q MK, O AJ. Effects of envelope-vocoder processing on F0
discrimination and concurrent-vowel identification. Ear Hear. 26:451-460, 2005. IN
XENHAM</resolved_reference>
  <resolved_reference>Q MK, O AJ. Effects of introducing unprocessed low- frequency
information on the reception of envelope-vocoder processed speech. J. Acoust. Soc.
Am. 119:2417-2426, 2006. AYLEIGH</resolved_reference>
  <resolved_reference>R L. On our perception of sound direction. Philos. Mag.
74:214-231, 1907. UBINSTEIN URNER</resolved_reference>
  <resolved_reference>R JT, T CW. A novel acoustic simulation of cochlear implant
hearing: effects of temporal fine structure. First International IEEE EMBS Conference
on Neural Engineering, IEEE Press, 142-145, 2003.</resolved_reference>
  <resolved_reference>R UBINSTEIN ILSON INLEY BBAS JT, W BS, F CC, A PJ.
Pseudospontaneous activity: stochastic independence of auditory nerve fibers with
electrical stimulation. Hear. Res. 127:108-118, 1999. HANNON ENG AMATH YGONSKI
KELID</resolved_reference>
  <resolved_reference>S RV, Z F-G, K V, W J, E M. Speech recognition with primarily
temporal cues. Science 270:303-304, 1995. MITH ELGUTTE XENHAM</resolved_reference>
  <resolved_reference>S ZM, D B, O AJ. Chimaeric sounds reveal dichotomies in
auditory perception. Nature 416:87-90, 2002. TICKNEY ENG ITOVSKY
SSMANN</resolved_reference>
  <resolved_reference>S GS, Z F-G, L R, A P. Cochlear implant speech recognition with
speech maskers. J. Acoust. Soc. Am. 116:1081-1091, 2004. OBIAS
CHUBERT</resolved_reference>
  <resolved_reference>T JV, S ED. Effective onset duration of auditory stimuli. J.
Acoust. Soc. Am. 31:1595-1605, 1959. URNER ANTZ IDAL EHRENS ENRY</resolved_reference>
  <resolved_reference>T CW, G BJ, V C, B A, H BA. Speech recognition in noise for
cochlear implant listeners: Benefits of residual acoustic hearing. J. Acoust. Soc.
Am. 115:1729-1735, 2004.</resolved_reference>
  <resolved_reference>V AN DE AR OHLRAUSCH P S, K A. A new approach to comparing
binaural masking level differences at low and high frequencies. J. Acoust. Soc. Am.
101:1671-1680, 1997. AN OESEL YLER</resolved_reference>
  <resolved_reference>V H RJM, T RS. Speech perception, localization and
lateralization with bilateral cochlear implants. J. Acoust. Soc. Am. 113:1617-1630,
2003. IGHTMAN ISTLER</resolved_reference>
  <resolved_reference>W FL, K DJ. The dominant role of low frequency interaural time
differences in sound localization. J. Acoust. Soc. Am. 91:1648-1661, 1992. ON RENNAN
UBINSTEIN</resolved_reference>
  <resolved_reference>W JH, D W, R J. Spectral ripple resolution and speech
perception in babble and speech-shaped noise by cochlear implant listeners. Presented
at the 30th annual midwinter meeting of the Association for Research in Otolar-
yngology, vol. 30, pp. 304, 2007. U FINGST</resolved_reference>
  <resolved_reference>X L, P BE. Relative importance of temporal envelope and fine
structure in lexical-tone perception. J. Acoust. Soc. Am. 114:3024-3027,
2003.</resolved_reference>
  <resolved_reference>Y OST IGHTMAN REEN WA, W FL, G DM. Lateralization of filtered
clicks. J. Acoust. Soc. Am. 39:1526-1531, 1971.</resolved_reference>
  <page width="593.972" height="792" number="2">
    <header x="31.86" y="748.58" width="490.23" height="8.16"></header>
  </page>
  <page width="593.972" height="792" number="3">
    <header x="72.0" y="748.58" width="490.22" height="8.16"></header>
  </page>
  <page width="593.972" height="792" number="4">
    <header x="31.86" y="748.58" width="490.19" height="8.16"></header>
  </page>
  <page width="593.972" height="792" number="5">
    <header x="72.0" y="748.58" width="490.27" height="8.16"></header>
  </page>
  <page width="593.972" height="792" number="6">
    <header x="31.86" y="748.58" width="490.2" height="8.16"></header>
  </page>
  <page width="593.972" height="792" number="7">
    <header x="72.0" y="748.58" width="490.21" height="8.16"></header>
  </page>
  <page width="593.972" height="792" number="8">
    <header x="31.86" y="748.58" width="490.21" height="8.16"></header>
  </page>
  <page width="593.972" height="792" number="9">
    <header x="72.0" y="748.58" width="490.25" height="8.16"></header>
  </page>
  <page width="593.972" height="792" number="10">
    <header x="31.86" y="748.58" width="490.22" height="8.16"></header>
  </page>
  <page width="593.972" height="792" number="11">
    <header x="72.0" y="748.58" width="490.22" height="8.16"></header>
  </page>
</pdf>
