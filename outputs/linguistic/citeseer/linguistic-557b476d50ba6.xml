<?xml version='1.0' encoding='UTF-8'?><paper>
<algorithm name="Grobid Header Extraction" version="0.1"><title>Dissociating linguistic and non-linguistic gesture processing: Electrophysiological evidence from American Sign Language</title><authors><author><name>Michael Grosvald</name><affiliation>University of California at Irvine, Department of Neurology</affiliation></author><author><name>Eva Gutierrez</name><affiliation>University of California at Davis, Center for Mind and Brain</affiliation></author><author><name>Sarah Hafer</name><affiliation>University of California at Davis, Center for Mind and Brain</affiliation></author><author><name>David Corina</name><affiliation>University of California at Davis, Center for Mind and Brain | University of California at Davis, Departments of Linguistics and Psychology | University of Cali-fornia at Irvine, Department of Neurology</affiliation></author></authors><keywords /></algorithm><TEI>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dissociating linguistic and non-linguistic gesture processing: Electrophysiological evidence from American Sign Language</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
				<date type="published" when="2012-02-17">Available online 17 February 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Michael</forename>
								<surname>Grosvald</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Neurology</orgName>
								<orgName type="institution">University of California at Irvine</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Eva</forename>
								<surname>Gutierrez</surname>
							</persName>
							<affiliation>
								<orgName type="department">Center for Mind and Brain</orgName>
								<orgName type="institution">University of California at Davis</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Sarah</forename>
								<surname>Hafer</surname>
							</persName>
							<affiliation>
								<orgName type="department">Center for Mind and Brain</orgName>
								<orgName type="institution">University of California at Davis</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">David</forename>
								<surname>Corina</surname>
							</persName>
							<affiliation>
								<orgName type="department">Center for Mind and Brain</orgName>
								<orgName type="institution">University of California at Davis</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation>
								<orgName type="department">Departments of Linguistics and Psychology</orgName>
								<orgName type="institution">University of California at Davis</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation>
								<orgName type="department">Department of Neurology</orgName>
								<orgName type="institution">University of Cali-fornia at Irvine</orgName>
								<address>
									<addrLine>101 The City Drive South, Bldg. 53, Room 204</addrLine>
									<postCode>92868-4280</postCode>
									<settlement>Orange</settlement>
									<region>CA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dissociating linguistic and non-linguistic gesture processing: Electrophysiological evidence from American Sign Language</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2012-02-17">Available online 17 February 2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.bandl.2012.01.005</idno>
					<note type="submission">Article history: Accepted 24 January 2012</note>
					<note>a r t i c l e i n f o</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>Sign language</keywords>
			</textClass>
			<abstract />
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
	</text>
</TEI><algorithms version="110505">
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M A Arbib</author>
</authors>
<title>Interweaving protosign and protospeech: Further developments beyond the mirror.</title>
<date>2005</date>
<journal>Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems,</journal>
<volume>6</volume>
<pages>145--171</pages>
<marker>Arbib, 2005</marker>
<rawString>Arbib, M. A. (2005). Interweaving protosign and protospeech: Further developments beyond the mirror. Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems, 6, 145–171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Arbib</author>
</authors>
<title>From grasp to language: Embodied concepts and the challenge of abstraction.</title>
<date>2008</date>
<journal>Journal of Physiology-Paris,</journal>
<volume>102</volume>
<pages>4--20</pages>
<marker>Arbib, 2008</marker>
<rawString>Arbib, M. A. (2008). From grasp to language: Embodied concepts and the challenge of abstraction. Journal of Physiology-Paris, 102, 4–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Barrett</author>
<author>M D Rugg</author>
</authors>
<title>Event-related potentials and the semantic matching of faces.</title>
<date>1989</date>
<journal>Neuropsychologia,</journal>
<volume>27</volume>
<pages>913--922</pages>
<contexts>
<context citStr="Barrett &amp; Rugg, 1989" endWordPosition="1291" position="8485" startWordPosition="1288">agoort &amp; Kutas, 1995; Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found i</context>
</contexts>
<marker>Barrett, Rugg, 1989</marker>
<rawString>Barrett, S. E., &amp; Rugg, M. D. (1989). Event-related potentials and the semantic matching of faces. Neuropsychologia, 27, 913–922.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Barrett</author>
<author>M D Rugg</author>
</authors>
<title>Event-related potentials and the semantic matching of pictures.</title>
<date>1990</date>
<journal>Brain and Cognition,</journal>
<volume>14</volume>
<pages>201--212</pages>
<contexts>
<context citStr="Barrett and Rugg (1990)" endWordPosition="6716" position="42262" startWordPosition="6713">d an onset of about 300 ms post-stimulus onset and peaked at about 600 ms post-stimulus onset, very much like the negativities we have described in the present study. These effects are somewhat different from those that have been described in studies incorporating incongruent co-speech gestures and other sorts of non-linguistic imagery like drawings, photographs and videos. In Wu and Coulson’s (2005) study of contextually incongruent gestures, a component described by the researchers as a ‘‘gesture N450’’ was observed. Wu and Coulson noted the similarity of this effect to the N450 reported by Barrett and Rugg (1990) for second items in unrelated picture pairs relative to related picture pairs (e.g. wrench/fork vs. knife/fork), stating (p. 659) that consistent with their own findings, ‘‘most such ‘picture’ ERP studies report a broadly distributed negativity largest at frontal electrode sites and not evident at occipital sites (Barrett &amp; Rugg, 1990; Holcomb &amp; McPherson, 1994; McPherson &amp; Holcomb, 1999; Sitnikova et al., 2003; West &amp; Holcomb, 2002).’’ In contrast, the negativity reported in the present study was quite evident at occipital sites, as can be seen clearly in Figs. 3 and 4. A second notable find</context>
<context citStr="Barrett &amp; Rugg, 1990" endWordPosition="6768" position="42599" startWordPosition="6765">ke drawings, photographs and videos. In Wu and Coulson’s (2005) study of contextually incongruent gestures, a component described by the researchers as a ‘‘gesture N450’’ was observed. Wu and Coulson noted the similarity of this effect to the N450 reported by Barrett and Rugg (1990) for second items in unrelated picture pairs relative to related picture pairs (e.g. wrench/fork vs. knife/fork), stating (p. 659) that consistent with their own findings, ‘‘most such ‘picture’ ERP studies report a broadly distributed negativity largest at frontal electrode sites and not evident at occipital sites (Barrett &amp; Rugg, 1990; Holcomb &amp; McPherson, 1994; McPherson &amp; Holcomb, 1999; Sitnikova et al., 2003; West &amp; Holcomb, 2002).’’ In contrast, the negativity reported in the present study was quite evident at occipital sites, as can be seen clearly in Figs. 3 and 4. A second notable finding in our study concerns deaf subjects’ ERP response in the phonologically legal pseudo-sign condition, which was also consistent with an N400 response but was generally larger (more negative) than the negativity seen for semantically incongruent but fully lexical signs. This provides further evidence for broad processing similarities</context>
</contexts>
<marker>Barrett, Rugg, 1990</marker>
<rawString>Barrett, S. E., &amp; Rugg, M. D. (1990). Event-related potentials and the semantic matching of pictures. Brain and Cognition, 14, 201–212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bentin</author>
</authors>
<title>Event-related potentials, semantic processes, and expectancy factors in word recognition.</title>
<date>1987</date>
<journal>Brain and Language,</journal>
<volume>31</volume>
<pages>308--327</pages>
<contexts>
<context citStr="Bentin, 1987" endWordPosition="1149" position="7507" startWordPosition="1148">iculty in semantic conceptual integration (Brown &amp; Hagoort, 1993; Hagoort &amp; Van Berkum, 2007). For example, for listeners encountering the two sentences ‘‘I like my coffee with milk and sugar’’ and ‘‘I like my coffee with milk and mud,’’ the N400 response to the last word in the second item is expected to be larger. An N400 or N400-like component can also be found in response to orthographically/phonologically legal but non-occurring ‘‘pseudo-words’’ (e.g. ‘‘blork’’), and it has sometimes been reported that pseudo-words elicit a stronger N400 response than semantically incongruent real words (Bentin, 1987; Bentin, McCarthy, &amp; Wood, 1985; Hagoort &amp; Kutas, 1995), consistent with the idea that the magnitude of N400 response is related to the difficulty of the ongoing process of semantic-contextual integration. However, orthographically illegal ‘‘non-words’’ (e.g. ‘‘rbsnk’’) do not generally elicit an N400, and a positive component is sometimes seen instead (Hagoort &amp; Kutas, 1995; Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a </context>
<context citStr="Bentin, 1987" endWordPosition="6881" position="43319" startWordPosition="6880">contrast, the negativity reported in the present study was quite evident at occipital sites, as can be seen clearly in Figs. 3 and 4. A second notable finding in our study concerns deaf subjects’ ERP response in the phonologically legal pseudo-sign condition, which was also consistent with an N400 response but was generally larger (more negative) than the negativity seen for semantically incongruent but fully lexical signs. This provides further evidence for broad processing similarities for different linguistic modalities, in the light of similar findings for pseudo-words in earlier studies (Bentin, 1987; Bentin et al., 1985; Hagoort &amp; Kutas, 1995). It is interesting, however, that phonologically legal pseudo-signs did not more strongly differentiate from the semantically incongruent signs in the present study. This may be an indication that our pseudo-signs (or some of their sub-lexical components) are activating lexical representations to a substantial degree (cf. Friedrich, Eulitz, &amp; Lahiri, 2006), and that at the same time, these representations are incongruent with the sentential contexts in which they have been presented. The pseudo-sign and incongruent sign conditions shared another si</context>
</contexts>
<marker>Bentin, 1987</marker>
<rawString>Bentin, S. (1987). Event-related potentials, semantic processes, and expectancy factors in word recognition. Brain and Language, 31, 308–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bentin</author>
<author>G McCarthy</author>
<author>C C Wood</author>
</authors>
<title>Event-related potentials, lexical decision, and semantic priming.</title>
<date>1985</date>
<journal>Electroencephalography &amp; Clinical Neurophysiology,</journal>
<volume>60</volume>
<pages>353--355</pages>
<contexts>
<context citStr="Bentin, McCarthy, &amp; Wood, 1985" endWordPosition="1154" position="7539" startWordPosition="1150">ntic conceptual integration (Brown &amp; Hagoort, 1993; Hagoort &amp; Van Berkum, 2007). For example, for listeners encountering the two sentences ‘‘I like my coffee with milk and sugar’’ and ‘‘I like my coffee with milk and mud,’’ the N400 response to the last word in the second item is expected to be larger. An N400 or N400-like component can also be found in response to orthographically/phonologically legal but non-occurring ‘‘pseudo-words’’ (e.g. ‘‘blork’’), and it has sometimes been reported that pseudo-words elicit a stronger N400 response than semantically incongruent real words (Bentin, 1987; Bentin, McCarthy, &amp; Wood, 1985; Hagoort &amp; Kutas, 1995), consistent with the idea that the magnitude of N400 response is related to the difficulty of the ongoing process of semantic-contextual integration. However, orthographically illegal ‘‘non-words’’ (e.g. ‘‘rbsnk’’) do not generally elicit an N400, and a positive component is sometimes seen instead (Hagoort &amp; Kutas, 1995; Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, </context>
<context citStr="Bentin et al., 1985" endWordPosition="6885" position="43340" startWordPosition="6882">negativity reported in the present study was quite evident at occipital sites, as can be seen clearly in Figs. 3 and 4. A second notable finding in our study concerns deaf subjects’ ERP response in the phonologically legal pseudo-sign condition, which was also consistent with an N400 response but was generally larger (more negative) than the negativity seen for semantically incongruent but fully lexical signs. This provides further evidence for broad processing similarities for different linguistic modalities, in the light of similar findings for pseudo-words in earlier studies (Bentin, 1987; Bentin et al., 1985; Hagoort &amp; Kutas, 1995). It is interesting, however, that phonologically legal pseudo-signs did not more strongly differentiate from the semantically incongruent signs in the present study. This may be an indication that our pseudo-signs (or some of their sub-lexical components) are activating lexical representations to a substantial degree (cf. Friedrich, Eulitz, &amp; Lahiri, 2006), and that at the same time, these representations are incongruent with the sentential contexts in which they have been presented. The pseudo-sign and incongruent sign conditions shared another similarity in that the </context>
</contexts>
<marker>Bentin, McCarthy, Wood, 1985</marker>
<rawString>Bentin, S., McCarthy, G., &amp; Wood, C. C. (1985). Event-related potentials, lexical decision, and semantic priming. Electroencephalography &amp; Clinical Neurophysiology, 60, 353–355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Bobes</author>
<author>M Valdés-Sosa</author>
<author>E Olivares</author>
</authors>
<title>An ERP study of expectancy violation in face perception.</title>
<date>1994</date>
<journal>Brain and Cognition,</journal>
<volume>26</volume>
<pages>1--22</pages>
<contexts>
<context citStr="Bobes, Valdés-Sosa, &amp; Olivares, 1994" endWordPosition="1296" position="8523" startWordPosition="1292">Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 Th</context>
</contexts>
<marker>Bobes, Valdés-Sosa, Olivares, 1994</marker>
<rawString>Bobes, M. A., Valdés-Sosa, M., &amp; Olivares, E. (1994). An ERP study of expectancy violation in face perception. Brain and Cognition, 26, 1–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Brown</author>
<author>P Hagoort</author>
</authors>
<title>The processing nature of the N400: Evidence from masked priming.</title>
<date>1993</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>5</volume>
<pages>34--44</pages>
<contexts>
<context citStr="Brown &amp; Hagoort, 1993" endWordPosition="1062" position="6959" startWordPosition="1059">y investigated in previous ERP research on written, spoken and signed language (e.g. Capek et al., 2009; Kutas, Neville, &amp; Holcomb, 1987). The N400 is a broad negative deflection generally seen at central and parietal scalp sites that peaks about 400 ms after the visual or auditory presentation of a word. Although all content words elicit an N400 component, the ERP response is larger for words that are semantically anomalous or less expected (Hagoort &amp; Brown, 1994; Kutas &amp; Hillyard, 1984); thus the N400 is often interpreted as an index of ease or difficulty in semantic conceptual integration (Brown &amp; Hagoort, 1993; Hagoort &amp; Van Berkum, 2007). For example, for listeners encountering the two sentences ‘‘I like my coffee with milk and sugar’’ and ‘‘I like my coffee with milk and mud,’’ the N400 response to the last word in the second item is expected to be larger. An N400 or N400-like component can also be found in response to orthographically/phonologically legal but non-occurring ‘‘pseudo-words’’ (e.g. ‘‘blork’’), and it has sometimes been reported that pseudo-words elicit a stronger N400 response than semantically incongruent real words (Bentin, 1987; Bentin, McCarthy, &amp; Wood, 1985; Hagoort &amp; Kutas, 1</context>
</contexts>
<marker>Brown, Hagoort, 1993</marker>
<rawString>Brown, C., &amp; Hagoort, P. (1993). The processing nature of the N400: Evidence from masked priming. Journal of Cognitive Neuroscience, 5, 34–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M Capek</author>
<author>G Grossi</author>
<author>A J Newman</author>
<author>S L McBurney</author>
<author>D Corina</author>
<author>B Roeder</author>
</authors>
<title>Brain systems mediating semantic and syntactic processing in deaf native signers: Biological invariance and modality specificity.</title>
<date>2009</date>
<booktitle>Proceedings of the National Academy of Sciences of the United States of America,</booktitle>
<volume>106</volume>
<pages>8784--8789</pages>
<contexts>
<context citStr="Capek et al., 2009" endWordPosition="974" position="6441" startWordPosition="971">untered non-linguistic manual forms (here ‘‘self-grooming’’ behaviors, e.g. scratching the face, rubbing one’s eye, adjusting the sleeves of a shirt, etc.). We sought to compare the processing of these non-linguistic gestural forms within a sentential context to cases in which deaf signers encountered violations of semantic expectancy that have been observed to elicit a well-defined electrophysiological component, the N400. The N400 component (Holcomb &amp; Neville, 1991; Kutas &amp; Hillyard, 1980) has been frequently investigated in previous ERP research on written, spoken and signed language (e.g. Capek et al., 2009; Kutas, Neville, &amp; Holcomb, 1987). The N400 is a broad negative deflection generally seen at central and parietal scalp sites that peaks about 400 ms after the visual or auditory presentation of a word. Although all content words elicit an N400 component, the ERP response is larger for words that are semantically anomalous or less expected (Hagoort &amp; Brown, 1994; Kutas &amp; Hillyard, 1984); thus the N400 is often interpreted as an index of ease or difficulty in semantic conceptual integration (Brown &amp; Hagoort, 1993; Hagoort &amp; Van Berkum, 2007). For example, for listeners encountering the two sen</context>
<context citStr="Capek et al. (2009)" endWordPosition="1451" position="9589" startWordPosition="1448">Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 This possibility is bolstered by recent work of Albert Kim and colleagues, who have found that relative to real word controls, N400 amplitude decreases and P600 amplitude increases, parametrically, as orthographic irregularity increases (Kim &amp; Pitkänen, submitted for publication).spoken and written language, and more recent work has shown that these components can be elicited in the visual–manual modality as well. For example, in a recent study Capek et al. (2009) compared ERP responses to semantically and syntactically well-formed and ill-formed sentences.While semantic violations elicited anN400 that was largest over central and posterior sites, syntactic violations elicited an anterior negativity followed by a widely distributed P600. Thesefindings are consistentwith the idea thatwithinwritten, spoken and signed languages, semantic and syntactic processes are mediated by non-identical brain systems (Capek et al., 2009). The present study makes use of dynamic video stimuli showing ASL sentences completed by four classes of ending item—semantically co</context>
<context citStr="Capek et al., 2009" endWordPosition="6412" position="40307" startWordPosition="6409">n the incongruent sings. In addition, we suggested that the non-linguistic gestures might elicit a positive-going wave, relative to baseline. While this last prediction was more speculative than the others, the expected pattern was in fact observed very consistently in our analysis of the data. Together, these findings lead to a number of important observations. First, the outcome of our incongruent sign vs. congruent sign comparison replicates earlier findings which have also indicated that the N400 generalizes across modalities, including the visual– manual modality of signed language (e.g. Capek et al., 2009; Kutas et al., 1987). These findings are broadly consistent with other studies using a variety of methodologies including positron emission tomography (PET; Corina, San Jose-Robertson, Guillemin, High, &amp; Braun, 2003), functional magnetic resonance imaging (fMRI; Neville et al., 1998), and cortical stimulation mapping (Corina et al., 1999), highlighting key neural processing similarities between signed and spoken language, in spite of the obvious physical differences in the linguistic signal. For instance, Neville et al. (1997) also found that deaf signers exhibited an N400 response to semanti</context>
</contexts>
<marker>Capek, Grossi, Newman, McBurney, Corina, Roeder, 2009</marker>
<rawString>Capek, C. M., Grossi, G., Newman, A. J., McBurney, S. L., Corina, D., Roeder, B., et al. (2009). Brain systems mediating semantic and syntactic processing in deaf native signers: Biological invariance and modality specificity. Proceedings of the National Academy of Sciences of the United States of America, 106, 8784–8789.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L L Chao</author>
<author>L Nielsen-Bohlman</author>
<author>R T Knight</author>
</authors>
<title>Auditory event-related potentials dissociate early and late memory processes.</title>
<date>1995</date>
<journal>Electroencephalography &amp; Clinical Neurophysiology,</journal>
<volume>96</volume>
<pages>157--168</pages>
<contexts>
<context citStr="Chao, Nielsen-Bohlman, &amp; Knight, 1995" endWordPosition="1303" position="8585" startWordPosition="1299">ct the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 This possibility is bolstered by recent work of Albert Kim and c</context>
</contexts>
<marker>Chao, Nielsen-Bohlman, Knight, 1995</marker>
<rawString>Chao, L. L., Nielsen-Bohlman, L., &amp; Knight, R. T. (1995). Auditory event-related potentials dissociate early and late memory processes. Electroencephalography &amp; Clinical Neurophysiology, 96, 157–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C Corballis</author>
</authors>
<title>The evolution of language.</title>
<date>2009</date>
<journal>Annals of the New York Academy of Sciences,</journal>
<volume>1156</volume>
<contexts>
<context citStr="Corballis, 2009" endWordPosition="419" position="2731" startWordPosition="418">s and human den, &amp; Aronoff, 2010; Morford &amp; Kegl, 2000; Senghas, 2005). Even within mature sign languages of Deaf communities, linguistic accounts of sign language structure have also argued that lexical and discourse components of American Sign Language (ASL) and other signed languages may be best understood as being gesturally based (Liddell, 2003). Thus diachronic and synchronic evidence from language research support the contention that signed languages might make use of perceptual systems similar to those through which humans understand or parse human actions and gestures more generally (Corballis, 2009). In contrast, given its linguistic status, sign language perceptionmay require the attunement of specialized sys-N400 Deaf Pseudo-word Grooming gesture 1. Introduction While it is now widely accepted deaf communities around the world r ations of human languages—languag visual–manual modality rather than0093-934X/$ - see front matter  2012 Elsevier Inc. A doi:10.1016/j.bandl.2012.01.005ture (e.g. the performer scratching her face). We found significant N400-like responses in the incongruent and pseudo-sign contexts, while the gestures elicited a large positivity.  2012 Elsevier Inc. All righ</context>
</contexts>
<marker>Corballis, 2009</marker>
<rawString>Corballis, M. C. (2009). The evolution of language. Annals of the New York Academy of Sciences, 1156, 19–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D P Corina</author>
<author>S L McBurney</author>
<author>C Dodrill</author>
<author>K Hinshaw</author>
<author>J Brinkley</author>
<author>G Ojemann</author>
</authors>
<title>Functional roles of Broca’s area and SMG: Evidence from cortical stimulation mapping in a deaf signer.</title>
<date>1999</date>
<journal>NeuroImage,</journal>
<volume>10</volume>
<pages>570--581</pages>
<contexts>
<context citStr="Corina et al., 1999" endWordPosition="6461" position="40648" startWordPosition="6458">f important observations. First, the outcome of our incongruent sign vs. congruent sign comparison replicates earlier findings which have also indicated that the N400 generalizes across modalities, including the visual– manual modality of signed language (e.g. Capek et al., 2009; Kutas et al., 1987). These findings are broadly consistent with other studies using a variety of methodologies including positron emission tomography (PET; Corina, San Jose-Robertson, Guillemin, High, &amp; Braun, 2003), functional magnetic resonance imaging (fMRI; Neville et al., 1998), and cortical stimulation mapping (Corina et al., 1999), highlighting key neural processing similarities between signed and spoken language, in spite of the obvious physical differences in the linguistic signal. For instance, Neville et al. (1997) also found that deaf signers exhibited an N400 response to semantically incongruent ASL sentences, relative to congruent sentences. Like the effects in the present study, this response was broadly distributed and had an onset and peak that the researchers noted was somewhat later Lanthan would be expected for written language, but consistent with earlier studies on auditory language (Holcomb &amp; Neville, 1</context>
</contexts>
<marker>Corina, McBurney, Dodrill, Hinshaw, Brinkley, Ojemann, 1999</marker>
<rawString>Corina, D. P., McBurney, S. L., Dodrill, C., Hinshaw, K., Brinkley, J., &amp; Ojemann, G. (1999). Functional roles of Broca’s area and SMG: Evidence from cortical stimulation mapping in a deaf signer. NeuroImage, 10, 570–581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Corina</author>
<author>Y-S Chiu</author>
<author>H Knapp</author>
<author>R Greenwald</author>
<author>San Jose-Robertson</author>
<author>L</author>
<author>A Braun</author>
</authors>
<title>Neural correlates of human action observation in hearing and deaf subjects.</title>
<date>2007</date>
<journal>Brain Research,</journal>
<volume>1152</volume>
<pages>111--129</pages>
<contexts>
<context citStr="Corina et al., 2007" endWordPosition="144" position="938" startWordPosition="141">role for manual gesture in the development and evolution of human languages (Arbib, 2005, 2008; Gentilucci &amp; Corballis, 2006; Rizzolatti &amp; Arbib, 1998; Tomasello, 2005;Wilcox, 2004). Retems for recognizing sign forms. A comprehensive theory of sign language recognition will be enhanced by providing an account of when and how the processing of sign forms diverges from the processing of human actions in general. Recent behavioral and neuro-imaging studies have reported differences in deaf subjects’ responses to single signs compared to non-linguistic gestures (Corina, Grosvald, &amp; Lachaud, 2011; Corina et al., 2007; Emmorey, Xu, Gannon, Goldin-Meadow, &amp; Braun, 2010; MacSweeney et al., 2004), but no studies to our knowledge have examined the recognition of signs and gestures ⇑ Corresponding author. Address: Department of Neurology, University of California at Irvine, 101 The City Drive South, Bldg. 53, Room 204, Orange, CA 92868- 4280, United States. Fax: +1 714 456 1697. Brain &amp; Language 121 (2012) 12–24 Contents lists available at Brain &amp; La .eE-mail address: m.grosvald@uci.edu (M. Grosvald).question of how a sign is recognized and integrated into a sentential context in real time has received far less</context>
<context citStr="Corina et al., 2007" endWordPosition="1618" position="10871" startWordPosition="1615">egal but non-occurring pseudo-signs, and non-linguistic grooming gestures. Based upon previous studies, we expected a gradation of N400-like responses across conditions, with N400 effects of smaller magnitude for semantically incongruent endingsandof largermagnitude (i.e. more negative) for phonologically legal pseudo-signs. The ERP response for the non-linguistic gesture condition is a priori more difficult to predict. Previous neuro-imaging studies of deaf signers have reported differences in patterns of activation associated with the perception of signs compared to non-linguistic gestures (Corina et al., 2007; Emmorey et al., 2010; MacSweeney et al., 2004), but the methodologies used in those studies lacked the temporal resolution to determine at what stage of processing these differences may occur. While N400-like responses have been elicited to co-speech gestural mismatches (Kelly et al., 2004; Wu &amp; Coulson, 2005), in our study, gestures occur in place of semantically appropriate sentence-ending items, rather than as a possible accompaniment. It should also be borne in mind that the relationship of signs and grooming gestures is probably not quite akin to that between standard lexical items in s</context>
<context citStr="Corina et al. (2007)" endWordPosition="7021" position="44242" startWordPosition="7018">re activating lexical representations to a substantial degree (cf. Friedrich, Eulitz, &amp; Lahiri, 2006), and that at the same time, these representations are incongruent with the sentential contexts in which they have been presented. The pseudo-sign and incongruent sign conditions shared another similarity in that the effects they elicited were very prominent at occipital sites, which differs from what has traditionally been observed in studies of word processing. Whether this is a reflection of the modality of expression or other experimental factors must await further study, though results of Corina et al. (2007), discussed below, may offer some insights about useful directions such research might take. A third set of findings, concerning the outcome related to our non-linguistic grooming actions, is especially provocative. In contrast to the three other kinds of sentence-final items, all of which could be considered linguistic (i.e. as actual lexical items in two cases, and phonologically legal lexical gaps in the third), the non-linguistic grooming actions elicited a large positivity. As noted earlier, phonologically illegal words in ERP studies have in some cases elicited a positive-going component</context>
<context citStr="Corina et al. (2007)" endWordPosition="8375" position="53005" startWordPosition="8372">esting parallel integration of speech and gesture in this context. In contrast, the grooming gesture condition in the present study was not associated with any N400-like effects. We suggest that this is due to the fact that subjects were unlikely to perceive these actions as being akin to co-speech (or co-sign) gestures, but instead as something qualitatively different. This detection process evidently occurred quite rapidly during online processing of these stimuli, comparable to the speed at which semantic processing was carried out for the linguistic stimuli. The findings of a PET study by Corina et al. (2007) may shed some additional light on this outcome. In that study, deaf signers were found to have engaged different brain regions when processing ASL signs and selfgrooming gestures, in contrast with the hearing non-signers who also took part in the study. Specifically, deaf signers engaged lefthemisphere perisylvian language areas when processing ASL sign forms, but recruited middle-occipital temporal–ventral regions when processing self-grooming actions. The latter areas are known to be involved in the detection of human bodies, faces, and movements. The present findings add temporal precision</context>
<context citStr="Corina et al. (2007)" endWordPosition="9037" position="57299" startWordPosition="9034">dy’s gesture condition were strongest in posterior areas as well, though in both cases, one must be cautious in making a connection between the scalp topography of ERP effects and location of their source.4 Finally, an alternative interpretation of the positivity seen in the grooming gesture condition in the present study is that it is due to subjects’ interpreting these non-linguistic final items as missing information, i.e. as the absence of a final item, rather than a final4 It should also be noted that the effects seen in the present study were for gestures in a sentence context, while in Corina et al. (2007) the sign and gesture stimuli were seen in isolation. 120 unique gesture stimuli, the actions were performed with differences in the number and configuration of hands or fingers used, the location of the body involved, and so on. Also shown in the rightmost two columns of the table are the ‘‘correct’’ and ‘‘incorrect’’ word choices for the occasional quiz items. A number sign (#) preceding an item means that item was fingerspelled. Many of these sentences were adapted from the English-language stimuli used in Johnson and Hamm (2000). Table A1 FRAME Semantically congruent Semantically incongrue</context>
</contexts>
<marker>Corina, Chiu, Knapp, Greenwald, Jose-Robertson, L, Braun, 2007</marker>
<rawString>Corina, D., Chiu, Y.-S., Knapp, H., Greenwald, R., San Jose-Robertson, L., &amp; Braun, A. (2007). Neural correlates of human action observation in hearing and deaf subjects. Brain Research, 1152, 111–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D P Corina</author>
<author>H P Knapp</author>
</authors>
<title>Psycholinguistic and neurolinguistic perspectives on sign languages.</title>
<date>2006</date>
<booktitle>Handbook of psycholinguistics (2nd ed.,</booktitle>
<pages>1001--1024</pages>
<editor>In M. J. Traxler &amp; M. A. Gernsbacher (Eds.),</editor>
<publisher>Academic Press.</publisher>
<location>San Diego, CA:</location>
<contexts>
<context citStr="Corina &amp; Knapp, 2006" endWordPosition="245" position="1574" startWordPosition="242">annon, Goldin-Meadow, &amp; Braun, 2010; MacSweeney et al., 2004), but no studies to our knowledge have examined the recognition of signs and gestures ⇑ Corresponding author. Address: Department of Neurology, University of California at Irvine, 101 The City Drive South, Bldg. 53, Room 204, Orange, CA 92868- 4280, United States. Fax: +1 714 456 1697. Brain &amp; Language 121 (2012) 12–24 Contents lists available at Brain &amp; La .eE-mail address: m.grosvald@uci.edu (M. Grosvald).question of how a sign is recognized and integrated into a sentential context in real time has received far less attention (see Corina &amp; Knapp, 2006; Emmorey, 2002; for some discussions). Sign language recognition may be more complicated than spoken language recognition by virtue of the fact that the primary articulators, the hands and arms, are also used in a wide range of other common everyday behaviors that include non-linguistic actions such a reaching and grasping, waving, and scratching oneself, as well gesticulations that accompany speech (i.e. co-speech gestures) or serve non-sign language deictic functions, such as pointing. The formal relationship between signed languages and human den, &amp; Aronoff, 2010; Morford &amp; Kegl, 2000; Sen</context>
</contexts>
<marker>Corina, Knapp, 2006</marker>
<rawString>Corina, D. P., &amp; Knapp, H. P. (2006). Psycholinguistic and neurolinguistic perspectives on sign languages. In M. J. Traxler &amp; M. A. Gernsbacher (Eds.), Handbook of psycholinguistics (2nd ed., pp. 1001–1024). San Diego, CA: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D P Corina</author>
<author>San Jose-Robertson</author>
<author>L Guillemin</author>
<author>A High</author>
<author>J</author>
<author>A R Braun</author>
</authors>
<title>Language lateralization in a bimanual language.</title>
<date>2003</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>15</volume>
<pages>718--730</pages>
<marker>Corina, Jose-Robertson, Guillemin, High, J, Braun, 2003</marker>
<rawString>Corina, D. P., San Jose-Robertson, L., Guillemin, A., High, J., &amp; Braun, A. R. (2003). Language lateralization in a bimanual language. Journal of Cognitive Neuroscience, 15, 718–730.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Corina</author>
<author>M Grosvald</author>
<author>C Lachaud</author>
</authors>
<title>Perceptual invariance or orientation specificity in American Sign Language? Evidence from repetition priming for signs and gestures.</title>
<date>2011</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<volume>26</volume>
<pages>1102--1135</pages>
<contexts>
<context citStr="Corina, Grosvald, &amp; Lachaud, 2011" endWordPosition="140" position="917" startWordPosition="136">cientists have proposed a critical role for manual gesture in the development and evolution of human languages (Arbib, 2005, 2008; Gentilucci &amp; Corballis, 2006; Rizzolatti &amp; Arbib, 1998; Tomasello, 2005;Wilcox, 2004). Retems for recognizing sign forms. A comprehensive theory of sign language recognition will be enhanced by providing an account of when and how the processing of sign forms diverges from the processing of human actions in general. Recent behavioral and neuro-imaging studies have reported differences in deaf subjects’ responses to single signs compared to non-linguistic gestures (Corina, Grosvald, &amp; Lachaud, 2011; Corina et al., 2007; Emmorey, Xu, Gannon, Goldin-Meadow, &amp; Braun, 2010; MacSweeney et al., 2004), but no studies to our knowledge have examined the recognition of signs and gestures ⇑ Corresponding author. Address: Department of Neurology, University of California at Irvine, 101 The City Drive South, Bldg. 53, Room 204, Orange, CA 92868- 4280, United States. Fax: +1 714 456 1697. Brain &amp; Language 121 (2012) 12–24 Contents lists available at Brain &amp; La .eE-mail address: m.grosvald@uci.edu (M. Grosvald).question of how a sign is recognized and integrated into a sentential context in real time </context>
</contexts>
<marker>Corina, Grosvald, Lachaud, 2011</marker>
<rawString>Corina, D., Grosvald, M., &amp; Lachaud, C. (2011). Perceptual invariance or orientation specificity in American Sign Language? Evidence from repetition priming for signs and gestures. Language and Cognitive Processes, 26, 1102–1135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cornejo</author>
<author>F Simonetti</author>
<author>A Ibáñez</author>
<author>N Aldunate</author>
<author>V López</author>
<author>F Ceric</author>
</authors>
<title>Gesture and metaphor comprehension: Electrophysiological evidence of crossmodal coordination by audiovisual stimulation.</title>
<date>2009</date>
<journal>Brain and Cognition,</journal>
<volume>70</volume>
<pages>42--52</pages>
<contexts>
<context citStr="Cornejo et al., 2009" endWordPosition="7970" position="50389" startWordPosition="7967">nigmatic. While this cannot be entirely Language 121 (2012) 12–24We have already alluded to the growing number of studies which have used ERP methodology to examine the contributions of co-speech manual gestures to the interpretation of both linguistic and non-linguistic stimuli (Holle &amp; Gunter, 2007; Kelly et al., 2004; Ozyürek, Willems, Kita, &amp; Hagoort, 2007; Wu &amp; Coulson, 2005, 2007a, 2007b). Many of these studies have used iconic manual gestures that depict a salient visual–spatial property of concrete objects, such as their size and shape or an associated manner of movement (but see also Cornejo et al., 2009). Collectively these studies suggest that co-speech manual gestures influence semantic representations, and that discrepancies between gestural forms and the semantic contexts in which they occur lead to greater processing costs on the part of language perceivers. This in turn results in increased negativities in the time window often associated with the classic N400 effect, observed in response to word meanings that violate the wider semantic context (Kutas &amp; Hillyard, 1980). For example, Kelly et al. (2004) observed modulation of ERP responses for speech tokens that were either accompanied b</context>
</contexts>
<marker>Cornejo, Simonetti, Ibáñez, Aldunate, López, Ceric, 2009</marker>
<rawString>Cornejo, C., Simonetti, F., Ibáñez, A., Aldunate, N., López, V., &amp; Ceric, F. (2009). Gesture and metaphor comprehension: Electrophysiological evidence of crossmodal coordination by audiovisual stimulation. Brain and Cognition, 70, 42–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Delorme</author>
<author>S Makeig</author>
</authors>
<title>EEGLAB: An open source toolbox for analysis of single-trial EEG dynamics.</title>
<date>2004</date>
<journal>Journal of Neuroscience Methods,</journal>
<volume>134</volume>
<pages>9--21</pages>
<contexts>
<context citStr="Delorme &amp; Makeig, 2004" endWordPosition="4284" position="27235" startWordPosition="4281">ongruent and pseudosign conditions can be seen to have elicited negative-going waves. In addition, the pseudo-sign negativity is generally greater in magnitude than the negativity elicited in the semantically incongruent condition. In contrast, beginning at approximately 400 ms we ob-the average of the left and right mastoids. The EEG was digitized online at 256 Hz, and filtered offline below 30 Hz and above 0.01 Hz. Scalp electrode impedance threshold values were set at 20 kX. Initial analysis of the EEG data was performed using the ERPLAB plugin (Lopez-Calderon &amp; Luck, in press) for EEGLAB (Delorme &amp; Makeig, 2004). Epochs began 200 ms before stimulus onset and ended 1000 ms after. Inspection of subjects’ EEG data was performed by eye to check rejections suggested by a script run in ERPLAB whose artifact rejection thresholds were set at ±120 lV. For all 16 subjects, in each of the four sentence ending conditions at least 20 of the original 30 trials remained after the rejection procedure just described. The statistical analyses reported below were carried out using the SPSS statistical package. To assess the significance of the observed effects, a column analysis was conducted (cf. Kim &amp; Osterhout, 2005</context>
</contexts>
<marker>Delorme, Makeig, 2004</marker>
<rawString>Delorme, A., &amp; Makeig, S. (2004). EEGLAB: An open source toolbox for analysis of single-trial EEG dynamics. Journal of Neuroscience Methods, 134, 9–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Emmorey</author>
</authors>
<title>Language, cognition, and the brain: Insights from sign language research.</title>
<date>2002</date>
<location>Mahwah, NJ: Lawrence Erlbaum.</location>
<contexts>
<context citStr="Emmorey, 2002" endWordPosition="247" position="1589" startWordPosition="246">&amp; Braun, 2010; MacSweeney et al., 2004), but no studies to our knowledge have examined the recognition of signs and gestures ⇑ Corresponding author. Address: Department of Neurology, University of California at Irvine, 101 The City Drive South, Bldg. 53, Room 204, Orange, CA 92868- 4280, United States. Fax: +1 714 456 1697. Brain &amp; Language 121 (2012) 12–24 Contents lists available at Brain &amp; La .eE-mail address: m.grosvald@uci.edu (M. Grosvald).question of how a sign is recognized and integrated into a sentential context in real time has received far less attention (see Corina &amp; Knapp, 2006; Emmorey, 2002; for some discussions). Sign language recognition may be more complicated than spoken language recognition by virtue of the fact that the primary articulators, the hands and arms, are also used in a wide range of other common everyday behaviors that include non-linguistic actions such a reaching and grasping, waving, and scratching oneself, as well gesticulations that accompany speech (i.e. co-speech gestures) or serve non-sign language deictic functions, such as pointing. The formal relationship between signed languages and human den, &amp; Aronoff, 2010; Morford &amp; Kegl, 2000; Senghas, 2005). Ev</context>
</contexts>
<marker>Emmorey, 2002</marker>
<rawString>Emmorey, K. (2002). Language, cognition, and the brain: Insights from sign language research. Mahwah, NJ: Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Emmorey</author>
<author>J Xu</author>
<author>P Gannon</author>
<author>S Goldin-Meadow</author>
<author>A Braun</author>
</authors>
<title>CNS activation and regional connectivity during pantomime observation: No engagement of the mirror neuron system for deaf signers.</title>
<date>2010</date>
<journal>NeuroImage,</journal>
<volume>49</volume>
<pages>994--1005</pages>
<contexts>
<context citStr="Emmorey, Xu, Gannon, Goldin-Meadow, &amp; Braun, 2010" endWordPosition="151" position="989" startWordPosition="145">re in the development and evolution of human languages (Arbib, 2005, 2008; Gentilucci &amp; Corballis, 2006; Rizzolatti &amp; Arbib, 1998; Tomasello, 2005;Wilcox, 2004). Retems for recognizing sign forms. A comprehensive theory of sign language recognition will be enhanced by providing an account of when and how the processing of sign forms diverges from the processing of human actions in general. Recent behavioral and neuro-imaging studies have reported differences in deaf subjects’ responses to single signs compared to non-linguistic gestures (Corina, Grosvald, &amp; Lachaud, 2011; Corina et al., 2007; Emmorey, Xu, Gannon, Goldin-Meadow, &amp; Braun, 2010; MacSweeney et al., 2004), but no studies to our knowledge have examined the recognition of signs and gestures ⇑ Corresponding author. Address: Department of Neurology, University of California at Irvine, 101 The City Drive South, Bldg. 53, Room 204, Orange, CA 92868- 4280, United States. Fax: +1 714 456 1697. Brain &amp; Language 121 (2012) 12–24 Contents lists available at Brain &amp; La .eE-mail address: m.grosvald@uci.edu (M. Grosvald).question of how a sign is recognized and integrated into a sentential context in real time has received far less attention (see Corina &amp; Knapp, 2006; Emmorey, 2002</context>
<context citStr="Emmorey et al., 2010" endWordPosition="1622" position="10893" startWordPosition="1619">g pseudo-signs, and non-linguistic grooming gestures. Based upon previous studies, we expected a gradation of N400-like responses across conditions, with N400 effects of smaller magnitude for semantically incongruent endingsandof largermagnitude (i.e. more negative) for phonologically legal pseudo-signs. The ERP response for the non-linguistic gesture condition is a priori more difficult to predict. Previous neuro-imaging studies of deaf signers have reported differences in patterns of activation associated with the perception of signs compared to non-linguistic gestures (Corina et al., 2007; Emmorey et al., 2010; MacSweeney et al., 2004), but the methodologies used in those studies lacked the temporal resolution to determine at what stage of processing these differences may occur. While N400-like responses have been elicited to co-speech gestural mismatches (Kelly et al., 2004; Wu &amp; Coulson, 2005), in our study, gestures occur in place of semantically appropriate sentence-ending items, rather than as a possible accompaniment. It should also be borne in mind that the relationship of signs and grooming gestures is probably not quite akin to that between standard lexical items in spoken language and the</context>
</contexts>
<marker>Emmorey, Xu, Gannon, Goldin-Meadow, Braun, 2010</marker>
<rawString>Emmorey, K., Xu, J., Gannon, P., Goldin-Meadow, S., &amp; Braun, A. (2010). CNS activation and regional connectivity during pantomime observation: No engagement of the mirror neuron system for deaf signers. NeuroImage, 49, 994–1005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedrich</author>
<author>C Eulitz</author>
<author>A Lahiri</author>
</authors>
<title>Not every pseudoword disrupts word recognition: An ERP study.</title>
<date>2006</date>
<journal>Behavioral and Brain Functions,</journal>
<volume>2</volume>
<pages>36</pages>
<contexts>
<context citStr="Friedrich, Eulitz, &amp; Lahiri, 2006" endWordPosition="6940" position="43722" startWordPosition="6936">ntically incongruent but fully lexical signs. This provides further evidence for broad processing similarities for different linguistic modalities, in the light of similar findings for pseudo-words in earlier studies (Bentin, 1987; Bentin et al., 1985; Hagoort &amp; Kutas, 1995). It is interesting, however, that phonologically legal pseudo-signs did not more strongly differentiate from the semantically incongruent signs in the present study. This may be an indication that our pseudo-signs (or some of their sub-lexical components) are activating lexical representations to a substantial degree (cf. Friedrich, Eulitz, &amp; Lahiri, 2006), and that at the same time, these representations are incongruent with the sentential contexts in which they have been presented. The pseudo-sign and incongruent sign conditions shared another similarity in that the effects they elicited were very prominent at occipital sites, which differs from what has traditionally been observed in studies of word processing. Whether this is a reflection of the modality of expression or other experimental factors must await further study, though results of Corina et al. (2007), discussed below, may offer some insights about useful directions such research</context>
</contexts>
<marker>Friedrich, Eulitz, Lahiri, 2006</marker>
<rawString>Friedrich, C., Eulitz, C., &amp; Lahiri, A. (2006). Not every pseudoword disrupts word recognition: An ERP study. Behavioral and Brain Functions, 2, 36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A D Friederici</author>
</authors>
<title>Towards a neural basis of auditory sentence processing.</title>
<date>2002</date>
<journal>Trends in Cognitive Sciences,</journal>
<volume>6</volume>
<pages>78--84</pages>
<contexts>
<context citStr="Friederici, 2002" endWordPosition="1354" position="8945" startWordPosition="1353">stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 This possibility is bolstered by recent work of Albert Kim and colleagues, who have found that relative to real word controls, N400 amplitude decreases and P600 amplitude increases, parametrically, as orthographic irregularity increases (Kim &amp; Pitkänen, submitted for publication).spoken and written language, and more recent work has shown that these components can be elicited in the visual–manual modality as well. For ex</context>
</contexts>
<marker>Friederici, 2002</marker>
<rawString>Friederici, A. D. (2002). Towards a neural basis of auditory sentence processing. Trends in Cognitive Sciences, 6, 78–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Frishberg</author>
</authors>
<title>Ghanaian Sign Language. In</title>
<date>1987</date>
<publisher>McGraw-Gill Book Company.</publisher>
<location>New York:</location>
<contexts>
<context citStr="Frishberg, 1987" endWordPosition="560" position="3749" startWordPosition="559">e performer scratching her face). We found significant N400-like responses in the incongruent and pseudo-sign contexts, while the gestures elicited a large positivity.  2012 Elsevier Inc. All rights reserved. gned languages used in nt full-fledged instantich are expressed in the ral–oral modality—the cently, linguists have documented compelling evidence that the development of nascent sign languages derives from idiosyncratic gestural and pantomimic systems used by isolated communities, which in some casesmay be limited to individual families who have a need to communicate with a deaf child (Frishberg, 1987; GoldinMeadow, 2003; Kegl, Senghas, &amp; Coppola, 1999; Meir, Sandler, Pad-Sign language ASL high-close-probability sign (a ‘‘semantically reasonable’’ completion to the sentence; e.g. BED), a lowclose-probability sign (a real sign that is nonetheless a ‘‘semantically odd’’ completion to the sentence;Dissociating linguistic and non-linguistic Electrophysiological evidence from Amer Michael Grosvald a,⇑, Eva Gutierrez b, Sarah Hafer b, D aDepartment of Neurology, University of California at Irvine, United States bCenter for Mind and Brain, University of California at Davis, United States cDepartm</context>
</contexts>
<marker>Frishberg, 1987</marker>
<rawString>Frishberg, N. (1987). Ghanaian Sign Language. In J. Van Cleve (Ed.), Gallaudet encyclopaedia of deaf people and deafness. New York: McGraw-Gill Book Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ganis</author>
<author>M Kutas</author>
</authors>
<title>An electrophysiological study of scene effects on object identification.</title>
<date>2003</date>
<journal>Cognitive Brain Research,</journal>
<volume>16</volume>
<pages>123--144</pages>
<contexts>
<context citStr="Ganis &amp; Kutas, 2003" endWordPosition="1274" position="8375" startWordPosition="1271">rds’’ (e.g. ‘‘rbsnk’’) do not generally elicit an N400, and a positive component is sometimes seen instead (Hagoort &amp; Kutas, 1995; Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forst</context>
</contexts>
<marker>Ganis, Kutas, 2003</marker>
<rawString>Ganis, G., &amp; Kutas, M. (2003). An electrophysiological study of scene effects on object identification. Cognitive Brain Research, 16, 123–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ganis</author>
<author>M Kutas</author>
<author>M I Sereno</author>
</authors>
<title>The search for ‘‘common sense’’: An electrophysiological study of the comprehension of words and pictures in reading.</title>
<date>1996</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>8</volume>
<pages>89--106</pages>
<contexts>
<context citStr="Ganis, Kutas, &amp; Sereno, 1996" endWordPosition="1279" position="8405" startWordPosition="1275">) do not generally elicit an N400, and a positive component is sometimes seen instead (Hagoort &amp; Kutas, 1995; Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 </context>
</contexts>
<marker>Ganis, Kutas, Sereno, 1996</marker>
<rawString>Ganis, G., Kutas, M., &amp; Sereno, M. I. (1996). The search for ‘‘common sense’’: An electrophysiological study of the comprehension of words and pictures in reading. Journal of Cognitive Neuroscience, 8, 89–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gentilucci</author>
<author>M Corballis</author>
</authors>
<title>From manual gesture to speech: A gradual transition.</title>
<date>2006</date>
<journal>Neuroscience &amp; Biobehavioral Reviews,</journal>
<volume>30</volume>
<pages>949--960</pages>
<marker>Gentilucci, Corballis, 2006</marker>
<rawString>Gentilucci, M., &amp; Corballis, M. (2006). From manual gesture to speech: A gradual transition. Neuroscience &amp; Biobehavioral Reviews, 30, 949–960.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldin-Meadow</author>
</authors>
<title>Hearing gestures: How our hands help us think.</title>
<date>2003</date>
<publisher>Harvard University Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Goldin-Meadow, 2003</marker>
<rawString>Goldin-Meadow, S. (2003). Hearing gestures: How our hands help us think. Cambridge, MA: Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W W Greenhouse</author>
<author>S Geisser</author>
</authors>
<title>On methods in the analysis of profile data.</title>
<date>1959</date>
<journal>Psychometrika,</journal>
<volume>24</volume>
<pages>95--112</pages>
<contexts>
<context citStr="Greenhouse &amp; Geisser, 1959" endWordPosition="3998" position="25385" startWordPosition="3994">ree ANOVAs the factor Electrode had one level for each pair of electrodes, from most anterior to most posterior. For the N400 analysis, the dependent measure was mean amplitude of EEG response within the window from 400 to 600 ms after stimulus onset. Because the latency of the effects related to gesture was somewhat greater, a second column analysis was run for the window from 600 to 800 ms after stimulus onset. For the purposes of these column analyses, data from the two frontmost sites (FP1 and FP2) and from two posterior sites (PO3 and PO4) were not used. In all cases, Greenhouse–Geisser (Greenhouse &amp; Geisser, 1959) adjustments for non-sphericity were performed where appropriate and are reflected in the reported results. In the following section, the outcomes for the ANOVAs performed for each time window will be given in the order midline, inner, outer, and outermost. This establishes the significance of the results, which we first introduce with illustrations and descriptions of the waveforms and the associated topographic maps. 3. Results 3.1. Waveforms and topographic maps Pictured in Figs. 3 and 4 are grand-average waveforms at selected electrode sites for the four sentence Ending conditions. Visual </context>
</contexts>
<marker>Greenhouse, Geisser, 1959</marker>
<rawString>Greenhouse, W. W., &amp; Geisser, S. (1959). On methods in the analysis of profile data. Psychometrika, 24, 95–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hagoort</author>
<author>C Brown</author>
</authors>
<title>Brain responses to lexical ambiguity resolution and parsing. In</title>
<date>1994</date>
<pages>45--80</pages>
<location>Hillsdale, NJ, UK:</location>
<contexts>
<context citStr="Hagoort &amp; Brown, 1994" endWordPosition="1036" position="6806" startWordPosition="1033">o elicit a well-defined electrophysiological component, the N400. The N400 component (Holcomb &amp; Neville, 1991; Kutas &amp; Hillyard, 1980) has been frequently investigated in previous ERP research on written, spoken and signed language (e.g. Capek et al., 2009; Kutas, Neville, &amp; Holcomb, 1987). The N400 is a broad negative deflection generally seen at central and parietal scalp sites that peaks about 400 ms after the visual or auditory presentation of a word. Although all content words elicit an N400 component, the ERP response is larger for words that are semantically anomalous or less expected (Hagoort &amp; Brown, 1994; Kutas &amp; Hillyard, 1984); thus the N400 is often interpreted as an index of ease or difficulty in semantic conceptual integration (Brown &amp; Hagoort, 1993; Hagoort &amp; Van Berkum, 2007). For example, for listeners encountering the two sentences ‘‘I like my coffee with milk and sugar’’ and ‘‘I like my coffee with milk and mud,’’ the N400 response to the last word in the second item is expected to be larger. An N400 or N400-like component can also be found in response to orthographically/phonologically legal but non-occurring ‘‘pseudo-words’’ (e.g. ‘‘blork’’), and it has sometimes been reported tha</context>
</contexts>
<marker>Hagoort, Brown, 1994</marker>
<rawString>Hagoort, P., &amp; Brown, C. (1994). Brain responses to lexical ambiguity resolution and parsing. In L. Frazier, J. Clifton Charles, &amp; K. Rayner (Eds.), Perspectives in sentence processing (pp. 45–80). Hillsdale, NJ, UK: Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hagoort</author>
<author>M Kutas</author>
</authors>
<title>Electrophysiological insights into language deficits.</title>
<date>1995</date>
<booktitle>In F. Boller &amp; J. Grafman (Eds.), Handbook of neuropsychology</booktitle>
<pages>105--134</pages>
<publisher>Elsevier.</publisher>
<location>Amsterdam:</location>
<contexts>
<context citStr="Hagoort &amp; Kutas, 1995" endWordPosition="1158" position="7563" startWordPosition="1155">wn &amp; Hagoort, 1993; Hagoort &amp; Van Berkum, 2007). For example, for listeners encountering the two sentences ‘‘I like my coffee with milk and sugar’’ and ‘‘I like my coffee with milk and mud,’’ the N400 response to the last word in the second item is expected to be larger. An N400 or N400-like component can also be found in response to orthographically/phonologically legal but non-occurring ‘‘pseudo-words’’ (e.g. ‘‘blork’’), and it has sometimes been reported that pseudo-words elicit a stronger N400 response than semantically incongruent real words (Bentin, 1987; Bentin, McCarthy, &amp; Wood, 1985; Hagoort &amp; Kutas, 1995), consistent with the idea that the magnitude of N400 response is related to the difficulty of the ongoing process of semantic-contextual integration. However, orthographically illegal ‘‘non-words’’ (e.g. ‘‘rbsnk’’) do not generally elicit an N400, and a positive component is sometimes seen instead (Hagoort &amp; Kutas, 1995; Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during </context>
<context citStr="Hagoort &amp; Kutas, 1995" endWordPosition="1844" position="12326" startWordPosition="1841">s routine experience. A better spoken-language analogue of our grooming action condition might be something like ‘‘I like my coffee with milk and [clearing of throat],’’ though we know of no spoken-language studies which have incorporated such a condition. The non-linguistic grooming gestures used in the present study may be another example of forms that language users (in this case, signers) are able to quickly reject as non-linguistic during language processing. If this is the case, then one might also expect that such forms will not elicit an N400 but rather a positive-going component (cf. Hagoort &amp; Kutas, 1995). In summary, to the extent that semantic processing at the sentence level is similar for signed and spoken language, despite the obvious difference in modality, the ERP responses associated with our four sentence ending condition should be predictable. First, the incongruent signs should elicit a negative-going component relative to the baseline (congruent sign) condition, consistent with the classic N400 response seen for English and other spoken languages, as well as some previous ERP studies of ASL (Kutas et al., 1987; Neville et al., 1997). Second, the pseudo-signs should also elicit a ne</context>
<context citStr="Hagoort &amp; Kutas, 1995" endWordPosition="4112" position="26128" startWordPosition="4109">ing section, the outcomes for the ANOVAs performed for each time window will be given in the order midline, inner, outer, and outermost. This establishes the significance of the results, which we first introduce with illustrations and descriptions of the waveforms and the associated topographic maps. 3. Results 3.1. Waveforms and topographic maps Pictured in Figs. 3 and 4 are grand-average waveforms at selected electrode sites for the four sentence Ending conditions. Visual inspection of the waveforms reveals that all conditions evoked exogenous potentials often associated with written words (Hagoort &amp; Kutas, 1995); these include a posteriorly distributed positivity (P1) peaking at about 100 ms post-stimulus onset, followed by a posteriorly distributed negativity (N1) peaking at about 180 ms after target onset. Starting at approximately 300 ms after stimulus onset, we begin to see a differentiation for different sentence ending conditions which we will quantify in detail in the statistical analysis. Relative to the baseline (semantically congruent sign) condition, both the semantically incongruent and pseudosign conditions can be seen to have elicited negative-going waves. In addition, the pseudo-sign n</context>
<context citStr="Hagoort &amp; Kutas, 1995" endWordPosition="6889" position="43364" startWordPosition="6886">n the present study was quite evident at occipital sites, as can be seen clearly in Figs. 3 and 4. A second notable finding in our study concerns deaf subjects’ ERP response in the phonologically legal pseudo-sign condition, which was also consistent with an N400 response but was generally larger (more negative) than the negativity seen for semantically incongruent but fully lexical signs. This provides further evidence for broad processing similarities for different linguistic modalities, in the light of similar findings for pseudo-words in earlier studies (Bentin, 1987; Bentin et al., 1985; Hagoort &amp; Kutas, 1995). It is interesting, however, that phonologically legal pseudo-signs did not more strongly differentiate from the semantically incongruent signs in the present study. This may be an indication that our pseudo-signs (or some of their sub-lexical components) are activating lexical representations to a substantial degree (cf. Friedrich, Eulitz, &amp; Lahiri, 2006), and that at the same time, these representations are incongruent with the sentential contexts in which they have been presented. The pseudo-sign and incongruent sign conditions shared another similarity in that the effects they elicited we</context>
</contexts>
<marker>Hagoort, Kutas, 1995</marker>
<rawString>Hagoort, P., &amp; Kutas, M. (1995). Electrophysiological insights into language deficits. In F. Boller &amp; J. Grafman (Eds.), Handbook of neuropsychology (pp. 105–134). Amsterdam: Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hagoort</author>
<author>J van Berkum</author>
</authors>
<title>Beyond the sentence given.</title>
<date>2007</date>
<journal>Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences, 362, M. Grosvald</journal>
<pages>801--811</pages>
<marker>Hagoort, van Berkum, 2007</marker>
<rawString>Hagoort, P., &amp; van Berkum, J. (2007). Beyond the sentence given. Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences, 362, M. Grosvald et al. / Brain &amp;801–811.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Holcomb</author>
<author>W B McPherson</author>
</authors>
<title>Event-related brain potentials reflect semantic priming in an object decision task.</title>
<date>1994</date>
<journal>Brain and Cognition,</journal>
<volume>24</volume>
<pages>259--276</pages>
<contexts>
<context citStr="Holcomb &amp; McPherson, 1994" endWordPosition="6772" position="42626" startWordPosition="6769">hs and videos. In Wu and Coulson’s (2005) study of contextually incongruent gestures, a component described by the researchers as a ‘‘gesture N450’’ was observed. Wu and Coulson noted the similarity of this effect to the N450 reported by Barrett and Rugg (1990) for second items in unrelated picture pairs relative to related picture pairs (e.g. wrench/fork vs. knife/fork), stating (p. 659) that consistent with their own findings, ‘‘most such ‘picture’ ERP studies report a broadly distributed negativity largest at frontal electrode sites and not evident at occipital sites (Barrett &amp; Rugg, 1990; Holcomb &amp; McPherson, 1994; McPherson &amp; Holcomb, 1999; Sitnikova et al., 2003; West &amp; Holcomb, 2002).’’ In contrast, the negativity reported in the present study was quite evident at occipital sites, as can be seen clearly in Figs. 3 and 4. A second notable finding in our study concerns deaf subjects’ ERP response in the phonologically legal pseudo-sign condition, which was also consistent with an N400 response but was generally larger (more negative) than the negativity seen for semantically incongruent but fully lexical signs. This provides further evidence for broad processing similarities for different linguistic m</context>
</contexts>
<marker>Holcomb, McPherson, 1994</marker>
<rawString>Holcomb, P. J., &amp; McPherson, W. B. (1994). Event-related brain potentials reflect semantic priming in an object decision task. Brain and Cognition, 24, 259–276.Holcomb, P. J., &amp; Neville, H. J. (1990). Auditory and visual semantic priming in lexical decision: A comparison using event-related brain potentials. Language and Cognitive Processes, 5, 281–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Holcomb</author>
<author>H J Neville</author>
</authors>
<title>Natural speech processing: An analysis using event-related brain potentials.</title>
<date>1991</date>
<journal>Psychobiology,</journal>
<volume>19</volume>
<pages>286--300</pages>
<contexts>
<context citStr="Holcomb &amp; Neville, 1991" endWordPosition="949" position="6294" startWordPosition="946">esent paper was to use real-time electrophysiological measures to assess empirically the time course of sentence processing in cases where subjects encountered non-linguistic manual forms (here ‘‘self-grooming’’ behaviors, e.g. scratching the face, rubbing one’s eye, adjusting the sleeves of a shirt, etc.). We sought to compare the processing of these non-linguistic gestural forms within a sentential context to cases in which deaf signers encountered violations of semantic expectancy that have been observed to elicit a well-defined electrophysiological component, the N400. The N400 component (Holcomb &amp; Neville, 1991; Kutas &amp; Hillyard, 1980) has been frequently investigated in previous ERP research on written, spoken and signed language (e.g. Capek et al., 2009; Kutas, Neville, &amp; Holcomb, 1987). The N400 is a broad negative deflection generally seen at central and parietal scalp sites that peaks about 400 ms after the visual or auditory presentation of a word. Although all content words elicit an N400 component, the ERP response is larger for words that are semantically anomalous or less expected (Hagoort &amp; Brown, 1994; Kutas &amp; Hillyard, 1984); thus the N400 is often interpreted as an index of ease or dif</context>
</contexts>
<marker>Holcomb, Neville, 1991</marker>
<rawString>Holcomb, P. J., &amp; Neville, H. J. (1991). Natural speech processing: An analysis using event-related brain potentials. Psychobiology, 19, 286–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Holle</author>
<author>T C Gunter</author>
</authors>
<title>The role of iconic gestures in speech disambiguation: ERP evidence.</title>
<date>2007</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>19</volume>
<pages>1175--1192</pages>
<contexts>
<context citStr="Holle &amp; Gunter, 2007" endWordPosition="7915" position="50069" startWordPosition="7912"> gesture stimuli in the presguage 121 (2012) 12–24 19ent study; all support the prediction that phonologically illegal non-signs would elicit a positive-going waveform. However, confirmation of this must await future research. ically seen in analogous speech studies. The effects seen in the item which is present yet enigmatic. While this cannot be entirely Language 121 (2012) 12–24We have already alluded to the growing number of studies which have used ERP methodology to examine the contributions of co-speech manual gestures to the interpretation of both linguistic and non-linguistic stimuli (Holle &amp; Gunter, 2007; Kelly et al., 2004; Ozyürek, Willems, Kita, &amp; Hagoort, 2007; Wu &amp; Coulson, 2005, 2007a, 2007b). Many of these studies have used iconic manual gestures that depict a salient visual–spatial property of concrete objects, such as their size and shape or an associated manner of movement (but see also Cornejo et al., 2009). Collectively these studies suggest that co-speech manual gestures influence semantic representations, and that discrepancies between gestural forms and the semantic contexts in which they occur lead to greater processing costs on the part of language perceivers. This in turn re</context>
</contexts>
<marker>Holle, Gunter, 2007</marker>
<rawString>Holle, H., &amp; Gunter, T. C. (2007). The role of iconic gestures in speech disambiguation: ERP evidence. Journal of Cognitive Neuroscience, 19, 1175–1192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B W Johnson</author>
<author>J P Hamm</author>
</authors>
<title>High-density mapping in an N400 paradigm: Evidence for bilateral temporal lobe generators.</title>
<date>2000</date>
<journal>Clinical Neurophysiology,</journal>
<volume>111</volume>
<pages>532--545</pages>
<contexts>
<context citStr="Johnson and Hamm (2000)" endWordPosition="9127" position="57837" startWordPosition="9124"> present study were for gestures in a sentence context, while in Corina et al. (2007) the sign and gesture stimuli were seen in isolation. 120 unique gesture stimuli, the actions were performed with differences in the number and configuration of hands or fingers used, the location of the body involved, and so on. Also shown in the rightmost two columns of the table are the ‘‘correct’’ and ‘‘incorrect’’ word choices for the occasional quiz items. A number sign (#) preceding an item means that item was fingerspelled. Many of these sentences were adapted from the English-language stimuli used in Johnson and Hamm (2000). Table A1 FRAME Semantically congruent Semantically incongruent Pseudo-sign Quiz items Correct Incorrect 1 BOY SLEEP IN HIS BED LEMON BARK.A’ sleep fight 2 HEAR BARK BARK LOOK RIGHT PRO DOG SECRET HOUSE.V hear touch 3 MAN PRO CARPENTER BUILD HOUSE HAIRCUT NOSE.V’’ build eat 4 DOOR PRO LOCK LOOK-FOR KEY NOSE G_2H (contact 2x) lock hat 5 WATER+CL:pond PRO CL:many-across FISH WORD GHOST.S water wine 6 MOTORCYCLE BROKE-DOWN-REPEATEDLY FINALLY BOUGHT NEW CAR GHOST WRIST.CS (open &amp; close) buy wear 7 PRO3 BECOME-ILL SICK CAN’T GO-TO WORK BOTTLE NOSE.5 (2x) sick one 8 MY HOUSE LIGHTS BLACKOUT-POW CL:</context>
</contexts>
<marker>Johnson, Hamm, 2000</marker>
<rawString>Johnson, B. W., &amp; Hamm, J. P. (2000). High-density mapping in an N400 paradigm: Evidence for bilateral temporal lobe generators. Clinical Neurophysiology, 111, 532–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Johnson</author>
<author>E Donchin</author>
</authors>
<title>P300 and stimulus categorization: Two plus one is not so different from one plus one.</title>
<date>1980</date>
<journal>Psychophysiology,</journal>
<volume>17</volume>
<pages>167--178</pages>
<contexts>
<context citStr="Johnson &amp; Donchin, 1980" endWordPosition="7520" position="47455" startWordPosition="7517">e that illegal non-words, relative to pseudo-words and real words, appear to elicit a large late positivity. This positivity has sometimes been interpreted as a P300 response (e.g. Holcomb &amp; Neville, 1990). In the present experiment, the centro-parietal distribution of the positive component elicited in the gesture condition also corresponds to the typical distribution of the P300 component. At least three interpretations of this effect may be relevant here. First, a P300 response is well-attested in studies making use of stimuli perceived by subjects to be in a low-probability category (e.g. Johnson &amp; Donchin, 1980). In our experiment, grooming gestures occurred 1/4 of the time, rendering these non-linguistic events low-probability with respect to the other three (linguistic) sentence ending conditions. Second, ERP differences between non-words and words have been attributed to the fact that these non-linguistic items have little or nothing in common with lexical entries and therefore do not generate lexical activity (cf. Rugg &amp; Nagy, 1987). Third, the ERP differences observed between pseudo-words and non-words have also been suggested to reflect a pre-lexical filtering process that quickly rejects non-l</context>
</contexts>
<marker>Johnson, Donchin, 1980</marker>
<rawString>Johnson, R., Jr, &amp; Donchin, E. (1980). P300 and stimulus categorization: Two plus one is not so different from one plus one. Psychophysiology, 17, 167–178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kegl</author>
<author>A Senghas</author>
<author>M Coppola</author>
</authors>
<title>Creation through contact: Sign language emergence and sign language change in Nicaragua. In</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<contexts>
<context citStr="Kegl, Senghas, &amp; Coppola, 1999" endWordPosition="568" position="3801" startWordPosition="564">found significant N400-like responses in the incongruent and pseudo-sign contexts, while the gestures elicited a large positivity.  2012 Elsevier Inc. All rights reserved. gned languages used in nt full-fledged instantich are expressed in the ral–oral modality—the cently, linguists have documented compelling evidence that the development of nascent sign languages derives from idiosyncratic gestural and pantomimic systems used by isolated communities, which in some casesmay be limited to individual families who have a need to communicate with a deaf child (Frishberg, 1987; GoldinMeadow, 2003; Kegl, Senghas, &amp; Coppola, 1999; Meir, Sandler, Pad-Sign language ASL high-close-probability sign (a ‘‘semantically reasonable’’ completion to the sentence; e.g. BED), a lowclose-probability sign (a real sign that is nonetheless a ‘‘semantically odd’’ completion to the sentence;Dissociating linguistic and non-linguistic Electrophysiological evidence from Amer Michael Grosvald a,⇑, Eva Gutierrez b, Sarah Hafer b, D aDepartment of Neurology, University of California at Irvine, United States bCenter for Mind and Brain, University of California at Davis, United States cDepartments of Linguistics and Psychology, University of Ca</context>
</contexts>
<marker>Kegl, Senghas, Coppola, 1999</marker>
<rawString>Kegl, J., Senghas, A., &amp; Coppola, M. (1999). Creation through contact: Sign language emergence and sign language change in Nicaragua. In M. DeGraff (Ed.), Language creation and language change: Creolization, diachrony, and development (pp. 179–237). Cambridge MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S D Kelly</author>
<author>C Kravitz</author>
<author>M Hopkins</author>
</authors>
<title>Neural correlates of bimodal speech and gesture comprehension.</title>
<date>2004</date>
<journal>Brain and Language,</journal>
<volume>89</volume>
<pages>243--260</pages>
<contexts>
<context citStr="Kelly, Kravitz, &amp; Hopkins, 2004" endWordPosition="1330" position="8776" startWordPosition="1326">usibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 This possibility is bolstered by recent work of Albert Kim and colleagues, who have found that relative to real word controls, N400 amplitude decreases and P600 amplitude increases, parametrically, as orthographic irregularity increases (Kim &amp; Pitkänen, s</context>
<context citStr="Kelly et al., 2004" endWordPosition="1662" position="11163" startWordPosition="1659">honologically legal pseudo-signs. The ERP response for the non-linguistic gesture condition is a priori more difficult to predict. Previous neuro-imaging studies of deaf signers have reported differences in patterns of activation associated with the perception of signs compared to non-linguistic gestures (Corina et al., 2007; Emmorey et al., 2010; MacSweeney et al., 2004), but the methodologies used in those studies lacked the temporal resolution to determine at what stage of processing these differences may occur. While N400-like responses have been elicited to co-speech gestural mismatches (Kelly et al., 2004; Wu &amp; Coulson, 2005), in our study, gestures occur in place of semantically appropriate sentence-ending items, rather than as a possible accompaniment. It should also be borne in mind that the relationship of signs and grooming gestures is probably not quite akin to that between standard lexical items in spoken language and the orthographically/phonotactically illegal pseudo-words used in earlier ERP studies. Unlike grooming gestures, which are part of everyday life, illegal non-words like ‘‘dkfpst’’ are probably alien to most people’s routine experience. A better spoken-language analogue of </context>
<context citStr="Kelly et al., 2004" endWordPosition="7919" position="50089" startWordPosition="7916">e presguage 121 (2012) 12–24 19ent study; all support the prediction that phonologically illegal non-signs would elicit a positive-going waveform. However, confirmation of this must await future research. ically seen in analogous speech studies. The effects seen in the item which is present yet enigmatic. While this cannot be entirely Language 121 (2012) 12–24We have already alluded to the growing number of studies which have used ERP methodology to examine the contributions of co-speech manual gestures to the interpretation of both linguistic and non-linguistic stimuli (Holle &amp; Gunter, 2007; Kelly et al., 2004; Ozyürek, Willems, Kita, &amp; Hagoort, 2007; Wu &amp; Coulson, 2005, 2007a, 2007b). Many of these studies have used iconic manual gestures that depict a salient visual–spatial property of concrete objects, such as their size and shape or an associated manner of movement (but see also Cornejo et al., 2009). Collectively these studies suggest that co-speech manual gestures influence semantic representations, and that discrepancies between gestural forms and the semantic contexts in which they occur lead to greater processing costs on the part of language perceivers. This in turn results in increased n</context>
</contexts>
<marker>Kelly, Kravitz, Hopkins, 2004</marker>
<rawString>Kelly, S. D., Kravitz, C., &amp; Hopkins, M. (2004). Neural correlates of bimodal speech and gesture comprehension. Brain and Language, 89, 243–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kim</author>
<author>L Osterhout</author>
</authors>
<title>The independence of combinatory semantic processing: Evidence from event-related potentials.</title>
<date>2005</date>
<journal>Journal of Memory and Language,</journal>
<volume>52</volume>
<pages>205--225</pages>
<contexts>
<context citStr="Kim &amp; Osterhout, 2005" endWordPosition="4384" position="27836" startWordPosition="4381">lorme &amp; Makeig, 2004). Epochs began 200 ms before stimulus onset and ended 1000 ms after. Inspection of subjects’ EEG data was performed by eye to check rejections suggested by a script run in ERPLAB whose artifact rejection thresholds were set at ±120 lV. For all 16 subjects, in each of the four sentence ending conditions at least 20 of the original 30 trials remained after the rejection procedure just described. The statistical analyses reported below were carried out using the SPSS statistical package. To assess the significance of the observed effects, a column analysis was conducted (cf. Kim &amp; Osterhout, 2005) for which a separate ANOVA was run on each of four subsets of the scalp sites, as illustrated in Fig. 2. For the midline scalp sites, colored green in the figure, the two factors in the ANOVA were Electrode (one level for each of the four electrodes) and sentence Ending (semantically guage 121 (2012) 12–24 15serve a large positive-going wave relative to the baseline for the grooming gesture condition. These effects appear to be long lasting, extending beyond the end of the 1000 ms time window. Lan16 M. Grosvald et al. / Brain &amp;Fig. 5 presents topographic maps of key contrasts, and reinforces </context>
</contexts>
<marker>Kim, Osterhout, 2005</marker>
<rawString>Kim, A., &amp; Osterhout, L. (2005). The independence of combinatory semantic processing: Evidence from event-related potentials. Journal of Memory and Language, 52, 205–225. Kim, A., &amp; Pitkänen, I. (submitted for publication). Dissociation of ERPs to structural and semantic processing difficulty during sentence-embedded pseudoword processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kutas</author>
<author>S A Hillyard</author>
</authors>
<title>Reading senseless sentences: Brain potentials reflect semantic incongruity.</title>
<date>1980</date>
<journal>Science,</journal>
<volume>207</volume>
<pages>203--208</pages>
<contexts>
<context citStr="Kutas &amp; Hillyard, 1980" endWordPosition="954" position="6319" startWordPosition="950">al-time electrophysiological measures to assess empirically the time course of sentence processing in cases where subjects encountered non-linguistic manual forms (here ‘‘self-grooming’’ behaviors, e.g. scratching the face, rubbing one’s eye, adjusting the sleeves of a shirt, etc.). We sought to compare the processing of these non-linguistic gestural forms within a sentential context to cases in which deaf signers encountered violations of semantic expectancy that have been observed to elicit a well-defined electrophysiological component, the N400. The N400 component (Holcomb &amp; Neville, 1991; Kutas &amp; Hillyard, 1980) has been frequently investigated in previous ERP research on written, spoken and signed language (e.g. Capek et al., 2009; Kutas, Neville, &amp; Holcomb, 1987). The N400 is a broad negative deflection generally seen at central and parietal scalp sites that peaks about 400 ms after the visual or auditory presentation of a word. Although all content words elicit an N400 component, the ERP response is larger for words that are semantically anomalous or less expected (Hagoort &amp; Brown, 1994; Kutas &amp; Hillyard, 1984); thus the N400 is often interpreted as an index of ease or difficulty in semantic conce</context>
<context citStr="Kutas &amp; Hillyard, 1980" endWordPosition="8042" position="50869" startWordPosition="8039">sual–spatial property of concrete objects, such as their size and shape or an associated manner of movement (but see also Cornejo et al., 2009). Collectively these studies suggest that co-speech manual gestures influence semantic representations, and that discrepancies between gestural forms and the semantic contexts in which they occur lead to greater processing costs on the part of language perceivers. This in turn results in increased negativities in the time window often associated with the classic N400 effect, observed in response to word meanings that violate the wider semantic context (Kutas &amp; Hillyard, 1980). For example, Kelly et al. (2004) observed modulation of ERP responses for speech tokens that were either accompanied by matching, complementary or mismatched hand gestures. An N400-like component was observed for mismatched gesture-speech tokens relative to the other conditions. Wu and Coulson (2005) examined ERPs for subjects who watched cartoons followed by a gestural depiction that either matched or mismatched the events shown in the cartoons. Gestures elicited an N400-like component (a socalled ‘‘gesture N450’’) that was larger for incongruent than congruent items. Ozyürek et al. (2007) </context>
</contexts>
<marker>Kutas, Hillyard, 1980</marker>
<rawString>Kutas, M., &amp; Hillyard, S. A. (1980). Reading senseless sentences: Brain potentials reflect semantic incongruity. Science, 207, 203–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kutas</author>
<author>S A Hillyard</author>
</authors>
<title>Brain potentials during reading reflect word expectancy and semantic association.</title>
<date>1984</date>
<journal>Nature,</journal>
<volume>307</volume>
<pages>161--163</pages>
<contexts>
<context citStr="Kutas &amp; Hillyard, 1984" endWordPosition="1040" position="6831" startWordPosition="1037"> electrophysiological component, the N400. The N400 component (Holcomb &amp; Neville, 1991; Kutas &amp; Hillyard, 1980) has been frequently investigated in previous ERP research on written, spoken and signed language (e.g. Capek et al., 2009; Kutas, Neville, &amp; Holcomb, 1987). The N400 is a broad negative deflection generally seen at central and parietal scalp sites that peaks about 400 ms after the visual or auditory presentation of a word. Although all content words elicit an N400 component, the ERP response is larger for words that are semantically anomalous or less expected (Hagoort &amp; Brown, 1994; Kutas &amp; Hillyard, 1984); thus the N400 is often interpreted as an index of ease or difficulty in semantic conceptual integration (Brown &amp; Hagoort, 1993; Hagoort &amp; Van Berkum, 2007). For example, for listeners encountering the two sentences ‘‘I like my coffee with milk and sugar’’ and ‘‘I like my coffee with milk and mud,’’ the N400 response to the last word in the second item is expected to be larger. An N400 or N400-like component can also be found in response to orthographically/phonologically legal but non-occurring ‘‘pseudo-words’’ (e.g. ‘‘blork’’), and it has sometimes been reported that pseudo-words elicit a s</context>
</contexts>
<marker>Kutas, Hillyard, 1984</marker>
<rawString>Kutas, M., &amp; Hillyard, S. A. (1984). Brain potentials during reading reflect word expectancy and semantic association. Nature, 307, 161–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kutas</author>
<author>H J Neville</author>
<author>P J Holcomb</author>
</authors>
<title>A preliminary comparison of the N400 response to semantic anomalies during reading, listening, and signing.</title>
<date>1987</date>
<journal>Electroencephalography and Clinical Neurophysiology, Supplement,</journal>
<volume>39</volume>
<pages>325--330</pages>
<contexts>
<context citStr="Kutas, Neville, &amp; Holcomb, 1987" endWordPosition="979" position="6474" startWordPosition="975">ic manual forms (here ‘‘self-grooming’’ behaviors, e.g. scratching the face, rubbing one’s eye, adjusting the sleeves of a shirt, etc.). We sought to compare the processing of these non-linguistic gestural forms within a sentential context to cases in which deaf signers encountered violations of semantic expectancy that have been observed to elicit a well-defined electrophysiological component, the N400. The N400 component (Holcomb &amp; Neville, 1991; Kutas &amp; Hillyard, 1980) has been frequently investigated in previous ERP research on written, spoken and signed language (e.g. Capek et al., 2009; Kutas, Neville, &amp; Holcomb, 1987). The N400 is a broad negative deflection generally seen at central and parietal scalp sites that peaks about 400 ms after the visual or auditory presentation of a word. Although all content words elicit an N400 component, the ERP response is larger for words that are semantically anomalous or less expected (Hagoort &amp; Brown, 1994; Kutas &amp; Hillyard, 1984); thus the N400 is often interpreted as an index of ease or difficulty in semantic conceptual integration (Brown &amp; Hagoort, 1993; Hagoort &amp; Van Berkum, 2007). For example, for listeners encountering the two sentences ‘‘I like my coffee with mi</context>
<context citStr="Kutas et al., 1987" endWordPosition="1927" position="12853" startWordPosition="1924">s will not elicit an N400 but rather a positive-going component (cf. Hagoort &amp; Kutas, 1995). In summary, to the extent that semantic processing at the sentence level is similar for signed and spoken language, despite the obvious difference in modality, the ERP responses associated with our four sentence ending condition should be predictable. First, the incongruent signs should elicit a negative-going component relative to the baseline (congruent sign) condition, consistent with the classic N400 response seen for English and other spoken languages, as well as some previous ERP studies of ASL (Kutas et al., 1987; Neville et al., 1997). Second, the pseudo-signs should also elicit a negative-going wave, and this response can be expected to be of larger magnitude (i.e. be more negative) than that seen for the incongruent signs. Third, while the likely response to the grooming gesture condition is more difficult to predict, we may expect to see a positive-going component relative to the baseline. 2. Methodology 2.1. Participants guage 121 (2012) 12–24 13The 16 participants (12 female and 4 male; age range = [19, 45], mean = 25.4 and SD = 8.3) were deaf users of ASL; all were students or staff at Gallaude</context>
<context citStr="Kutas et al., 1987" endWordPosition="6416" position="40328" startWordPosition="6413">ngs. In addition, we suggested that the non-linguistic gestures might elicit a positive-going wave, relative to baseline. While this last prediction was more speculative than the others, the expected pattern was in fact observed very consistently in our analysis of the data. Together, these findings lead to a number of important observations. First, the outcome of our incongruent sign vs. congruent sign comparison replicates earlier findings which have also indicated that the N400 generalizes across modalities, including the visual– manual modality of signed language (e.g. Capek et al., 2009; Kutas et al., 1987). These findings are broadly consistent with other studies using a variety of methodologies including positron emission tomography (PET; Corina, San Jose-Robertson, Guillemin, High, &amp; Braun, 2003), functional magnetic resonance imaging (fMRI; Neville et al., 1998), and cortical stimulation mapping (Corina et al., 1999), highlighting key neural processing similarities between signed and spoken language, in spite of the obvious physical differences in the linguistic signal. For instance, Neville et al. (1997) also found that deaf signers exhibited an N400 response to semantically incongruent ASL</context>
</contexts>
<marker>Kutas, Neville, Holcomb, 1987</marker>
<rawString>Kutas, M., Neville, H. J., &amp; Holcomb, P. J. (1987). A preliminary comparison of the N400 response to semantic anomalies during reading, listening, and signing. Electroencephalography and Clinical Neurophysiology, Supplement, 39, 325–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S K Liddell</author>
</authors>
<title>Grammar, gesture, and meaning in American Sign Language.</title>
<date>2003</date>
<booktitle>In development at the</booktitle>
<publisher>Cambridge University</publisher>
<institution>Center for Mind and Brain, University of California at Davis.</institution>
<location>Cambridge, UK:</location>
<contexts>
<context citStr="Liddell, 2003" endWordPosition="379" position="2467" startWordPosition="378">inguistic actions such a reaching and grasping, waving, and scratching oneself, as well gesticulations that accompany speech (i.e. co-speech gestures) or serve non-sign language deictic functions, such as pointing. The formal relationship between signed languages and human den, &amp; Aronoff, 2010; Morford &amp; Kegl, 2000; Senghas, 2005). Even within mature sign languages of Deaf communities, linguistic accounts of sign language structure have also argued that lexical and discourse components of American Sign Language (ASL) and other signed languages may be best understood as being gesturally based (Liddell, 2003). Thus diachronic and synchronic evidence from language research support the contention that signed languages might make use of perceptual systems similar to those through which humans understand or parse human actions and gestures more generally (Corballis, 2009). In contrast, given its linguistic status, sign language perceptionmay require the attunement of specialized sys-N400 Deaf Pseudo-word Grooming gesture 1. Introduction While it is now widely accepted deaf communities around the world r ations of human languages—languag visual–manual modality rather than0093-934X/$ - see front matter </context>
</contexts>
<marker>Liddell, 2003</marker>
<rawString>Liddell, S. K. (2003). Grammar, gesture, and meaning in American Sign Language. Cambridge, UK: Cambridge University Press. Lopez-Calderon, J., &amp; Luck, S. (in press). ERPLAB. Plug-in for EEGLAB. In development at the Center for Mind and Brain, University of California at Davis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M MacSweeney</author>
<author>R Campbell</author>
<author>B Woll</author>
<author>V Giampietro</author>
<author>A S David</author>
<author>P K McGuire</author>
</authors>
<title>Dissociating linguistic and nonlinguistic gestural communication in the brain.</title>
<date>2004</date>
<journal>NeuroImage,</journal>
<volume>22</volume>
<pages>1605--1618</pages>
<contexts>
<context citStr="MacSweeney et al., 2004" endWordPosition="155" position="1015" startWordPosition="152">ges (Arbib, 2005, 2008; Gentilucci &amp; Corballis, 2006; Rizzolatti &amp; Arbib, 1998; Tomasello, 2005;Wilcox, 2004). Retems for recognizing sign forms. A comprehensive theory of sign language recognition will be enhanced by providing an account of when and how the processing of sign forms diverges from the processing of human actions in general. Recent behavioral and neuro-imaging studies have reported differences in deaf subjects’ responses to single signs compared to non-linguistic gestures (Corina, Grosvald, &amp; Lachaud, 2011; Corina et al., 2007; Emmorey, Xu, Gannon, Goldin-Meadow, &amp; Braun, 2010; MacSweeney et al., 2004), but no studies to our knowledge have examined the recognition of signs and gestures ⇑ Corresponding author. Address: Department of Neurology, University of California at Irvine, 101 The City Drive South, Bldg. 53, Room 204, Orange, CA 92868- 4280, United States. Fax: +1 714 456 1697. Brain &amp; Language 121 (2012) 12–24 Contents lists available at Brain &amp; La .eE-mail address: m.grosvald@uci.edu (M. Grosvald).question of how a sign is recognized and integrated into a sentential context in real time has received far less attention (see Corina &amp; Knapp, 2006; Emmorey, 2002; for some discussions). S</context>
<context citStr="MacSweeney et al., 2004" endWordPosition="1626" position="10919" startWordPosition="1623">n-linguistic grooming gestures. Based upon previous studies, we expected a gradation of N400-like responses across conditions, with N400 effects of smaller magnitude for semantically incongruent endingsandof largermagnitude (i.e. more negative) for phonologically legal pseudo-signs. The ERP response for the non-linguistic gesture condition is a priori more difficult to predict. Previous neuro-imaging studies of deaf signers have reported differences in patterns of activation associated with the perception of signs compared to non-linguistic gestures (Corina et al., 2007; Emmorey et al., 2010; MacSweeney et al., 2004), but the methodologies used in those studies lacked the temporal resolution to determine at what stage of processing these differences may occur. While N400-like responses have been elicited to co-speech gestural mismatches (Kelly et al., 2004; Wu &amp; Coulson, 2005), in our study, gestures occur in place of semantically appropriate sentence-ending items, rather than as a possible accompaniment. It should also be borne in mind that the relationship of signs and grooming gestures is probably not quite akin to that between standard lexical items in spoken language and the orthographically/phonotac</context>
</contexts>
<marker>MacSweeney, Campbell, Woll, Giampietro, David, McGuire, 2004</marker>
<rawString>MacSweeney, M., Campbell, R., Woll, B., Giampietro, V., David, A. S., McGuire, P. K., et al. (2004). Dissociating linguistic and nonlinguistic gestural communication in the brain. NeuroImage, 22, 1605–1618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W B McPherson</author>
<author>P J Holcomb</author>
</authors>
<title>An electrophysiological investigation of semantic priming with pictures of real objects.</title>
<date>1999</date>
<journal>Psychophysiology,</journal>
<volume>36</volume>
<pages>53--65</pages>
<contexts>
<context citStr="McPherson &amp; Holcomb, 1999" endWordPosition="6777" position="42653" startWordPosition="6773">ulson’s (2005) study of contextually incongruent gestures, a component described by the researchers as a ‘‘gesture N450’’ was observed. Wu and Coulson noted the similarity of this effect to the N450 reported by Barrett and Rugg (1990) for second items in unrelated picture pairs relative to related picture pairs (e.g. wrench/fork vs. knife/fork), stating (p. 659) that consistent with their own findings, ‘‘most such ‘picture’ ERP studies report a broadly distributed negativity largest at frontal electrode sites and not evident at occipital sites (Barrett &amp; Rugg, 1990; Holcomb &amp; McPherson, 1994; McPherson &amp; Holcomb, 1999; Sitnikova et al., 2003; West &amp; Holcomb, 2002).’’ In contrast, the negativity reported in the present study was quite evident at occipital sites, as can be seen clearly in Figs. 3 and 4. A second notable finding in our study concerns deaf subjects’ ERP response in the phonologically legal pseudo-sign condition, which was also consistent with an N400 response but was generally larger (more negative) than the negativity seen for semantically incongruent but fully lexical signs. This provides further evidence for broad processing similarities for different linguistic modalities, in the light of </context>
</contexts>
<marker>McPherson, Holcomb, 1999</marker>
<rawString>McPherson, W. B., &amp; Holcomb, P. J. (1999). An electrophysiological investigation of semantic priming with pictures of real objects. Psychophysiology, 36, 53–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Meir</author>
<author>W Sandler</author>
<author>C Padden</author>
<author>M Aronoff</author>
</authors>
<title>Emerging sign languages. In</title>
<date>2010</date>
<volume>2</volume>
<publisher>University Press.</publisher>
<location>New York: Oxford</location>
<marker>Meir, Sandler, Padden, Aronoff, 2010</marker>
<rawString>Meir, I., Sandler, W., Padden, C., &amp; Aronoff, M. (2010). Emerging sign languages. In M. Marschark &amp; P. Spencer (Eds.). Oxford handbook of deaf studies, language, and education (Vol. 2). New York: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Morford</author>
<author>J A Kegl</author>
</authors>
<title>Gestural precursors to linguistic constructs: How input shapes the form of language. In</title>
<date>2000</date>
<booktitle>Language and gesture</booktitle>
<pages>358--387</pages>
<editor>D. McNeill (Ed.),</editor>
<publisher>Cambridge University Press.</publisher>
<location>Cambridge, UK:</location>
<contexts>
<context citStr="Morford &amp; Kegl, 2000" endWordPosition="335" position="2169" startWordPosition="332">(see Corina &amp; Knapp, 2006; Emmorey, 2002; for some discussions). Sign language recognition may be more complicated than spoken language recognition by virtue of the fact that the primary articulators, the hands and arms, are also used in a wide range of other common everyday behaviors that include non-linguistic actions such a reaching and grasping, waving, and scratching oneself, as well gesticulations that accompany speech (i.e. co-speech gestures) or serve non-sign language deictic functions, such as pointing. The formal relationship between signed languages and human den, &amp; Aronoff, 2010; Morford &amp; Kegl, 2000; Senghas, 2005). Even within mature sign languages of Deaf communities, linguistic accounts of sign language structure have also argued that lexical and discourse components of American Sign Language (ASL) and other signed languages may be best understood as being gesturally based (Liddell, 2003). Thus diachronic and synchronic evidence from language research support the contention that signed languages might make use of perceptual systems similar to those through which humans understand or parse human actions and gestures more generally (Corballis, 2009). In contrast, given its linguistic st</context>
</contexts>
<marker>Morford, Kegl, 2000</marker>
<rawString>Morford, J. P., &amp; Kegl, J. A. (2000). Gestural precursors to linguistic constructs: How input shapes the form of language. In D. McNeill (Ed.), Language and gesture (pp. 358–387). Cambridge, UK: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H J Neville</author>
<author>D Bavelier</author>
<author>D Corina</author>
<author>J Rauschecker</author>
<author>A Karni</author>
<author>A Lalwani</author>
</authors>
<title>Cerebral organization for language in deaf and hearing subjects: Biological constraints and effects of experience.</title>
<date>1998</date>
<booktitle>Proceedings of the National Academy of Sciences of the United States of America,</booktitle>
<volume>95</volume>
<pages>922--929</pages>
<contexts>
<context citStr="Neville et al., 1998" endWordPosition="6453" position="40592" startWordPosition="6449"> of the data. Together, these findings lead to a number of important observations. First, the outcome of our incongruent sign vs. congruent sign comparison replicates earlier findings which have also indicated that the N400 generalizes across modalities, including the visual– manual modality of signed language (e.g. Capek et al., 2009; Kutas et al., 1987). These findings are broadly consistent with other studies using a variety of methodologies including positron emission tomography (PET; Corina, San Jose-Robertson, Guillemin, High, &amp; Braun, 2003), functional magnetic resonance imaging (fMRI; Neville et al., 1998), and cortical stimulation mapping (Corina et al., 1999), highlighting key neural processing similarities between signed and spoken language, in spite of the obvious physical differences in the linguistic signal. For instance, Neville et al. (1997) also found that deaf signers exhibited an N400 response to semantically incongruent ASL sentences, relative to congruent sentences. Like the effects in the present study, this response was broadly distributed and had an onset and peak that the researchers noted was somewhat later Lanthan would be expected for written language, but consistent with ea</context>
</contexts>
<marker>Neville, Bavelier, Corina, Rauschecker, Karni, Lalwani, 1998</marker>
<rawString>Neville, H. J., Bavelier, D., Corina, D., Rauschecker, J., Karni, A., Lalwani, A., et al. (1998). Cerebral organization for language in deaf and hearing subjects: Biological constraints and effects of experience. Proceedings of the National Academy of Sciences of the United States of America, 95, 922–929.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H J Neville</author>
<author>S A Coffey</author>
<author>D S Lawson</author>
<author>A Fischer</author>
<author>K Emmorey</author>
<author>U Bellugi</author>
</authors>
<title>Neural systems mediating American Sign Language: Effects of sensory experience and age of acquisition.</title>
<date>1997</date>
<journal>Brain and Language,</journal>
<pages>285--308</pages>
<contexts>
<context citStr="Neville et al., 1997" endWordPosition="1931" position="12876" startWordPosition="1928"> N400 but rather a positive-going component (cf. Hagoort &amp; Kutas, 1995). In summary, to the extent that semantic processing at the sentence level is similar for signed and spoken language, despite the obvious difference in modality, the ERP responses associated with our four sentence ending condition should be predictable. First, the incongruent signs should elicit a negative-going component relative to the baseline (congruent sign) condition, consistent with the classic N400 response seen for English and other spoken languages, as well as some previous ERP studies of ASL (Kutas et al., 1987; Neville et al., 1997). Second, the pseudo-signs should also elicit a negative-going wave, and this response can be expected to be of larger magnitude (i.e. be more negative) than that seen for the incongruent signs. Third, while the likely response to the grooming gesture condition is more difficult to predict, we may expect to see a positive-going component relative to the baseline. 2. Methodology 2.1. Participants guage 121 (2012) 12–24 13The 16 participants (12 female and 4 male; age range = [19, 45], mean = 25.4 and SD = 8.3) were deaf users of ASL; all were students or staff at Gallaudet University in Washing</context>
<context citStr="Neville et al. (1997)" endWordPosition="6489" position="40840" startWordPosition="6486">ities, including the visual– manual modality of signed language (e.g. Capek et al., 2009; Kutas et al., 1987). These findings are broadly consistent with other studies using a variety of methodologies including positron emission tomography (PET; Corina, San Jose-Robertson, Guillemin, High, &amp; Braun, 2003), functional magnetic resonance imaging (fMRI; Neville et al., 1998), and cortical stimulation mapping (Corina et al., 1999), highlighting key neural processing similarities between signed and spoken language, in spite of the obvious physical differences in the linguistic signal. For instance, Neville et al. (1997) also found that deaf signers exhibited an N400 response to semantically incongruent ASL sentences, relative to congruent sentences. Like the effects in the present study, this response was broadly distributed and had an onset and peak that the researchers noted was somewhat later Lanthan would be expected for written language, but consistent with earlier studies on auditory language (Holcomb &amp; Neville, 1990, 1991). Neville et al. suggested that this delay might be due to the fact that the recognition point of different signs will tend to vary more than for printed language, in which all infor</context>
</contexts>
<marker>Neville, Coffey, Lawson, Fischer, Emmorey, Bellugi, 1997</marker>
<rawString>Neville, H. J., Coffey, S. A., Lawson, D. S., Fischer, A., Emmorey, K., &amp; Bellugi, U. (1997). Neural systems mediating American Sign Language: Effects of sensory experience and age of acquisition. Brain and Language, 285–308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H J Neville</author>
<author>J L Nicol</author>
<author>A Barss</author>
<author>K I Forster</author>
<author>M F Garrett</author>
</authors>
<title>Syntactically based sentence processing classes: Evidence from event-related brain potentials.</title>
<date>1991</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>3</volume>
<pages>151--165</pages>
<contexts>
<context citStr="Neville, Nicol, Barss, Forster, &amp; Garrett, 1991" endWordPosition="1361" position="8994" startWordPosition="1355">ictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 This possibility is bolstered by recent work of Albert Kim and colleagues, who have found that relative to real word controls, N400 amplitude decreases and P600 amplitude increases, parametrically, as orthographic irregularity increases (Kim &amp; Pitkänen, submitted for publication).spoken and written language, and more recent work has shown that these components can be elicited in the visual–manual modality as well. For example, in a recent study Capek et al. (2009) comp</context>
</contexts>
<marker>Neville, Nicol, Barss, Forster, Garrett, 1991</marker>
<rawString>Neville, H. J., Nicol, J. L., Barss, A., Forster, K. I., &amp; Garrett, M. F. (1991). Syntactically based sentence processing classes: Evidence from event-related brain potentials. Journal of Cognitive Neuroscience, 3, 151–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nigam</author>
<author>J E Hoffman</author>
<author>R F Simons</author>
</authors>
<title>N400 and semantic anomaly with pictures and words.</title>
<date>1992</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>4</volume>
<pages>15--22</pages>
<contexts>
<context citStr="Nigam, Hoffman, &amp; Simons, 1992" endWordPosition="1284" position="8437" startWordPosition="1280">400, and a positive component is sometimes seen instead (Hagoort &amp; Kutas, 1995; Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are </context>
</contexts>
<marker>Nigam, Hoffman, Simons, 1992</marker>
<rawString>Nigam, A., Hoffman, J. E., &amp; Simons, R. F. (1992). N400 and semantic anomaly with pictures and words. Journal of Cognitive Neuroscience, 4, 15–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Osterhout</author>
<author>P Holcomb</author>
</authors>
<title>Event-related brain potentials elicited by syntactic anomaly.</title>
<date>1992</date>
<journal>Journal of Memory and Language,</journal>
<volume>31</volume>
<pages>785--806</pages>
<contexts>
<context citStr="Osterhout &amp; Holcomb, 1992" endWordPosition="1367" position="9032" startWordPosition="1364"> Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 This possibility is bolstered by recent work of Albert Kim and colleagues, who have found that relative to real word controls, N400 amplitude decreases and P600 amplitude increases, parametrically, as orthographic irregularity increases (Kim &amp; Pitkänen, submitted for publication).spoken and written language, and more recent work has shown that these components can be elicited in the visual–manual modality as well. For example, in a recent study Capek et al. (2009) compared ERP responses to semantically and</context>
</contexts>
<marker>Osterhout, Holcomb, 1992</marker>
<rawString>Osterhout, L., &amp; Holcomb, P. (1992). Event-related brain potentials elicited by syntactic anomaly. Journal of Memory and Language, 31, 785–806.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ozyürek</author>
<author>R M Willems</author>
<author>S Kita</author>
<author>P Hagoort</author>
</authors>
<title>On-line integration of semantic information from speech and gesture: Insights from event-related brain potentials.</title>
<date>2007</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>19</volume>
<pages>605--616</pages>
<contexts>
<context citStr="Ozyürek, Willems, Kita, &amp; Hagoort, 2007" endWordPosition="7925" position="50130" startWordPosition="7920">2) 12–24 19ent study; all support the prediction that phonologically illegal non-signs would elicit a positive-going waveform. However, confirmation of this must await future research. ically seen in analogous speech studies. The effects seen in the item which is present yet enigmatic. While this cannot be entirely Language 121 (2012) 12–24We have already alluded to the growing number of studies which have used ERP methodology to examine the contributions of co-speech manual gestures to the interpretation of both linguistic and non-linguistic stimuli (Holle &amp; Gunter, 2007; Kelly et al., 2004; Ozyürek, Willems, Kita, &amp; Hagoort, 2007; Wu &amp; Coulson, 2005, 2007a, 2007b). Many of these studies have used iconic manual gestures that depict a salient visual–spatial property of concrete objects, such as their size and shape or an associated manner of movement (but see also Cornejo et al., 2009). Collectively these studies suggest that co-speech manual gestures influence semantic representations, and that discrepancies between gestural forms and the semantic contexts in which they occur lead to greater processing costs on the part of language perceivers. This in turn results in increased negativities in the time window often asso</context>
<context citStr="Ozyürek et al. (2007)" endWordPosition="8133" position="51468" startWordPosition="8130">utas &amp; Hillyard, 1980). For example, Kelly et al. (2004) observed modulation of ERP responses for speech tokens that were either accompanied by matching, complementary or mismatched hand gestures. An N400-like component was observed for mismatched gesture-speech tokens relative to the other conditions. Wu and Coulson (2005) examined ERPs for subjects who watched cartoons followed by a gestural depiction that either matched or mismatched the events shown in the cartoons. Gestures elicited an N400-like component (a socalled ‘‘gesture N450’’) that was larger for incongruent than congruent items. Ozyürek et al. (2007) recorded EEG while subjects listened to sentences with a critical verb (e.g. ‘‘knock’’) accompanied by a related co-speech gesture (e.g. KNOCK). Verbal/gestural semantic content either matched or mismatched the earlier part of the sentence. The researchers noted that following the N1–P2 complex, the ERP response to mismatch conditions started to deviate from the response to the correct condition in the latency window of the P2 component, around 225–275 ms post stimulus onset, while at around 350 ms, the mismatch conditions deviated from the congruent condition. This was followed by a similar </context>
</contexts>
<marker>Ozyürek, Willems, Kita, Hagoort, 2007</marker>
<rawString>Ozyürek, A., Willems, R. M., Kita, S., &amp; Hagoort, P. (2007). On-line integration of semantic information from speech and gesture: Insights from event-related brain potentials. Journal of Cognitive Neuroscience, 19, 605–616.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Pratarelli</author>
</authors>
<title>Semantic processing of pictures and spoken words: Evidence from event-related brain potentials.</title>
<date>1994</date>
<journal>Brain and Cognition,</journal>
<volume>24</volume>
<pages>137--157</pages>
<contexts>
<context citStr="Pratarelli, 1994" endWordPosition="1286" position="8456" startWordPosition="1285"> sometimes seen instead (Hagoort &amp; Kutas, 1995; Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP comp</context>
</contexts>
<marker>Pratarelli, 1994</marker>
<rawString>Pratarelli, M. E. (1994). Semantic processing of pictures and spoken words: Evidence from event-related brain potentials. Brain and Cognition, 24, 137–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Rizzolatti</author>
<author>M A Arbib</author>
</authors>
<title>Language within our grasp.</title>
<date>1998</date>
<journal>Trends in Neurosciences,</journal>
<volume>21</volume>
<pages>188--194</pages>
<marker>Rizzolatti, Arbib, 1998</marker>
<rawString>Rizzolatti, G., &amp; Arbib, M. A. (1998). Language within our grasp. Trends in Neurosciences, 21, 188–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M D Rugg</author>
<author>M E Nagy</author>
</authors>
<title>Lexical contribution to non-word-repetition effects: Evidence from event-related potentials.</title>
<date>1987</date>
<journal>Memory and Cognition,</journal>
<volume>15</volume>
<pages>473--481</pages>
<contexts>
<context citStr="Rugg &amp; Nagy, 1987" endWordPosition="7585" position="47888" startWordPosition="7582">t may be relevant here. First, a P300 response is well-attested in studies making use of stimuli perceived by subjects to be in a low-probability category (e.g. Johnson &amp; Donchin, 1980). In our experiment, grooming gestures occurred 1/4 of the time, rendering these non-linguistic events low-probability with respect to the other three (linguistic) sentence ending conditions. Second, ERP differences between non-words and words have been attributed to the fact that these non-linguistic items have little or nothing in common with lexical entries and therefore do not generate lexical activity (cf. Rugg &amp; Nagy, 1987). Third, the ERP differences observed between pseudo-words and non-words have also been suggested to reflect a pre-lexical filtering process that quickly rejects non-linguistic items based upon aberrant physical characteristics (Holcomb &amp; Neville, 1990). For example, Ziegler et al. (1997) suggest such a categorization may be based on a spelling check in the case of non-word consonant-string stimuli. This last interpretation accords well with a possibility we noted in the Introduction, that such an ERP response may be due to the operation of a filtering/rejection mechanism, allowing language us</context>
</contexts>
<marker>Rugg, Nagy, 1987</marker>
<rawString>Rugg, M. D., &amp; Nagy, M. E. (1987). Lexical contribution to non-word-repetition effects: Evidence from event-related potentials. Memory and Cognition, 15, 473–481.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Senghas</author>
</authors>
<title>Language emergence. Clues from a new Bedouin sign language.</title>
<date>2005</date>
<journal>Current Biology,</journal>
<volume>15</volume>
<pages>463--465</pages>
<contexts>
<context citStr="Senghas, 2005" endWordPosition="337" position="2185" startWordPosition="336">006; Emmorey, 2002; for some discussions). Sign language recognition may be more complicated than spoken language recognition by virtue of the fact that the primary articulators, the hands and arms, are also used in a wide range of other common everyday behaviors that include non-linguistic actions such a reaching and grasping, waving, and scratching oneself, as well gesticulations that accompany speech (i.e. co-speech gestures) or serve non-sign language deictic functions, such as pointing. The formal relationship between signed languages and human den, &amp; Aronoff, 2010; Morford &amp; Kegl, 2000; Senghas, 2005). Even within mature sign languages of Deaf communities, linguistic accounts of sign language structure have also argued that lexical and discourse components of American Sign Language (ASL) and other signed languages may be best understood as being gesturally based (Liddell, 2003). Thus diachronic and synchronic evidence from language research support the contention that signed languages might make use of perceptual systems similar to those through which humans understand or parse human actions and gestures more generally (Corballis, 2009). In contrast, given its linguistic status, sign langu</context>
</contexts>
<marker>Senghas, 2005</marker>
<rawString>Senghas, A. (2005). Language emergence. Clues from a new Bedouin sign language. Current Biology, 15, 463–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sitnikova</author>
<author>P J Holcomb</author>
<author>K A Kiyonaga</author>
<author>G R Kuperberg</author>
</authors>
<title>Two neurocognitive mechanisms of semantic integration during the comprehension of real-world events.</title>
<date>2008</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>20</volume>
<pages>2037--2057</pages>
<contexts>
<context citStr="Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008" endWordPosition="1316" position="8680" startWordPosition="1311">h which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 This possibility is bolstered by recent work of Albert Kim and colleagues, who have found that relative to real word controls, N400 amplitude decreases and P60</context>
</contexts>
<marker>Sitnikova, Holcomb, Kiyonaga, Kuperberg, 2008</marker>
<rawString>Sitnikova, T., Holcomb, P. J., Kiyonaga, K. A., &amp; Kuperberg, G. R. (2008). Two neurocognitive mechanisms of semantic integration during the comprehension of real-world events. Journal of Cognitive Neuroscience, 20, 2037–2057.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sitnikova</author>
<author>G Kuperberg</author>
<author>P J Holcomb</author>
</authors>
<title>Semantic integration in videos of real-world events: An electrophysiological investigation.</title>
<date>2003</date>
<journal>Psychophysiology,</journal>
<volume>40</volume>
<pages>160--164</pages>
<contexts>
<context citStr="Sitnikova, Kuperberg, &amp; Holcomb, 2003" endWordPosition="1321" position="8719" startWordPosition="1317"> forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 This possibility is bolstered by recent work of Albert Kim and colleagues, who have found that relative to real word controls, N400 amplitude decreases and P600 amplitude increases, parametrically, </context>
<context citStr="Sitnikova et al., 2003" endWordPosition="6781" position="42677" startWordPosition="6778">textually incongruent gestures, a component described by the researchers as a ‘‘gesture N450’’ was observed. Wu and Coulson noted the similarity of this effect to the N450 reported by Barrett and Rugg (1990) for second items in unrelated picture pairs relative to related picture pairs (e.g. wrench/fork vs. knife/fork), stating (p. 659) that consistent with their own findings, ‘‘most such ‘picture’ ERP studies report a broadly distributed negativity largest at frontal electrode sites and not evident at occipital sites (Barrett &amp; Rugg, 1990; Holcomb &amp; McPherson, 1994; McPherson &amp; Holcomb, 1999; Sitnikova et al., 2003; West &amp; Holcomb, 2002).’’ In contrast, the negativity reported in the present study was quite evident at occipital sites, as can be seen clearly in Figs. 3 and 4. A second notable finding in our study concerns deaf subjects’ ERP response in the phonologically legal pseudo-sign condition, which was also consistent with an N400 response but was generally larger (more negative) than the negativity seen for semantically incongruent but fully lexical signs. This provides further evidence for broad processing similarities for different linguistic modalities, in the light of similar findings for pse</context>
</contexts>
<marker>Sitnikova, Kuperberg, Holcomb, 2003</marker>
<rawString>Sitnikova, T., Kuperberg, G., &amp; Holcomb, P. J. (2003). Semantic integration in videos of real-world events: An electrophysiological investigation. Psychophysiology, 40, 160–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomasello</author>
</authors>
<title>Constructing a language: A usage-based theory of language acquisition.</title>
<date>2005</date>
<publisher>Harvard University Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Tomasello, 2005</marker>
<rawString>Tomasello, M. (2005). Constructing a language: A usage-based theory of language acquisition. Cambridge, MA: Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Van Petten</author>
<author>H Rheinfelder</author>
</authors>
<title>Conceptual relationships between spoken words and environmental sounds: Event-related brain potential measures.</title>
<date>1995</date>
<marker>Van Petten, Rheinfelder, 1995</marker>
<rawString>Van Petten, C., &amp; Rheinfelder, H. (1995). Conceptual relationships between spoken words and environmental sounds: Event-related brain potential measures.</rawString>
</citation>
<citation valid="false">
<volume>121</volume>
<issue>2012</issue>
<pages>485--508</pages>
<marker />
<rawString>guage 121 (2012) 12–24 23Neuropsychologia, 33, 485–508.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C West</author>
<author>P J Holcomb</author>
</authors>
<title>Event-related potentials during discourse-level semantic integration of complex pictures.</title>
<date>2002</date>
<journal>Cognitive Brain Research,</journal>
<volume>13</volume>
<pages>363--375</pages>
<contexts>
<context citStr="West &amp; Holcomb, 2002" endWordPosition="6785" position="42700" startWordPosition="6782">stures, a component described by the researchers as a ‘‘gesture N450’’ was observed. Wu and Coulson noted the similarity of this effect to the N450 reported by Barrett and Rugg (1990) for second items in unrelated picture pairs relative to related picture pairs (e.g. wrench/fork vs. knife/fork), stating (p. 659) that consistent with their own findings, ‘‘most such ‘picture’ ERP studies report a broadly distributed negativity largest at frontal electrode sites and not evident at occipital sites (Barrett &amp; Rugg, 1990; Holcomb &amp; McPherson, 1994; McPherson &amp; Holcomb, 1999; Sitnikova et al., 2003; West &amp; Holcomb, 2002).’’ In contrast, the negativity reported in the present study was quite evident at occipital sites, as can be seen clearly in Figs. 3 and 4. A second notable finding in our study concerns deaf subjects’ ERP response in the phonologically legal pseudo-sign condition, which was also consistent with an N400 response but was generally larger (more negative) than the negativity seen for semantically incongruent but fully lexical signs. This provides further evidence for broad processing similarities for different linguistic modalities, in the light of similar findings for pseudo-words in earlier st</context>
</contexts>
<marker>West, Holcomb, 2002</marker>
<rawString>West, W. C., &amp; Holcomb, P. J. (2002). Event-related potentials during discourse-level semantic integration of complex pictures. Cognitive Brain Research, 13, 363–375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Wilcox</author>
</authors>
<title>Gesture and language: Cross-linguistic and historical data from signed languages.</title>
<date>2004</date>
<journal>Gesture,</journal>
<volume>4</volume>
<pages>43--73</pages>
<marker>Wilcox, 2004</marker>
<rawString>Wilcox, S. (2004). Gesture and language: Cross-linguistic and historical data from signed languages. Gesture, 4, 43–73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y C Wu</author>
<author>S Coulson</author>
</authors>
<title>Meaningful gestures: Electrophysiological indices of iconic gesture comprehension.</title>
<date>2005</date>
<journal>Psychophysiology,</journal>
<volume>42</volume>
<pages>654--667</pages>
<contexts>
<context citStr="Wu and Coulson (2005)" endWordPosition="8087" position="51172" startWordPosition="8084">ntic contexts in which they occur lead to greater processing costs on the part of language perceivers. This in turn results in increased negativities in the time window often associated with the classic N400 effect, observed in response to word meanings that violate the wider semantic context (Kutas &amp; Hillyard, 1980). For example, Kelly et al. (2004) observed modulation of ERP responses for speech tokens that were either accompanied by matching, complementary or mismatched hand gestures. An N400-like component was observed for mismatched gesture-speech tokens relative to the other conditions. Wu and Coulson (2005) examined ERPs for subjects who watched cartoons followed by a gestural depiction that either matched or mismatched the events shown in the cartoons. Gestures elicited an N400-like component (a socalled ‘‘gesture N450’’) that was larger for incongruent than congruent items. Ozyürek et al. (2007) recorded EEG while subjects listened to sentences with a critical verb (e.g. ‘‘knock’’) accompanied by a related co-speech gesture (e.g. KNOCK). Verbal/gestural semantic content either matched or mismatched the earlier part of the sentence. The researchers noted that following the N1–P2 complex, the ER</context>
<context citStr="Wu &amp; Coulson, 2005" endWordPosition="1334" position="8797" startWordPosition="1331">cessing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), environmental noises (Chao, Nielsen-Bohlman, &amp; Knight, 1995; Van Petten &amp; Rheinfelder, 1995), movie clips (Sitnikova, Holcomb, Kiyonaga, &amp; Kuperberg, 2008; Sitnikova, Kuperberg, &amp; Holcomb, 2003) and co-speech gestures (Kelly, Kravitz, &amp; Hopkins, 2004; Wu &amp; Coulson, 2005). Linguistically anomalous stimuli are not always associated with an N400 response. For example, the left anterior negativity (LAN; Friederici, 2002; Neville, Nicol, Barss, Forster, &amp; Garrett, 1991) and P600 (Osterhout &amp; Holcomb, 1992) are well-known ERP components that have been found in syntactic violation contexts in 1 This possibility is bolstered by recent work of Albert Kim and colleagues, who have found that relative to real word controls, N400 amplitude decreases and P600 amplitude increases, parametrically, as orthographic irregularity increases (Kim &amp; Pitkänen, submitted for publicat</context>
<context citStr="Wu &amp; Coulson, 2005" endWordPosition="1666" position="11184" startWordPosition="1663">pseudo-signs. The ERP response for the non-linguistic gesture condition is a priori more difficult to predict. Previous neuro-imaging studies of deaf signers have reported differences in patterns of activation associated with the perception of signs compared to non-linguistic gestures (Corina et al., 2007; Emmorey et al., 2010; MacSweeney et al., 2004), but the methodologies used in those studies lacked the temporal resolution to determine at what stage of processing these differences may occur. While N400-like responses have been elicited to co-speech gestural mismatches (Kelly et al., 2004; Wu &amp; Coulson, 2005), in our study, gestures occur in place of semantically appropriate sentence-ending items, rather than as a possible accompaniment. It should also be borne in mind that the relationship of signs and grooming gestures is probably not quite akin to that between standard lexical items in spoken language and the orthographically/phonotactically illegal pseudo-words used in earlier ERP studies. Unlike grooming gestures, which are part of everyday life, illegal non-words like ‘‘dkfpst’’ are probably alien to most people’s routine experience. A better spoken-language analogue of our grooming action c</context>
<context citStr="Wu &amp; Coulson, 2005" endWordPosition="7929" position="50150" startWordPosition="7926">diction that phonologically illegal non-signs would elicit a positive-going waveform. However, confirmation of this must await future research. ically seen in analogous speech studies. The effects seen in the item which is present yet enigmatic. While this cannot be entirely Language 121 (2012) 12–24We have already alluded to the growing number of studies which have used ERP methodology to examine the contributions of co-speech manual gestures to the interpretation of both linguistic and non-linguistic stimuli (Holle &amp; Gunter, 2007; Kelly et al., 2004; Ozyürek, Willems, Kita, &amp; Hagoort, 2007; Wu &amp; Coulson, 2005, 2007a, 2007b). Many of these studies have used iconic manual gestures that depict a salient visual–spatial property of concrete objects, such as their size and shape or an associated manner of movement (but see also Cornejo et al., 2009). Collectively these studies suggest that co-speech manual gestures influence semantic representations, and that discrepancies between gestural forms and the semantic contexts in which they occur lead to greater processing costs on the part of language perceivers. This in turn results in increased negativities in the time window often associated with the clas</context>
</contexts>
<marker>Wu, Coulson, 2005</marker>
<rawString>Wu, Y. C., &amp; Coulson, S. (2005). Meaningful gestures: Electrophysiological indices of iconic gesture comprehension. Psychophysiology, 42, 654–667.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y C Wu</author>
<author>S Coulson</author>
</authors>
<title>How iconic gestures enhance communication: An ERP study.</title>
<date>2007</date>
<journal>Brain and Language,</journal>
<volume>101</volume>
<pages>234--245</pages>
<marker>Wu, Coulson, 2007</marker>
<rawString>Wu, Y. C., &amp; Coulson, S. (2007a). How iconic gestures enhance communication: An ERP study. Brain and Language, 101, 234–245.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y C Wu</author>
<author>S Coulson</author>
</authors>
<title>Iconic gestures prime related concepts: An ERP study.</title>
<date>2007</date>
<journal>Psychonomic Bulletin &amp; Review,</journal>
<volume>14</volume>
<pages>57--63</pages>
<marker>Wu, Coulson, 2007</marker>
<rawString>Wu, Y. C., &amp; Coulson, S. (2007b). Iconic gestures prime related concepts: An ERP study. Psychonomic Bulletin &amp; Review, 14, 57–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Ziegler</author>
<author>M Besson</author>
<author>A M Jacobs</author>
<author>T A Nazir</author>
<author>T H Carr</author>
</authors>
<title>Word, pseudoword, and nonword processing: A multitask comparison using eventrelated brain potentials.</title>
<date>1997</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>9</volume>
<pages>758--775</pages>
<contexts>
<context citStr="Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997" endWordPosition="1213" position="7931" startWordPosition="1207">ically/phonologically legal but non-occurring ‘‘pseudo-words’’ (e.g. ‘‘blork’’), and it has sometimes been reported that pseudo-words elicit a stronger N400 response than semantically incongruent real words (Bentin, 1987; Bentin, McCarthy, &amp; Wood, 1985; Hagoort &amp; Kutas, 1995), consistent with the idea that the magnitude of N400 response is related to the difficulty of the ongoing process of semantic-contextual integration. However, orthographically illegal ‘‘non-words’’ (e.g. ‘‘rbsnk’’) do not generally elicit an N400, and a positive component is sometimes seen instead (Hagoort &amp; Kutas, 1995; Ziegler, Besson, Jacobs, Nazir, &amp; Carr, 1997). This may reflect the operation of some kind of filtering mechanism during online processing, through which language users are able to quickly reject forms that lie beyond a certain point of acceptability, or plausibility, during the ongoing processing of the incoming language stream.1 TheN400 (orN400-like responses) canalsobeobserved innumerous contexts involving non-linguistic butmeaningful stimuli, such as pictures (Ganis &amp; Kutas, 2003; Ganis, Kutas, &amp; Sereno, 1996; Nigam, Hoffman, &amp; Simons, 1992; Pratarelli, 1994), faces (Barrett &amp; Rugg, 1989; Bobes, Valdés-Sosa, &amp; Olivares, 1994), envir</context>
<context citStr="Ziegler et al., 1997" endWordPosition="7125" position="44910" startWordPosition="7122">t useful directions such research might take. A third set of findings, concerning the outcome related to our non-linguistic grooming actions, is especially provocative. In contrast to the three other kinds of sentence-final items, all of which could be considered linguistic (i.e. as actual lexical items in two cases, and phonologically legal lexical gaps in the third), the non-linguistic grooming actions elicited a large positivity. As noted earlier, phonologically illegal words in ERP studies have in some cases elicited a positive-going component rather than an N400 (Holcomb &amp; Neville, 1990; Ziegler et al., 1997). Holcomb and Neville (1990) examined differences between pseudo-words and non-words in the visual and auditorymodalities in the context of a lexical decision experiment. Pseudo-words accorded with phonotactic constraints of English; visually presented non-words were composed of consoM. Grosvald et al. / Brain &amp;nant strings and auditorynon-wordswerewords played backwards. The researchers reported that within an early time window (150– 300 ms), auditory non-words (but not visual non-words) elicited amore negative response than pseudo-words, but only at anterior and right hemisphere sites. In a </context>
<context citStr="Ziegler et al. (1997)" endWordPosition="7626" position="48177" startWordPosition="7623">s low-probability with respect to the other three (linguistic) sentence ending conditions. Second, ERP differences between non-words and words have been attributed to the fact that these non-linguistic items have little or nothing in common with lexical entries and therefore do not generate lexical activity (cf. Rugg &amp; Nagy, 1987). Third, the ERP differences observed between pseudo-words and non-words have also been suggested to reflect a pre-lexical filtering process that quickly rejects non-linguistic items based upon aberrant physical characteristics (Holcomb &amp; Neville, 1990). For example, Ziegler et al. (1997) suggest such a categorization may be based on a spelling check in the case of non-word consonant-string stimuli. This last interpretation accords well with a possibility we noted in the Introduction, that such an ERP response may be due to the operation of a filtering/rejection mechanism, allowing language users to efficiently reject items in the incoming linguistic signal that do not fall within some limits of linguistic acceptability. The gesture stimuli in the present study, in lacking the semantic appropriateness of semantically congruent signs, the lexicality of incongruent signs, and ev</context>
</contexts>
<marker>Ziegler, Besson, Jacobs, Nazir, Carr, 1997</marker>
<rawString>Ziegler, J. C., Besson, M., Jacobs, A. M., Nazir, T. A., &amp; Carr, T. H. (1997). Word, pseudoword, and nonword processing: A multitask comparison using eventrelated brain potentials. Journal of Cognitive Neuroscience, 9, 758–775.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Grosvald</author>
</authors>
<date>2012</date>
<journal>Brain &amp; Language</journal>
<volume>121</volume>
<pages>12--24</pages>
<marker>Grosvald, 2012</marker>
<rawString>24 M. Grosvald et al. / Brain &amp; Language 121 (2012) 12–24</rawString>
</citation>
</citationList>
</algorithm>
</algorithms></paper>