<?xml version="1.0"?>
<pdf>
  <title line_height="23.12" font="MGIIDO+NewBaskerville-Roman">Testing the
Development of Linguistic &#xA8; Knowledge in Adult Na&#x131;ve Learners of American
Sign Language</title>
  <section line_height="8.53" font="MGIIFA+NewBaskerville-Italic" letter_ratio="0.26"
year_ratio="0.0" cap_ratio="1.28" name_ratio="0.2" word_count="50"
lateness="0.09090909090909091" reference_score="6.51">MARGRETA VON PEIN Union
Institute &amp; University, Cincinnati, Ohio and University at Albany, State
University of New York Department of Psychology 1400 Washington Avenue Albany, NY
12222 Email: mvpein@yahoo.com JEANETTE ALTARRIBA University at Albany, State
University of New York Department of Psychology 1400 Washington Avenue Albany, NY
12222 Email: ja087@albany.edu<component x="62.89" y="473.25" width="189.8"
height="74.43" page="1" page_width="495.0" page_height="720.0"></component><component
x="272.11" y="484.2" width="180.3" height="63.47" page="1" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.06"
year_ratio="0.01" cap_ratio="0.16" name_ratio="0.21693121693121692" word_count="189"
lateness="0.18181818181818182" reference_score="12.57">for semantically similar
words, for example, is evidence of this direct access to a conceptual store.
Bilingual research empirically testing theories from second language acquisition
(SLA) has not generally included data on adult acquisition of a visual-spatial L2,
such as American Sign Language (ASL). No studies to date have tested the &#xA8;
acquisition of ASL signs by na&#x131;ve learners using a timed procedure that
captures the implicit learning of those signs, even though a recent review by Rosen
(2008) indicates that there is tremendous growth in the study of ASL as a foreign
language, particularly among secondary school students in the United States. Further,
the experiments that have been carried out to examine various characteristics of the
representation of ASL signs did not provide for a context in which the time allotted
for the access and retrieval of a newly acquired sign was constrained, indicating the
automatic processing of the sign. However, neurobiological research in ASL has
confirmed that visual-spatial language processing is essentially the same as
oral-aural language processing (Emmorey, 2002; Emmorey et al., 2003; Horwitz et al.,
2003). The overall similarities in processing between ASL and spoken<component
x="31.15" y="61.15" width="191.31" height="271.69" page="2" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.04"
year_ratio="0.0" cap_ratio="0.1" name_ratio="0.2151394422310757" word_count="251"
lateness="0.2727272727272727" reference_score="11.83">English suggest that novice ASL
bilinguals may represent the new signs in the L2 via the same mechanism that
functions for bilinguals learning a second spoken language. Therefore, a fundamental
question remains open in this area of research study: To what extent are the memory
processes involved in learning ASL signs in the context of L2 learning similar to, or
different from, those involved in learning an oral-aural language? Are signs
processed like words in spoken languages? The aim of the current study is threefold.
First and foremost is the aim to uncover the characteristics of word representation
that are acquired when an adult first learns ASL sign vocabulary. Knowing the levels
of language representation (e.g., phonological, semantic) that are acquired and how
best they can be acquired may inform training methods for learning ASL as an L2.
Second, the work is aimed at investigating the representation in memory of newly
acquired signs under situations that would promote the automaticity of the access of
that information. Using an interference paradigm that will be described later, it was
possible to determine whether semantic or phonological information was encoded early
in the learning of ASL signs without the possibility of elaborative processes that
can be engaged in untimed response tasks. Third, the present work is aimed at testing
a hypothesis put forth by Kroll and Stewart (1994) regarding the conceptual or
semantic development that occurs when one first learns an L2. More will be said about
this final aim in the next section.<component x="240.36" y="61.14" width="191.31"
height="271.69" page="2" page_width="495.0"
page_height="720.0"></component><component x="62.89" y="572.1" width="191.29"
height="96.34" page="3" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.06"
year_ratio="0.01" cap_ratio="0.12" name_ratio="0.2608695652173913" word_count="207"
lateness="0.2727272727272727" reference_score="14.18">This study investigates a
specific part of what &#xA8; adult na&#x131;ve learners of ASL learn when first
exposed to the English equivalents of 28 simple ASL signs. The study investigates
only receptive skills and the levels of representation acquired early in learning.
The study is not about learning ASL itself; rather, it investigates what automatic
mental representations or associations are acquired when adults unfamiliar with a
visual language first "learn" the verbal translations of some signs. The theoretical
models of bilingual memory representation studied by both Kroll and Stewart (1994)
and Altarriba and Mathis (1997) are tested in the current study on the memory of
novice students of ASL. In merging aspects of both the word association model and the
concept mediation model of bilingual memory, Kroll and Stewart (1994) proposed a
model (i.e., the revised hierarchical model) that describes the asymmetrical links
that appear to be present in bilingual language representation as well as a model
that accounts for the differences reported in the literature on translation direction
(see Figure 3). This model contains mental lexicons for the L1 as well as an L2. The
L1 mental lexicon is depicted as larger than that of the L2 because it is assumed
that the bilingual would have<component x="62.89" y="244.32" width="191.3"
height="293.61" page="3" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.06"
year_ratio="0.0" cap_ratio="0.09" name_ratio="0.2090032154340836" word_count="311"
lateness="0.2727272727272727" reference_score="11.17">a larger vocabulary in his or
her native language than in the L2. The link between the L1 and concepts appears to
be bidirectional and very strong. As a person acquires an L2, especially later in
life, L2 words would be integrated into memory by developing a pathway that is
attached to the lexicon of the L1 (an idea emerging from the original word
association model). Finally, the connection between the L2 and concepts is
illustrated as being weak. However, it has been suggested that this link increases in
strength as the bilingual becomes more proficient or fluent in his or her L2 (a
notion derived from the earlier concept mediation model). One advantage of the
revised hierarchical model is that it accounts for several findings that have been
reported in bilingual studies, such as faster translation in the L2-L1 direction,
category interference that occurs only during L1-L2 translation (Kroll &amp; Stewart,
1994), and larger priming effects in the L1-L2 direction than in the L2-L1 direction
(e.g., Altarriba, 1992; Gollan, Forster, &amp; Frost, 1997). In addition, the model
attempts to show how changes in a person's proficiency in the L2 will change the way
in which lexical and conceptual information is accessed (i.e., greater proficiency in
the L2 allows a greater amount of conceptual information to be available). Although
this may be true to some extent, it has been argued that new words in an L2 may not
be stored in just the lexicon of the L2 but rather represented as both a lexical and
conceptual entry if the words were acquired in an environment in which both form and
meaning were emphasized (see Altarriba &amp; Mathis, 1997). Further, it is possible
that the conceptual aspect of some words may not be stored in a common conceptual
store for both languages, simply because there are some items that may represent
language-specific<component x="272.11" y="243.32" width="191.3" height="425.12"
page="3" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.05"
year_ratio="0.01" cap_ratio="0.11" name_ratio="0.292436974789916" word_count="595"
lateness="0.36363636363636365" reference_score="12.6">concepts and, therefore, direct
translations in the opposing language do not exist (Altarriba, 2000). Altarriba and
Mathis (1997) questioned the revised hierarchical model of Kroll and Stewart (1994),
which suggests that nonfluent bilinguals rely on lexical association early in SLA and
only later on concept mediation. As mentioned earlier, Altarriba and Mathis tested
Kroll and Stewart's model with monolingual English speakers who were taught Spanish
for the first time. Altarriba and Mathis designed a set of experiments to investigate
the acquisition of the link between conceptual memory and the L2, hypothesizing that
it could develop as early as the first encounter or first learning session with the
new language. Kroll and Stewart had claimed that this link developed over an
unspecified length of time and remained relatively weak. Altarriba and Mathis chose a
translation recognition paradigm aimed at measuring the interference that would be
caused by the presentation of L1-L2 (English-Spanish) pairs that were in some way
similar, but not identical, to the true translations. They theorized that individuals
would be slower to respond (slower response times [RTs]) to English-Spanish pairs
that were either orthographically or semantically similar to the true translations
(i.e., foils) that had been acquired during the learning session of their experiment.
In the translation recognition task, they indeed found that both monolingual and
bilingual participants had slower RTs to the foils. They concluded that orthographic
and semantic information is automatically coded early in the process of SLA. In other
words, the meanings of words in the new language were represented in the learner's
conceptual store as early as the first learning session. Could similar results be
found in a "crossmodal" bilingual environment? Because Altarriba and Mathis's (1997)
SLA hypotheses and conclusions are based on experimental data from oral-aural
languages, assumptions cannot be made as to whether these hypotheses will function in
the acquisition of all L2s, spoken and visual. Therefore, one of the aims of the
present study was to investigate what adults &#xA8; na&#x131;ve to ASL learn when
first exposed to signs and their English meanings. The current study hypothesizes
that hearing, English-speaking adults learning ASL would also encode semantic, as
well as lexical, information early in the learning process. However, as the study's
focus was a visual language as the L2 acquired, hypothesizing about orthographically
similar words between the two languages had to be altered. Instead, the hypothesis
concerned English words that were phonologically similar to the correct translation.
Adult students of ASL should have slower RTs when the English words are
phonologically similar to the correct translations than when the English words are
unrelated to the translations. A semantic condition was also included, as in
Altarriba and Mathis. To test these hypotheses, an experiment was designed that
included learning and testing phases. First, participants viewed a videotape of ASL
signs and heard the signs' English equivalents. After the participants studied the
signs and their translations, we needed to determine if the participants had
"learned" the corresponding English words. Second, the participants were tested on
their "learning." They viewed the same list of signs and heard an English word from
one of the test conditions, paired with each sign. They had to determine whether the
word was or was not the English translation they had learned for the sign. It was
expected that interference in processing would occur for the foils that were
semantically and phonologically similar to the correct translations that the
participants had learned in the study phase of the experiment if the participants had
indeed accurately encoded the visual, phonological, and semantic referents for each
sign.<component x="31.15" y="57.02" width="191.31" height="611.43" page="4"
page_width="495.0" page_height="720.0"></component><component x="240.36" y="396.73"
width="191.3" height="271.69" page="4" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.1" name_ratio="0.22934472934472935" word_count="702"
lateness="0.45454545454545453" reference_score="12.62">Undergraduate introductory
psychology students (n 48, average age 19.8) from the == University at Albany, State
University of New York participated in this experiment for course credit. The
participants had normal or correctedto-normal visual acuity and had no known hearing
limitations. When they were asked before the experiment, the participants said they
had no knowledge of finger spelling or ASL. Additionally, the participants were also
asked about their knowledge of ASL at the conclusion of the experiment. This practice
of asking participants about their language background both before and after an
experiment has been used previously, as it has been found that, on occasion, the act
of performing the experiment brings to mind a forgotten memory of their exposure to
ASL or other languages (see, e.g., Altarriba &amp; Mathis, 1997). The participants
received partial course credit. At the end of the experiment, a brief language
history questionnaire was administered to ensure that they &#xA8; were na&#x131;ve to
ASL. Mean self-ratings on a 10-point scale revealed native fluency in English at 9.3.
Percent of the day English was spoken was 92.3. Questionnaire results revealed no
exposure to, or knowledge of, ASL or any other signed language (see Appendices A and
B). Materials Sign Selection. Twenty-eight signs were selected that abided by the
following four criteria: (a) simple or monomorphemic, (b) frequently used, (c)
visually dissimilar from each another, and (d) not transparent. We relied on two
beginning ASL teaching texts and two ASL dictionaries as the source for simple and
frequently used signs (Humphries, Padden, &amp; O'Rourke, 1980; Smith, Lentz, &amp;
Mikos, 1988; Sternberg, 1994; Stokoe, Casterline, &amp; Croneberg, 1965). We wanted
to select a list of signs that were completely distinct from one another in terms of
all parameters, including movement, shape, and position. In other words, if two signs
varied from each other on a single parameter, we excluded those items from our final
list of signs. This ensured that the signs on the list were visually dissimilar. The
English translations of signs on the list were all concrete nouns. A native deaf
signer was videotaped signing the list. Videotaping a native signer is the ASL
equivalent to having a native English speaker say English words. The signer's mean
signing time per word was 1,260 milliseconds. The English speaker's mean time for
each word was 534 milliseconds. Therefore, it was determined that a 5,000-millsecond
interval between each sign would give participants adequate time to see the sign,
hear the English word, and respond as required. A 5-second interval was also the
preferred elapsed time between signs in recall and recognition tests in other
published works (Bonvillian, Rea, Orlansky, &amp; Slade, 1987; Bower &amp; Karlin,
1974; Cochran, McDonald, &amp; Parault, 1999). There was no sound on the videotape.
Next we needed to be sure the chosen signs were not transparent. Thirty participants
with no knowledge of ASL or experience with finger spelling and from the same pool as
the subsequent experiment were then asked to guess the English translations for the
signs. Two participants correctly guessed two different signs. These signs were
eliminated from the list. This ensured that the remaining signs were not
transparent-that is, their translations were not easily guessed-and, thus, these
signs were used in the ensuing experiment. Creating Semantic Associates. The English
translations for the 28 signs selected were then presented to 30 participants who did
not take part in the earlier norming study or in the subsequent experiment. They were
asked to write down the first word that came to mind next to each of the English
words. All of the words that the participants wrote were tabulated to find the word
most frequently associated with the target word on the list. Only exact wording was
tallied (i.e., not plurals for singular words or derivations of our words on the
list). For example, for "shoe" people wrote "sock" and "socks," which were counted as
two different words. Thus, the most frequently reported word for each target word was
used as the semantic associate for these items. As the participants were from the
same pool as those who would perform the subsequent experiment, these association
norms would presumably reflect the knowledge of the participants in the experiment
proper.<component x="240.36" y="56.85" width="191.31" height="271.69" page="4"
page_width="495.0" page_height="720.0"></component><component x="62.89" y="648.81"
width="191.29" height="19.63" page="5" page_width="495.0"
page_height="720.0"></component><component x="62.89" y="56.87" width="191.3"
height="567.45" page="5" page_width="495.0"
page_height="720.0"></component><component x="272.11" y="484.41" width="191.3"
height="184.02" page="5" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.08" name_ratio="0.208955223880597" word_count="134"
lateness="0.45454545454545453" reference_score="12.46">The experiment required words
in four test conditions: (a) the target words (i.e., the English words the
participant learned for the videotaped signs); (b) words unrelated to the target
words; (c) words semantically related to the target words; and (d) words
phonologically related to the target words. The unrelated items were made up of words
of approximately the same length and fre&#x2D8; quency as the signs' English
equivalents (Kucera &amp; Francis, 1967). Mean word length and mean word frequency
for the words in all four conditions are listed in Table 1. t -Tests indicated no
significant differences across conditions for either &gt; frequency or length (all ps
.05). The phonologically related condition was constructed of rhyming words
(Fergusson, 1985; Webster's, 1987). Sample stimulus items include the following:
Targets: apple, cookie; Unrelated: thigh, paddle; Semantic<component x="272.11"
y="244.08" width="191.3" height="194.98" page="5" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.19" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.17"
year_ratio="0.0" cap_ratio="0.93" name_ratio="0.21428571428571427" word_count="14"
lateness="0.45454545454545453" reference_score="13.1">TABLE 1 Word Length and
Frequency Means and Standard Deviation for Four Test Conditions<component x="272.11"
y="189.29" width="184.26" height="28.11" page="5" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.2" name_ratio="0.2559055118110236" word_count="508"
lateness="0.5454545454545454" reference_score="14.8">Foil: pie, sweet; Phonological
Foil: chapel, rookie. Thus, the words that corresponded to the target "apple" in each
condition included "thigh," "pie," and "chapel." The set can be derived for "cookie"
in the same way from the examples provided earlier (see Appendix C for a complete
listing of items). The videotape of the 28 common ASL signs created previously was
used in the current experiment. Four signs and four English words, each from a
different test condition, were isolated for use during the practice phase. The
remaining 24 English words for each condition (i.e., the English translations for the
sign, the unrelated words, the semantically related words, and the phonologically
related words) were counterbalanced across four experimental lists such that 6 words
from each condition appeared only in one list. Each list had a different set of six
words from each of the four conditions. To familiarize participants with the test
procedure, the four practice signs and words were shown and heard at the start of
each test phase. Everyone received the same practice items. The videotape of the 28
signs was then reordered into four randomly selected orders using Media 100's digital
nonlinear editing system. With the GoldWave audio program, the 96 test English words,
24 words in four conditions, plus 8 words used for practice were entered into the
computer. The words were cued so that they would be heard after the sign began but
before the sign ended. To standardize how the signs were presented to the
participant, Liddell's (1984) description of sign phonology was employed. In his
description, a sign can begin with either a MOVEMENT (M) or a HOLD (H) at a
stationary location. Signs can also end with either an M or an H. For example, the
sign for FATHER is HMH. In the sign for FATHER, the first movement to the forehead is
not relevant to sign formation. In the sign, the first and last contacts of the thumb
on the forehead are HOLDS, with the intervening MOVEMENT. (Note that another sign
form for FATHER is the thumb contact HOLD on the forehead without MOVEMENT but with
other fingers wiggling.) While seeing FATHER on videotape, the participant heard the
English word "father" after the initial H but before the M. The participant heard the
English word as the signer's palm began traveling toward her face. The English word
was completed before the signer's thumb came to rest on her forehead. Hearing the
English translation at the same moment in each sign's articulation was crucial for
accurately recording RT. Therefore, the words were cued to be heard just after the
initial M or H, as the signer was transitioning to the following H or M of the sign.
A program developed using SuperLab Pro software was used to record elapsed time
between the onset of the English word and the participant's response. The signs for
the experiment were presented on a video monitor, and the words were heard over
speakers on either side of the monitor and linked to a laptop computer.<component
x="31.15" y="57.02" width="191.3" height="611.43" page="6" page_width="495.0"
page_height="720.0"></component><component x="240.36" y="572.09" width="191.3"
height="96.34" page="6" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.04"
year_ratio="0.0" cap_ratio="0.03" name_ratio="0.27304347826086955" word_count="575"
lateness="0.6363636363636364" reference_score="12.55">All participants were assigned
a random number and were tested individually. The first phase of the experiment in
which the participants studied the signs and their English translations was the
acquisition phase. Participants were seated in front of the video monitor to watch 28
signs one by one and hear their English translations. They were asked to try their
best to learn the English translations for the 28 ASL signs. Within the same 5-second
interval for each sign, the participants heard the sign's English translation twice.
The videotape was repeated twice in the same order, so the participants saw the signs
twice and heard the English translations four times. Then the participants were asked
to check what they had learned by viewing the same 28 signs, without translations, in
a different order and saying aloud the English word they remembered for the sign. At
the end of the viewing without the audio, we read aloud the errors and omissions the
participants had made in naming the English translations and provided the accurate
sign and spoken translation for items the participants had missed. Then the
participants viewed the list of 28 signs again but in a different order. The English
words and their corresponding signs were repeated once again. This study test process
was repeated in full, until the participants reached 100% accuracy. When the
participants named the translations for the signs 100% correctly, they went on to the
testing phase of the experiment. To limit the duration of the experiment,
participants were excused from the experiment if they did not reach 100% accuracy
after half an hour of study. On this basis, 3 individuals were excluded from
finishing the experiment and 3 new participants were added to maintain the group
number at 48. Following the acquisition phase, the participants were given a 3-minute
intervening task, which included counting backward by 4s from 534. This task diverted
the participants from thinking about the acquisition phase and actively engaging in
rehearsal. The 3 minutes also allowed us to set up the computer for the test phase.
The second phase of the experiment, in which the participants decided if the word
they heard was the translation they had learned for the sign, was the testing phase.
On the monitor, the participants saw each of the 28 signs again in yet a different
order paired with hearing an English word. (Four of those signs formed the practice
trials that were then followed by the remaining 24 signs divided equally among the
following four conditions: correct target, semantically related, phonologically
related, and unrelated.) Each participant viewed a single experimental list in random
order. The participants were told to press a designated "yes" or "no" key on the
laptop keypad indicating whether the word they heard was or was not the word they had
learned for the sign on the video monitor. They were to make their decisions as
quickly and as accurately as possible. The participants were given 1,500 milliseconds
to respond. At the beginning of the test phase, four signs each with an English word
were presented as practice trials to familiarize the participants with the test
procedure. Then the actual test proceeded. As mentioned earlier, at the end of the
experiment, the participants were asked four questions about sign recognition (see
Appendix B) and answered a brief language history questionnaire. None of the
participants was found to have had prior experience with ASL or any other signed
language.<component x="240.36" y="56.85" width="191.33" height="479.92" page="6"
page_width="495.0" page_height="720.0"></component><component x="62.89" y="330.99"
width="191.3" height="337.45" page="7" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.1"
year_ratio="0.0" cap_ratio="0.18" name_ratio="0.23170731707317074" word_count="164"
lateness="0.6363636363636364" reference_score="15.26">For each participant, mean
response times and standard deviations (SDs) were computed for the four conditions
(true target, semantic, phonological, and unrelated). After computing SDs for each
participant's RT in each condition, we found no RTs, or outliers, that exceeded 2.5
SDs above or below the mean for each condition. All participants' RTs were included
in our analysis. Mean RTs, SDs, and error rates for the four test conditions (correct
translation, unrelated, semantic, and phonological) for all participants are listed
in Table 2. Only data for correct responses were included. An analysis of variance
(ANOVA) indicated that the four conditions differed significantly from one another,
with F (3,45) 27.708, = &lt; MS 8.620, p .001. Planned comparisons (Bon= ferroni
corrections were applied) showed that RTs for the semantic and the phonological
conditions &gt; were virtually the same, with t (47) 0.220, p = &#x2212; .05.
However, the RTs for the semantic and phonological conditions compared to the
unrelated condition were significantly slower, indicated by<component x="62.89"
y="56.87" width="191.3" height="238.82" page="7" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.19" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.22"
year_ratio="0.0" cap_ratio="0.84" name_ratio="0.10526315789473684" word_count="19"
lateness="0.6363636363636364" reference_score="16.08">TABLE 2 Mean Response Times
(Milliseconds), Standard Deviations, and Error Rates (Percentages) for All Test
Conditions (n 48) =<component x="272.11" y="625.1" width="180.54" height="43.84"
page="7" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.09"
year_ratio="0.0" cap_ratio="0.07" name_ratio="0.20175438596491227" word_count="342"
lateness="0.7272727272727273" reference_score="14.44">&lt; t (47) 2.363, p .05
(Cohen's d 0.48) and = = &lt; t (47) 2.753, p .01 (Cohen's d 0.56), = = respectively.
Semantically related foils produced an interference effect suggesting that novices in
ASL had formed a conceptual link to the ASL signs. Phonologically related foils
produced a slightly larger interference effect, indicating that the participants had
learned to associate the newly acquired signs and their phonological representations
in English. Error data were examined to see if the higher rate of errors in the
phonological condition was significantly different from other conditions (see Table
2). An ANOVA indicated that there was a significant difference in error rates across
the four conditions, with F (3,45) 27.708, MS 4.852; = = &lt; p .001. Planned
comparisons (Bonferroni corrections were applied) revealed that the error rate for
the target condition differed significantly from the phonological condition, with t
(47) 5.698, = &#x2212; &lt; p .001 (Cohen's d 1.16). In addition, the error = rate
for the unrelated condition was significantly different from the phonological
condition, with &lt; t (47) 6.132, p . 0001 (Cohen's d 1.77). = &#x2212; = Finally,
the error rate for the semantic condition was also significantly different from the
phono&lt; logical condition, with t (47) 5.695, p .001 = &#x2212; (Cohen's d 1.16).
Appendix D includes a list= ing of individual items and their corresponding error
rates. Note that although only one item in the semantic category produced a
significant error rate (i.e., "kids"), several items contributed to the large error
rate in the phonological condition. In this later condition, most prominent were the
items "fair," "bother," and "fig," corresponding to "bear," "father," and "pig,"
respectively. Clearly, these kinds of errors of substitution stem from the similarity
across items in terms of initial phonemes; thus, as in most situations, whenever
manner/place of articulation overlaps across lexical items, errors of recognition and
identification are more likely to occur. More will be said later in terms of the
implications of these kinds of errors for lexical representation and processing in
general.<component x="272.11" y="56.87" width="191.31" height="469.89" page="7"
page_width="495.0" page_height="720.0"></component><component x="31.15" y="648.81"
width="191.29" height="19.63" page="8" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.05"
year_ratio="0.0" cap_ratio="0.09" name_ratio="0.25285171102661597" word_count="1578"
lateness="0.8181818181818182" reference_score="15.19">The experiments described here
were designed to follow the approach of Altarriba and Mathis's (1997) experiments in
SLA. When Altarriba and Mathis tested English-speaking monolinguals who had just
acquired a set of words in an L2 (Spanish), they found that these participants had
encoded both semantic and orthographic aspects of the new words and were able to
access this new information when responding to a translation recognition task.
Because an interference effect occurred for both conditions, it appeared that
monolinguals formed a direct link with lexical and conceptual levels of
representation when first learning an L2. In the current study, the results of the
experiment on acquiring the ASL signs confirmed that L2 (ASL) conceptual processing
(as well as phonological processing of the English translation equivalents) is
involved very early in the language acquisition process. Both semantic and
phonological interference effects were reported within the current study. It can be
assumed, then, that the processes involved in acquiring an L2 as described by
Altarriba and Mathis also come into play for adult novices learning a visual language
as the L2. Moreover, as reported by Altarriba and Mathis, the current work also
indicates that the revised hierarchical model proposed by Kroll and Stewart (1994)
should be modified to indicate that conceptual/semantic information can be acquired
in the earliest stages of L2 learning. In other words, even after a single learning
session, individuals can acquire the knowledge of the meaning of newly learned L2
words-a link that had been purported to take more time to develop, as per the revised
hierarchical model. In relation to the above issues of acquisition and development,
note that all of the participants in the current study had been exposed to an L2 at
some point in their lives (either from birth or through schooling in later years; see
Appendix A). Thus, it appears that for the current participants, the acquisition of
concepts via sign constituted a kind of "third-language" exposure, although it was
not a verbal language, as were their L1s and L2s. Given the briefness of the
questionnaire that was used, it is difficult to assess the degree to which the
present participants were fluent in their L2 compared to their L1. Thus, although all
participants had been exposed to an L2 at some point in their lives, their relative
fluency in that language is likely to have varied considerably and is not currently
known. Future investigations of the acquisition of ASL signs should examine the
extent to which individuals who are exposed to an L2 and who consider themselves
truly "bilingual" or "fluent/proficient" in their L2 show different patterns of
translation recognition for newly acquired signs. Mode or context of learning and
acquisition should also be taken into account in further investigations. Thus,
participants' bilingualism may be examined as a variable of interest in future
studies of sign acquisition, as this question was not a focus of the current
investigation. The present study provided evidence that conceptual and phonological
interference occurs in learning the meanings of ASL signs-a finding similar to that
reported for the acquisition of words of a second, spoken language (see, e.g.,
Altarriba &amp; Mathis, 1997; van Hell &amp; Mahn, 1997). Previous ASL research
evidence points to the parallel functioning of visual-spatial and oral-aural
languages. For example, signs that look different from one another are identified
more quickly than those that look similar to one another. This mimics the
phonological similarity effect that occurs in spoken languages (see also Emmorey,
2002). In addition, Liddell (1984) illustrated how signs have beginnings, middles,
and ends similar to the segments of spoken words, onsets, medial phases, and offsets.
An interesting finding in the current set of results is that the error rates were
significantly higher in the phonological condition, as compared to other conditions
within the experiment; that is, many more confusion errors occurred when foils were
phonologically similar to the true translation. Given that the test pairs in the
current case were comprised of a spoken word and a word that was signed, the
implication is that the participants accessed the phonological representations of the
signed words to the extent that those representations interfered with their ability
to reject the incorrect pairing. Theoretically, these data suggest that individuals
accessed phonology when not specifically directed to do so in the context of the
current study. Phonology was encoded in an implicit manner, as part of the learning
of signs, overall. Thus, as current models of bilingual representation have suggested
(see, e.g., BIA and BIA in Dijkstra &amp; van Heuven, 1998), phonol+ ogy is often
retrieved in the process of understanding newly acquired concepts in an L2-even if it
is a signed language. Further, the current data underscore the basic finding in the
literature that many auditory confusion errors are derived from words that have
phonological overlap and share either place of articulation or manner of
articulation, or both. The fact that these phonological representations in the
current study stem from the recognition of a signed word is interesting evidence to
suggest that phonological confusion errors are not modality-specific (see also Engle,
Cantor, &amp; Turner, 1989, for a related discussion). Although the current study
examined translation recognition for newly acquired signs and their English
translations, the participants performed a learning task that by its very nature
emphasized the phonological and semantic aspects of the association between the
English word and its corresponding sign. Although the participants developed these
new representations such that they achieved 100% accuracy on a test of their
knowledge, it is unclear to what extent different participants might have engaged in
their own strategies in learning the signs of interest. Clearly, the possibility that
the participants engaged in their own mnemonic strategies to shape their mental
representations for the signs and their English counterparts may have affected the
way in which this knowledge was learned and encoded for each participant. Future
examinations of the acquisition of signs should vary instructions so as to either
document the means by which participants actively learn signs or provide concrete
instructions as to the types of strategies that should be used (e.g., imagery,
context availability) so as to investigate the influence of learning strat1 egy on
the ultimate representation of new signs. Moreover, it is important to note here that
although the current work focused on the learning of ASL signs, the learning of
language, in general, encompasses many more elements that bring together aspects of
reasoning, pragmatic usage, contextual influences, and the like (see, e.g.,
Larsen-Freeman, 2003; van Lier, 2004). Thus, language development is a highly dynamic
process, and future work may focus on the acquisition of ASL signs in broader
contexts of language, incorporating a more ecological approach to acquisition. In a
related vein, neurological investigations into the hemispheric involvement of
imageable concrete signs in ASL, as distinct fromabstract lexical forms, continue to
raise questions about the different roles imagery may play in ASL and English
(Emmorey &amp; Corina, 1993). Most recently, neurobiological evidence also indicates
that both signed and spoken languages are generally localized in the same area in the
left hemisphere (Corina, Vaid, &amp; Bellugi, 1992; Damasio &amp; Damasio, 2000;
Emmorey et al., 2003; Horwitz et al., 2003). Notwithstanding the linguistic and
neurobiological parallels between ASL and the spoken languages of the world, we
recognize that the visual modality makes a distinct difference in L2 learning. The
current study kept the learning challenge of ASL to a bare minimum (i.e., acquiring
the English words for 28 simple signs). Nothing about sign perception was
investigated. Clearly, &#xA8; the greater part of understanding how sign-na&#x131;ve
adults learn ASL has to include working memory experiments on what the adult learner
processes (i.e., sees, stores, attends to, recalls, etc.) in the visual modality
(see, e.g., Wilson &amp; Emmorey, 2003). Experiments on reproducing ASL signs are
recommended, as well as experiments with ASL units longer than primarily single
monomorphemic signs. When we analyzed the ways the participants remembered the
English meanings during the study phase of the present experiment, another potential
area of research became clear. Although the participants studied the English meanings
for the signs in the learning part of the experiment, we informally noted evident
mnemonics used by two participants, each for a single word. For example, one
participant said "father-head" while hearing the word "father" and viewing FATHER, in
which the thumb of the open hand shape touches the forehead. Another participant
during the study said "funny-nose" when seeing CLOWN, which is made by cupping the
nose with one hand. Future experiments on systematically including mnemonics in the
study phase might offer insight into another method for teaching ASL as an L2. The
concept mediation model, explained in Altarriba and Mathis's (1997) experiments and
in the current study, supports the practice of teaching SLA using contextual units
that emphasize the semantic or conceptual representation of a newly acquired word.
Many beginning ASL texts already emphasize contextual learning (see, e.g., Smith et
al., 1988). Thus, assuming that the acquisition of words in aural and visual
languages is similar, researchers can focus on how the visual modality is mentally
represented by hearing adults learning a signed language. What is most important to
keep in mind is that bilingual research should include oral-aural as well as
visual-spatial languages, and as the experiment in this study shows, the concept
mediation hypothesis (as well as the modifications of the revised hierarchical model
as posed by Altarriba and Mathis) applies to signed as well as to spoken
language.<component x="31.15" y="56.87" width="191.3" height="556.63" page="8"
page_width="495.0" page_height="720.0"></component><component x="240.36" y="57.0"
width="191.31" height="611.43" page="8" page_width="495.0"
page_height="720.0"></component><component x="62.89" y="57.03" width="191.3"
height="611.42" page="9" page_width="495.0"
page_height="720.0"></component><component x="272.11" y="57.01" width="191.3"
height="611.43" page="9" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="7.71" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.26" name_ratio="0.4158415841584158" word_count="101"
lateness="0.9090909090909091" reference_score="17.03">This research was completed as
part of the requirements for the Doctor of Philosophy degree awarded to the first
author. We would like to thank Lauren Cowell for assistance with data collection,
Erik L. Olheiser and Matthew Pastizzo for their help with programming and analysis,
and Christine Pryzbylo for her role in the development of research materials, as a
native ASL signer. We would also like to extend our gratitude to Rhoda Linton, Nancy
Mardas, Elizabeth Minnich, Randall Myers, and Janet Pray for their comments on an
earlier version of this work, as members of the first author's Doctoral Dissertation
Committee.<component x="31.15" y="514.59" width="191.3" height="117.3" page="10"
page_width="495.0" page_height="720.0"></component></section>
  <section line_height="7.71" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.03"
year_ratio="0.0" cap_ratio="0.05" name_ratio="0.2857142857142857" word_count="21"
lateness="0.9090909090909091" reference_score="14.43">1 We thank an anonymous
reviewer for pointing out this issue to us in an earlier draft of the current
article.<component x="31.15" y="446.53" width="191.29" height="19.18" page="10"
page_width="495.0" page_height="720.0"></component></section>
  <section line_height="7.71" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.22"
year_ratio="0.05" cap_ratio="0.27" name_ratio="0.15765765765765766" word_count="222"
lateness="0.9090909090909091" reference_score="28.64">Altarriba, J. (1990).
Constraints on interlingual facilitation effects in priming in Spanish-English
bilinguals. Unpublished doctoral dissertation, Vanderbilt University, Nashville, TN.
Altarriba, J. (1992). The representation of translation equivalents in bilingual
memory. In R. J. Harris (Ed.), Cognitive processing in bilinguals (pp. 157- 174).
Amsterdam: Elsevier Science. Altarriba, J. (2000). Language processing and memory
retrieval in Spanish-English bilinguals. Spanish Applied Linguistics, 4, 215-245.
Altarriba, J., &amp; Mathis, M. (1997). Conceptual and lexical development in second
language acquisition. Journal of Memory and Language , 36 , 550- 568. Bonvillian, J.
D., Rea, A. C., Orlansky, M. D., &amp; Slade, L. A. (1987). The effect of sign
language rehearsal on deaf subjects' immediate and delayed recall of English word
lists. Applied Psycholinguistics, 8, 33- 54. Bower, G. H., &amp; Karlin, M. B.
(1974). Depth of processing pictures of faces and recognition memory. Journal of
Experimental Psychology, 4, 751- 757. Cochran, B. P., McDonald, J. L., &amp; Parault,
S. J. (1999). Too smart for their own good: The disadvantage of a superior processing
capacity for adult language learners. Journal of Memory and Language , 41, 30- 58.
Corina, D. P., Vaid, J., &amp; Bellugi, U. (1992). The linguistic basis of left
hemisphere specialization. Science , 255, 1258-1260. Damasio, A. R., &amp; Damasio,
H.(2000). Language and the brain. In K. Emmorey &amp; H. Lane (Eds.), The
signs<component x="31.15" y="61.15" width="191.3" height="336.47" page="10"
page_width="495.0" page_height="720.0"></component></section>
  <section line_height="7.58" font="MGIIFA+NewBaskerville-Italic" letter_ratio="0.23"
year_ratio="0.04" cap_ratio="0.41" name_ratio="0.1457286432160804" word_count="398"
lateness="0.9090909090909091" reference_score="30.1">of language revisited: An
anthology to honor Ursula Bellugi and Edward Klima (pp. 477-491). Mahwah, NJ:
Erlbaum. Dijkstra, T., &amp; van Heuven, W. J. B. (1998). The BIA model and bilingual
word recognition. In J. Grainger &amp; A. Jacobs (Eds.), Localist connectionist
approaches to human cognition (pp. 189-225). Hove, England: Erlbaum. Emmorey, K.
(2002). Language, cognition, and the brain. Mahwah, NJ: Erlbaum. Emmorey, K., &amp;
Corina, D. (1993). Hemispheric specialization for ASL signs and English words:
Differences between imageable and abstract forms. Neuropsychologia, 31, 645-653.
Emmorey, K., Grabowski, T., McCullough, S., Damasio, H., Ponto, L., Hichwa, R., et
al. (2003). Neural systems underlying lexical retrieval for sign language.
Neuropsychologia, 41, 85-95. Engle, R. W.,Cantor, J., &amp; Turner, M.L. (1989).
Modality effects: Do they fall on deaf ears? Quarterly Journal of Experimental
Psychology A: Human Experimental Psychology, 41, 273-292. Fergusson, R. (1985). The
Penguin rhyming dictionary. London: Penguin Books. Gollan, T. H., Forster, K. I.,
&amp; Frost, R. (1997). Translation priming with different scripts: Masked priming
with cognates and noncognates in Hebrew- English bilinguals. Journal of Experimental
Psychology: Learning, Memory and Cognition, 23, 1122- 1139. Horwitz, B., Amunts, K.,
Bhattacharyya, R., Patkin, D., Jeffries, K., Zilles, K., et al. (2003). Activation of
Broca's area during the production of spoken and signed language: A combined
cytoarchitectonic mapping and PET analysis. Neuropsychologia, 41, 1868-1876.
Humphries, T., Padden, C., &amp; O'Rourke, T. J. (1980). A basic course in American
Sign Language . Silver Spring, MD: T. J. Publishers. Kroll, J. F., &amp; Stewart, E.
(1994). Category interference in translation and picture naming: Evidence for
asymmetric connections between bilingual memory representations. Journal of Memory
and Language , 33, 149-173. &#x2D8; Kucera, H., &amp; Francis, N. W. (1967).
Computational analysis of present-day American English. Providence, RI: Brown
University Press. Larsen-Freeman, D. (2003). Teaching language: From grammar to
grammaring . Boston: Thomson-Heinle. Liddell, S. (1984). Think and believe:
Sequentiality in American Sign Language. Language , 60, 372-398. Potter, M. C., So,
K. -F., von Eckardt, B., &amp; Feldman, L. B. (1984). Lexical and conceptual
representation in beginning and proficient bilinguals. Journal of Verbal Learning and
Verbal Behavior , 23, 23-38. Rosen, R. S. (2008). American Sign Language as a foreign
language in U.S. high schools: State of the art. Modern Language Journal , 92, 10-38.
Smith, C., Lentz, E. M., &amp; Mikos, K. (1988). Signing naturally: Student workbook
level 1. San Diego, CA: DawnSign Press.<component x="240.36" y="62.29" width="191.3"
height="605.34" page="10" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.19" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.09"
year_ratio="0.0" cap_ratio="0.31" name_ratio="0.13636363636363635" word_count="88"
lateness="1.0" reference_score="18.98">Mean age in years Mean self-rating (10-point
scale: 1 very little; 10 native-like) on overall English fluency = = Percentage of
day English was typically spoken Percentage of participants who had been exposed to
an L2 other than English from birth (countries of origin included Dominican Republic,
India, Iran, Pakistan, and Puerto Rico) Percentage of participants who had been
exposed to an L2 other than English later in life, primarily at school (languages
included Spanish, Arabic, Hindi, and Farsi but NOT American Sign Language or another
signed language)<component x="62.89" y="199.77" width="346.71" height="77.93"
page="11" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.19" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.81"
year_ratio="0.0" cap_ratio="0.0" name_ratio="0" word_count="4" lateness="1.0"
reference_score="10.01">19.8 9.3 92.3 23<component x="447.36" y="239.62"
width="15.73" height="38.08" page="11" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.53" font="MGIIFA+NewBaskerville-Italic" letter_ratio="0.26"
year_ratio="0.0" cap_ratio="1.28" name_ratio="0.2" word_count="50"
lateness="0.09090909090909091" reference_score="6.51">MARGRETA VON PEIN Union
Institute &amp; University, Cincinnati, Ohio and University at Albany, State
University of New York Department of Psychology 1400 Washington Avenue Albany, NY
12222 Email: mvpein@yahoo.com JEANETTE ALTARRIBA University at Albany, State
University of New York Department of Psychology 1400 Washington Avenue Albany, NY
12222 Email: ja087@albany.edu<component x="62.89" y="473.25" width="189.8"
height="74.43" page="1" page_width="495.0" page_height="720.0"></component><component
x="272.11" y="484.2" width="180.3" height="63.47" page="1" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.06"
year_ratio="0.01" cap_ratio="0.16" name_ratio="0.21693121693121692" word_count="189"
lateness="0.18181818181818182" reference_score="12.57">for semantically similar
words, for example, is evidence of this direct access to a conceptual store.
Bilingual research empirically testing theories from second language acquisition
(SLA) has not generally included data on adult acquisition of a visual-spatial L2,
such as American Sign Language (ASL). No studies to date have tested the &#xA8;
acquisition of ASL signs by na&#x131;ve learners using a timed procedure that
captures the implicit learning of those signs, even though a recent review by Rosen
(2008) indicates that there is tremendous growth in the study of ASL as a foreign
language, particularly among secondary school students in the United States. Further,
the experiments that have been carried out to examine various characteristics of the
representation of ASL signs did not provide for a context in which the time allotted
for the access and retrieval of a newly acquired sign was constrained, indicating the
automatic processing of the sign. However, neurobiological research in ASL has
confirmed that visual-spatial language processing is essentially the same as
oral-aural language processing (Emmorey, 2002; Emmorey et al., 2003; Horwitz et al.,
2003). The overall similarities in processing between ASL and spoken<component
x="31.15" y="61.15" width="191.31" height="271.69" page="2" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.04"
year_ratio="0.0" cap_ratio="0.1" name_ratio="0.2151394422310757" word_count="251"
lateness="0.2727272727272727" reference_score="11.83">English suggest that novice ASL
bilinguals may represent the new signs in the L2 via the same mechanism that
functions for bilinguals learning a second spoken language. Therefore, a fundamental
question remains open in this area of research study: To what extent are the memory
processes involved in learning ASL signs in the context of L2 learning similar to, or
different from, those involved in learning an oral-aural language? Are signs
processed like words in spoken languages? The aim of the current study is threefold.
First and foremost is the aim to uncover the characteristics of word representation
that are acquired when an adult first learns ASL sign vocabulary. Knowing the levels
of language representation (e.g., phonological, semantic) that are acquired and how
best they can be acquired may inform training methods for learning ASL as an L2.
Second, the work is aimed at investigating the representation in memory of newly
acquired signs under situations that would promote the automaticity of the access of
that information. Using an interference paradigm that will be described later, it was
possible to determine whether semantic or phonological information was encoded early
in the learning of ASL signs without the possibility of elaborative processes that
can be engaged in untimed response tasks. Third, the present work is aimed at testing
a hypothesis put forth by Kroll and Stewart (1994) regarding the conceptual or
semantic development that occurs when one first learns an L2. More will be said about
this final aim in the next section.<component x="240.36" y="61.14" width="191.31"
height="271.69" page="2" page_width="495.0"
page_height="720.0"></component><component x="62.89" y="572.1" width="191.29"
height="96.34" page="3" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.06"
year_ratio="0.01" cap_ratio="0.12" name_ratio="0.2608695652173913" word_count="207"
lateness="0.2727272727272727" reference_score="14.18">This study investigates a
specific part of what &#xA8; adult na&#x131;ve learners of ASL learn when first
exposed to the English equivalents of 28 simple ASL signs. The study investigates
only receptive skills and the levels of representation acquired early in learning.
The study is not about learning ASL itself; rather, it investigates what automatic
mental representations or associations are acquired when adults unfamiliar with a
visual language first "learn" the verbal translations of some signs. The theoretical
models of bilingual memory representation studied by both Kroll and Stewart (1994)
and Altarriba and Mathis (1997) are tested in the current study on the memory of
novice students of ASL. In merging aspects of both the word association model and the
concept mediation model of bilingual memory, Kroll and Stewart (1994) proposed a
model (i.e., the revised hierarchical model) that describes the asymmetrical links
that appear to be present in bilingual language representation as well as a model
that accounts for the differences reported in the literature on translation direction
(see Figure 3). This model contains mental lexicons for the L1 as well as an L2. The
L1 mental lexicon is depicted as larger than that of the L2 because it is assumed
that the bilingual would have<component x="62.89" y="244.32" width="191.3"
height="293.61" page="3" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.06"
year_ratio="0.0" cap_ratio="0.09" name_ratio="0.2090032154340836" word_count="311"
lateness="0.2727272727272727" reference_score="11.17">a larger vocabulary in his or
her native language than in the L2. The link between the L1 and concepts appears to
be bidirectional and very strong. As a person acquires an L2, especially later in
life, L2 words would be integrated into memory by developing a pathway that is
attached to the lexicon of the L1 (an idea emerging from the original word
association model). Finally, the connection between the L2 and concepts is
illustrated as being weak. However, it has been suggested that this link increases in
strength as the bilingual becomes more proficient or fluent in his or her L2 (a
notion derived from the earlier concept mediation model). One advantage of the
revised hierarchical model is that it accounts for several findings that have been
reported in bilingual studies, such as faster translation in the L2-L1 direction,
category interference that occurs only during L1-L2 translation (Kroll &amp; Stewart,
1994), and larger priming effects in the L1-L2 direction than in the L2-L1 direction
(e.g., Altarriba, 1992; Gollan, Forster, &amp; Frost, 1997). In addition, the model
attempts to show how changes in a person's proficiency in the L2 will change the way
in which lexical and conceptual information is accessed (i.e., greater proficiency in
the L2 allows a greater amount of conceptual information to be available). Although
this may be true to some extent, it has been argued that new words in an L2 may not
be stored in just the lexicon of the L2 but rather represented as both a lexical and
conceptual entry if the words were acquired in an environment in which both form and
meaning were emphasized (see Altarriba &amp; Mathis, 1997). Further, it is possible
that the conceptual aspect of some words may not be stored in a common conceptual
store for both languages, simply because there are some items that may represent
language-specific<component x="272.11" y="243.32" width="191.3" height="425.12"
page="3" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.05"
year_ratio="0.01" cap_ratio="0.11" name_ratio="0.292436974789916" word_count="595"
lateness="0.36363636363636365" reference_score="12.6">concepts and, therefore, direct
translations in the opposing language do not exist (Altarriba, 2000). Altarriba and
Mathis (1997) questioned the revised hierarchical model of Kroll and Stewart (1994),
which suggests that nonfluent bilinguals rely on lexical association early in SLA and
only later on concept mediation. As mentioned earlier, Altarriba and Mathis tested
Kroll and Stewart's model with monolingual English speakers who were taught Spanish
for the first time. Altarriba and Mathis designed a set of experiments to investigate
the acquisition of the link between conceptual memory and the L2, hypothesizing that
it could develop as early as the first encounter or first learning session with the
new language. Kroll and Stewart had claimed that this link developed over an
unspecified length of time and remained relatively weak. Altarriba and Mathis chose a
translation recognition paradigm aimed at measuring the interference that would be
caused by the presentation of L1-L2 (English-Spanish) pairs that were in some way
similar, but not identical, to the true translations. They theorized that individuals
would be slower to respond (slower response times [RTs]) to English-Spanish pairs
that were either orthographically or semantically similar to the true translations
(i.e., foils) that had been acquired during the learning session of their experiment.
In the translation recognition task, they indeed found that both monolingual and
bilingual participants had slower RTs to the foils. They concluded that orthographic
and semantic information is automatically coded early in the process of SLA. In other
words, the meanings of words in the new language were represented in the learner's
conceptual store as early as the first learning session. Could similar results be
found in a "crossmodal" bilingual environment? Because Altarriba and Mathis's (1997)
SLA hypotheses and conclusions are based on experimental data from oral-aural
languages, assumptions cannot be made as to whether these hypotheses will function in
the acquisition of all L2s, spoken and visual. Therefore, one of the aims of the
present study was to investigate what adults &#xA8; na&#x131;ve to ASL learn when
first exposed to signs and their English meanings. The current study hypothesizes
that hearing, English-speaking adults learning ASL would also encode semantic, as
well as lexical, information early in the learning process. However, as the study's
focus was a visual language as the L2 acquired, hypothesizing about orthographically
similar words between the two languages had to be altered. Instead, the hypothesis
concerned English words that were phonologically similar to the correct translation.
Adult students of ASL should have slower RTs when the English words are
phonologically similar to the correct translations than when the English words are
unrelated to the translations. A semantic condition was also included, as in
Altarriba and Mathis. To test these hypotheses, an experiment was designed that
included learning and testing phases. First, participants viewed a videotape of ASL
signs and heard the signs' English equivalents. After the participants studied the
signs and their translations, we needed to determine if the participants had
"learned" the corresponding English words. Second, the participants were tested on
their "learning." They viewed the same list of signs and heard an English word from
one of the test conditions, paired with each sign. They had to determine whether the
word was or was not the English translation they had learned for the sign. It was
expected that interference in processing would occur for the foils that were
semantically and phonologically similar to the correct translations that the
participants had learned in the study phase of the experiment if the participants had
indeed accurately encoded the visual, phonological, and semantic referents for each
sign.<component x="31.15" y="57.02" width="191.31" height="611.43" page="4"
page_width="495.0" page_height="720.0"></component><component x="240.36" y="396.73"
width="191.3" height="271.69" page="4" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.1" name_ratio="0.22934472934472935" word_count="702"
lateness="0.45454545454545453" reference_score="12.62">Undergraduate introductory
psychology students (n 48, average age 19.8) from the == University at Albany, State
University of New York participated in this experiment for course credit. The
participants had normal or correctedto-normal visual acuity and had no known hearing
limitations. When they were asked before the experiment, the participants said they
had no knowledge of finger spelling or ASL. Additionally, the participants were also
asked about their knowledge of ASL at the conclusion of the experiment. This practice
of asking participants about their language background both before and after an
experiment has been used previously, as it has been found that, on occasion, the act
of performing the experiment brings to mind a forgotten memory of their exposure to
ASL or other languages (see, e.g., Altarriba &amp; Mathis, 1997). The participants
received partial course credit. At the end of the experiment, a brief language
history questionnaire was administered to ensure that they &#xA8; were na&#x131;ve to
ASL. Mean self-ratings on a 10-point scale revealed native fluency in English at 9.3.
Percent of the day English was spoken was 92.3. Questionnaire results revealed no
exposure to, or knowledge of, ASL or any other signed language (see Appendices A and
B). Materials Sign Selection. Twenty-eight signs were selected that abided by the
following four criteria: (a) simple or monomorphemic, (b) frequently used, (c)
visually dissimilar from each another, and (d) not transparent. We relied on two
beginning ASL teaching texts and two ASL dictionaries as the source for simple and
frequently used signs (Humphries, Padden, &amp; O'Rourke, 1980; Smith, Lentz, &amp;
Mikos, 1988; Sternberg, 1994; Stokoe, Casterline, &amp; Croneberg, 1965). We wanted
to select a list of signs that were completely distinct from one another in terms of
all parameters, including movement, shape, and position. In other words, if two signs
varied from each other on a single parameter, we excluded those items from our final
list of signs. This ensured that the signs on the list were visually dissimilar. The
English translations of signs on the list were all concrete nouns. A native deaf
signer was videotaped signing the list. Videotaping a native signer is the ASL
equivalent to having a native English speaker say English words. The signer's mean
signing time per word was 1,260 milliseconds. The English speaker's mean time for
each word was 534 milliseconds. Therefore, it was determined that a 5,000-millsecond
interval between each sign would give participants adequate time to see the sign,
hear the English word, and respond as required. A 5-second interval was also the
preferred elapsed time between signs in recall and recognition tests in other
published works (Bonvillian, Rea, Orlansky, &amp; Slade, 1987; Bower &amp; Karlin,
1974; Cochran, McDonald, &amp; Parault, 1999). There was no sound on the videotape.
Next we needed to be sure the chosen signs were not transparent. Thirty participants
with no knowledge of ASL or experience with finger spelling and from the same pool as
the subsequent experiment were then asked to guess the English translations for the
signs. Two participants correctly guessed two different signs. These signs were
eliminated from the list. This ensured that the remaining signs were not
transparent-that is, their translations were not easily guessed-and, thus, these
signs were used in the ensuing experiment. Creating Semantic Associates. The English
translations for the 28 signs selected were then presented to 30 participants who did
not take part in the earlier norming study or in the subsequent experiment. They were
asked to write down the first word that came to mind next to each of the English
words. All of the words that the participants wrote were tabulated to find the word
most frequently associated with the target word on the list. Only exact wording was
tallied (i.e., not plurals for singular words or derivations of our words on the
list). For example, for "shoe" people wrote "sock" and "socks," which were counted as
two different words. Thus, the most frequently reported word for each target word was
used as the semantic associate for these items. As the participants were from the
same pool as those who would perform the subsequent experiment, these association
norms would presumably reflect the knowledge of the participants in the experiment
proper.<component x="240.36" y="56.85" width="191.31" height="271.69" page="4"
page_width="495.0" page_height="720.0"></component><component x="62.89" y="648.81"
width="191.29" height="19.63" page="5" page_width="495.0"
page_height="720.0"></component><component x="62.89" y="56.87" width="191.3"
height="567.45" page="5" page_width="495.0"
page_height="720.0"></component><component x="272.11" y="484.41" width="191.3"
height="184.02" page="5" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.08" name_ratio="0.208955223880597" word_count="134"
lateness="0.45454545454545453" reference_score="12.46">The experiment required words
in four test conditions: (a) the target words (i.e., the English words the
participant learned for the videotaped signs); (b) words unrelated to the target
words; (c) words semantically related to the target words; and (d) words
phonologically related to the target words. The unrelated items were made up of words
of approximately the same length and fre&#x2D8; quency as the signs' English
equivalents (Kucera &amp; Francis, 1967). Mean word length and mean word frequency
for the words in all four conditions are listed in Table 1. t -Tests indicated no
significant differences across conditions for either &gt; frequency or length (all ps
.05). The phonologically related condition was constructed of rhyming words
(Fergusson, 1985; Webster's, 1987). Sample stimulus items include the following:
Targets: apple, cookie; Unrelated: thigh, paddle; Semantic<component x="272.11"
y="244.08" width="191.3" height="194.98" page="5" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.19" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.17"
year_ratio="0.0" cap_ratio="0.93" name_ratio="0.21428571428571427" word_count="14"
lateness="0.45454545454545453" reference_score="13.1">TABLE 1 Word Length and
Frequency Means and Standard Deviation for Four Test Conditions<component x="272.11"
y="189.29" width="184.26" height="28.11" page="5" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.2" name_ratio="0.2559055118110236" word_count="508"
lateness="0.5454545454545454" reference_score="14.8">Foil: pie, sweet; Phonological
Foil: chapel, rookie. Thus, the words that corresponded to the target "apple" in each
condition included "thigh," "pie," and "chapel." The set can be derived for "cookie"
in the same way from the examples provided earlier (see Appendix C for a complete
listing of items). The videotape of the 28 common ASL signs created previously was
used in the current experiment. Four signs and four English words, each from a
different test condition, were isolated for use during the practice phase. The
remaining 24 English words for each condition (i.e., the English translations for the
sign, the unrelated words, the semantically related words, and the phonologically
related words) were counterbalanced across four experimental lists such that 6 words
from each condition appeared only in one list. Each list had a different set of six
words from each of the four conditions. To familiarize participants with the test
procedure, the four practice signs and words were shown and heard at the start of
each test phase. Everyone received the same practice items. The videotape of the 28
signs was then reordered into four randomly selected orders using Media 100's digital
nonlinear editing system. With the GoldWave audio program, the 96 test English words,
24 words in four conditions, plus 8 words used for practice were entered into the
computer. The words were cued so that they would be heard after the sign began but
before the sign ended. To standardize how the signs were presented to the
participant, Liddell's (1984) description of sign phonology was employed. In his
description, a sign can begin with either a MOVEMENT (M) or a HOLD (H) at a
stationary location. Signs can also end with either an M or an H. For example, the
sign for FATHER is HMH. In the sign for FATHER, the first movement to the forehead is
not relevant to sign formation. In the sign, the first and last contacts of the thumb
on the forehead are HOLDS, with the intervening MOVEMENT. (Note that another sign
form for FATHER is the thumb contact HOLD on the forehead without MOVEMENT but with
other fingers wiggling.) While seeing FATHER on videotape, the participant heard the
English word "father" after the initial H but before the M. The participant heard the
English word as the signer's palm began traveling toward her face. The English word
was completed before the signer's thumb came to rest on her forehead. Hearing the
English translation at the same moment in each sign's articulation was crucial for
accurately recording RT. Therefore, the words were cued to be heard just after the
initial M or H, as the signer was transitioning to the following H or M of the sign.
A program developed using SuperLab Pro software was used to record elapsed time
between the onset of the English word and the participant's response. The signs for
the experiment were presented on a video monitor, and the words were heard over
speakers on either side of the monitor and linked to a laptop computer.<component
x="31.15" y="57.02" width="191.3" height="611.43" page="6" page_width="495.0"
page_height="720.0"></component><component x="240.36" y="572.09" width="191.3"
height="96.34" page="6" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.04"
year_ratio="0.0" cap_ratio="0.03" name_ratio="0.27304347826086955" word_count="575"
lateness="0.6363636363636364" reference_score="12.55">All participants were assigned
a random number and were tested individually. The first phase of the experiment in
which the participants studied the signs and their English translations was the
acquisition phase. Participants were seated in front of the video monitor to watch 28
signs one by one and hear their English translations. They were asked to try their
best to learn the English translations for the 28 ASL signs. Within the same 5-second
interval for each sign, the participants heard the sign's English translation twice.
The videotape was repeated twice in the same order, so the participants saw the signs
twice and heard the English translations four times. Then the participants were asked
to check what they had learned by viewing the same 28 signs, without translations, in
a different order and saying aloud the English word they remembered for the sign. At
the end of the viewing without the audio, we read aloud the errors and omissions the
participants had made in naming the English translations and provided the accurate
sign and spoken translation for items the participants had missed. Then the
participants viewed the list of 28 signs again but in a different order. The English
words and their corresponding signs were repeated once again. This study test process
was repeated in full, until the participants reached 100% accuracy. When the
participants named the translations for the signs 100% correctly, they went on to the
testing phase of the experiment. To limit the duration of the experiment,
participants were excused from the experiment if they did not reach 100% accuracy
after half an hour of study. On this basis, 3 individuals were excluded from
finishing the experiment and 3 new participants were added to maintain the group
number at 48. Following the acquisition phase, the participants were given a 3-minute
intervening task, which included counting backward by 4s from 534. This task diverted
the participants from thinking about the acquisition phase and actively engaging in
rehearsal. The 3 minutes also allowed us to set up the computer for the test phase.
The second phase of the experiment, in which the participants decided if the word
they heard was the translation they had learned for the sign, was the testing phase.
On the monitor, the participants saw each of the 28 signs again in yet a different
order paired with hearing an English word. (Four of those signs formed the practice
trials that were then followed by the remaining 24 signs divided equally among the
following four conditions: correct target, semantically related, phonologically
related, and unrelated.) Each participant viewed a single experimental list in random
order. The participants were told to press a designated "yes" or "no" key on the
laptop keypad indicating whether the word they heard was or was not the word they had
learned for the sign on the video monitor. They were to make their decisions as
quickly and as accurately as possible. The participants were given 1,500 milliseconds
to respond. At the beginning of the test phase, four signs each with an English word
were presented as practice trials to familiarize the participants with the test
procedure. Then the actual test proceeded. As mentioned earlier, at the end of the
experiment, the participants were asked four questions about sign recognition (see
Appendix B) and answered a brief language history questionnaire. None of the
participants was found to have had prior experience with ASL or any other signed
language.<component x="240.36" y="56.85" width="191.33" height="479.92" page="6"
page_width="495.0" page_height="720.0"></component><component x="62.89" y="330.99"
width="191.3" height="337.45" page="7" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.1"
year_ratio="0.0" cap_ratio="0.18" name_ratio="0.23170731707317074" word_count="164"
lateness="0.6363636363636364" reference_score="15.26">For each participant, mean
response times and standard deviations (SDs) were computed for the four conditions
(true target, semantic, phonological, and unrelated). After computing SDs for each
participant's RT in each condition, we found no RTs, or outliers, that exceeded 2.5
SDs above or below the mean for each condition. All participants' RTs were included
in our analysis. Mean RTs, SDs, and error rates for the four test conditions (correct
translation, unrelated, semantic, and phonological) for all participants are listed
in Table 2. Only data for correct responses were included. An analysis of variance
(ANOVA) indicated that the four conditions differed significantly from one another,
with F (3,45) 27.708, = &lt; MS 8.620, p .001. Planned comparisons (Bon= ferroni
corrections were applied) showed that RTs for the semantic and the phonological
conditions &gt; were virtually the same, with t (47) 0.220, p = &#x2212; .05.
However, the RTs for the semantic and phonological conditions compared to the
unrelated condition were significantly slower, indicated by<component x="62.89"
y="56.87" width="191.3" height="238.82" page="7" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.19" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.22"
year_ratio="0.0" cap_ratio="0.84" name_ratio="0.10526315789473684" word_count="19"
lateness="0.6363636363636364" reference_score="16.08">TABLE 2 Mean Response Times
(Milliseconds), Standard Deviations, and Error Rates (Percentages) for All Test
Conditions (n 48) =<component x="272.11" y="625.1" width="180.54" height="43.84"
page="7" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.09"
year_ratio="0.0" cap_ratio="0.07" name_ratio="0.20175438596491227" word_count="342"
lateness="0.7272727272727273" reference_score="14.44">&lt; t (47) 2.363, p .05
(Cohen's d 0.48) and = = &lt; t (47) 2.753, p .01 (Cohen's d 0.56), = = respectively.
Semantically related foils produced an interference effect suggesting that novices in
ASL had formed a conceptual link to the ASL signs. Phonologically related foils
produced a slightly larger interference effect, indicating that the participants had
learned to associate the newly acquired signs and their phonological representations
in English. Error data were examined to see if the higher rate of errors in the
phonological condition was significantly different from other conditions (see Table
2). An ANOVA indicated that there was a significant difference in error rates across
the four conditions, with F (3,45) 27.708, MS 4.852; = = &lt; p .001. Planned
comparisons (Bonferroni corrections were applied) revealed that the error rate for
the target condition differed significantly from the phonological condition, with t
(47) 5.698, = &#x2212; &lt; p .001 (Cohen's d 1.16). In addition, the error = rate
for the unrelated condition was significantly different from the phonological
condition, with &lt; t (47) 6.132, p . 0001 (Cohen's d 1.77). = &#x2212; = Finally,
the error rate for the semantic condition was also significantly different from the
phono&lt; logical condition, with t (47) 5.695, p .001 = &#x2212; (Cohen's d 1.16).
Appendix D includes a list= ing of individual items and their corresponding error
rates. Note that although only one item in the semantic category produced a
significant error rate (i.e., "kids"), several items contributed to the large error
rate in the phonological condition. In this later condition, most prominent were the
items "fair," "bother," and "fig," corresponding to "bear," "father," and "pig,"
respectively. Clearly, these kinds of errors of substitution stem from the similarity
across items in terms of initial phonemes; thus, as in most situations, whenever
manner/place of articulation overlaps across lexical items, errors of recognition and
identification are more likely to occur. More will be said later in terms of the
implications of these kinds of errors for lexical representation and processing in
general.<component x="272.11" y="56.87" width="191.31" height="469.89" page="7"
page_width="495.0" page_height="720.0"></component><component x="31.15" y="648.81"
width="191.29" height="19.63" page="8" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.67" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.05"
year_ratio="0.0" cap_ratio="0.09" name_ratio="0.25285171102661597" word_count="1578"
lateness="0.8181818181818182" reference_score="15.19">The experiments described here
were designed to follow the approach of Altarriba and Mathis's (1997) experiments in
SLA. When Altarriba and Mathis tested English-speaking monolinguals who had just
acquired a set of words in an L2 (Spanish), they found that these participants had
encoded both semantic and orthographic aspects of the new words and were able to
access this new information when responding to a translation recognition task.
Because an interference effect occurred for both conditions, it appeared that
monolinguals formed a direct link with lexical and conceptual levels of
representation when first learning an L2. In the current study, the results of the
experiment on acquiring the ASL signs confirmed that L2 (ASL) conceptual processing
(as well as phonological processing of the English translation equivalents) is
involved very early in the language acquisition process. Both semantic and
phonological interference effects were reported within the current study. It can be
assumed, then, that the processes involved in acquiring an L2 as described by
Altarriba and Mathis also come into play for adult novices learning a visual language
as the L2. Moreover, as reported by Altarriba and Mathis, the current work also
indicates that the revised hierarchical model proposed by Kroll and Stewart (1994)
should be modified to indicate that conceptual/semantic information can be acquired
in the earliest stages of L2 learning. In other words, even after a single learning
session, individuals can acquire the knowledge of the meaning of newly learned L2
words-a link that had been purported to take more time to develop, as per the revised
hierarchical model. In relation to the above issues of acquisition and development,
note that all of the participants in the current study had been exposed to an L2 at
some point in their lives (either from birth or through schooling in later years; see
Appendix A). Thus, it appears that for the current participants, the acquisition of
concepts via sign constituted a kind of "third-language" exposure, although it was
not a verbal language, as were their L1s and L2s. Given the briefness of the
questionnaire that was used, it is difficult to assess the degree to which the
present participants were fluent in their L2 compared to their L1. Thus, although all
participants had been exposed to an L2 at some point in their lives, their relative
fluency in that language is likely to have varied considerably and is not currently
known. Future investigations of the acquisition of ASL signs should examine the
extent to which individuals who are exposed to an L2 and who consider themselves
truly "bilingual" or "fluent/proficient" in their L2 show different patterns of
translation recognition for newly acquired signs. Mode or context of learning and
acquisition should also be taken into account in further investigations. Thus,
participants' bilingualism may be examined as a variable of interest in future
studies of sign acquisition, as this question was not a focus of the current
investigation. The present study provided evidence that conceptual and phonological
interference occurs in learning the meanings of ASL signs-a finding similar to that
reported for the acquisition of words of a second, spoken language (see, e.g.,
Altarriba &amp; Mathis, 1997; van Hell &amp; Mahn, 1997). Previous ASL research
evidence points to the parallel functioning of visual-spatial and oral-aural
languages. For example, signs that look different from one another are identified
more quickly than those that look similar to one another. This mimics the
phonological similarity effect that occurs in spoken languages (see also Emmorey,
2002). In addition, Liddell (1984) illustrated how signs have beginnings, middles,
and ends similar to the segments of spoken words, onsets, medial phases, and offsets.
An interesting finding in the current set of results is that the error rates were
significantly higher in the phonological condition, as compared to other conditions
within the experiment; that is, many more confusion errors occurred when foils were
phonologically similar to the true translation. Given that the test pairs in the
current case were comprised of a spoken word and a word that was signed, the
implication is that the participants accessed the phonological representations of the
signed words to the extent that those representations interfered with their ability
to reject the incorrect pairing. Theoretically, these data suggest that individuals
accessed phonology when not specifically directed to do so in the context of the
current study. Phonology was encoded in an implicit manner, as part of the learning
of signs, overall. Thus, as current models of bilingual representation have suggested
(see, e.g., BIA and BIA in Dijkstra &amp; van Heuven, 1998), phonol+ ogy is often
retrieved in the process of understanding newly acquired concepts in an L2-even if it
is a signed language. Further, the current data underscore the basic finding in the
literature that many auditory confusion errors are derived from words that have
phonological overlap and share either place of articulation or manner of
articulation, or both. The fact that these phonological representations in the
current study stem from the recognition of a signed word is interesting evidence to
suggest that phonological confusion errors are not modality-specific (see also Engle,
Cantor, &amp; Turner, 1989, for a related discussion). Although the current study
examined translation recognition for newly acquired signs and their English
translations, the participants performed a learning task that by its very nature
emphasized the phonological and semantic aspects of the association between the
English word and its corresponding sign. Although the participants developed these
new representations such that they achieved 100% accuracy on a test of their
knowledge, it is unclear to what extent different participants might have engaged in
their own strategies in learning the signs of interest. Clearly, the possibility that
the participants engaged in their own mnemonic strategies to shape their mental
representations for the signs and their English counterparts may have affected the
way in which this knowledge was learned and encoded for each participant. Future
examinations of the acquisition of signs should vary instructions so as to either
document the means by which participants actively learn signs or provide concrete
instructions as to the types of strategies that should be used (e.g., imagery,
context availability) so as to investigate the influence of learning strat1 egy on
the ultimate representation of new signs. Moreover, it is important to note here that
although the current work focused on the learning of ASL signs, the learning of
language, in general, encompasses many more elements that bring together aspects of
reasoning, pragmatic usage, contextual influences, and the like (see, e.g.,
Larsen-Freeman, 2003; van Lier, 2004). Thus, language development is a highly dynamic
process, and future work may focus on the acquisition of ASL signs in broader
contexts of language, incorporating a more ecological approach to acquisition. In a
related vein, neurological investigations into the hemispheric involvement of
imageable concrete signs in ASL, as distinct fromabstract lexical forms, continue to
raise questions about the different roles imagery may play in ASL and English
(Emmorey &amp; Corina, 1993). Most recently, neurobiological evidence also indicates
that both signed and spoken languages are generally localized in the same area in the
left hemisphere (Corina, Vaid, &amp; Bellugi, 1992; Damasio &amp; Damasio, 2000;
Emmorey et al., 2003; Horwitz et al., 2003). Notwithstanding the linguistic and
neurobiological parallels between ASL and the spoken languages of the world, we
recognize that the visual modality makes a distinct difference in L2 learning. The
current study kept the learning challenge of ASL to a bare minimum (i.e., acquiring
the English words for 28 simple signs). Nothing about sign perception was
investigated. Clearly, &#xA8; the greater part of understanding how sign-na&#x131;ve
adults learn ASL has to include working memory experiments on what the adult learner
processes (i.e., sees, stores, attends to, recalls, etc.) in the visual modality
(see, e.g., Wilson &amp; Emmorey, 2003). Experiments on reproducing ASL signs are
recommended, as well as experiments with ASL units longer than primarily single
monomorphemic signs. When we analyzed the ways the participants remembered the
English meanings during the study phase of the present experiment, another potential
area of research became clear. Although the participants studied the English meanings
for the signs in the learning part of the experiment, we informally noted evident
mnemonics used by two participants, each for a single word. For example, one
participant said "father-head" while hearing the word "father" and viewing FATHER, in
which the thumb of the open hand shape touches the forehead. Another participant
during the study said "funny-nose" when seeing CLOWN, which is made by cupping the
nose with one hand. Future experiments on systematically including mnemonics in the
study phase might offer insight into another method for teaching ASL as an L2. The
concept mediation model, explained in Altarriba and Mathis's (1997) experiments and
in the current study, supports the practice of teaching SLA using contextual units
that emphasize the semantic or conceptual representation of a newly acquired word.
Many beginning ASL texts already emphasize contextual learning (see, e.g., Smith et
al., 1988). Thus, assuming that the acquisition of words in aural and visual
languages is similar, researchers can focus on how the visual modality is mentally
represented by hearing adults learning a signed language. What is most important to
keep in mind is that bilingual research should include oral-aural as well as
visual-spatial languages, and as the experiment in this study shows, the concept
mediation hypothesis (as well as the modifications of the revised hierarchical model
as posed by Altarriba and Mathis) applies to signed as well as to spoken
language.<component x="31.15" y="56.87" width="191.3" height="556.63" page="8"
page_width="495.0" page_height="720.0"></component><component x="240.36" y="57.0"
width="191.31" height="611.43" page="8" page_width="495.0"
page_height="720.0"></component><component x="62.89" y="57.03" width="191.3"
height="611.42" page="9" page_width="495.0"
page_height="720.0"></component><component x="272.11" y="57.01" width="191.3"
height="611.43" page="9" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="7.71" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.07"
year_ratio="0.0" cap_ratio="0.26" name_ratio="0.4158415841584158" word_count="101"
lateness="0.9090909090909091" reference_score="17.03">This research was completed as
part of the requirements for the Doctor of Philosophy degree awarded to the first
author. We would like to thank Lauren Cowell for assistance with data collection,
Erik L. Olheiser and Matthew Pastizzo for their help with programming and analysis,
and Christine Pryzbylo for her role in the development of research materials, as a
native ASL signer. We would also like to extend our gratitude to Rhoda Linton, Nancy
Mardas, Elizabeth Minnich, Randall Myers, and Janet Pray for their comments on an
earlier version of this work, as members of the first author's Doctoral Dissertation
Committee.<component x="31.15" y="514.59" width="191.3" height="117.3" page="10"
page_width="495.0" page_height="720.0"></component></section>
  <section line_height="7.71" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.03"
year_ratio="0.0" cap_ratio="0.05" name_ratio="0.2857142857142857" word_count="21"
lateness="0.9090909090909091" reference_score="14.43">1 We thank an anonymous
reviewer for pointing out this issue to us in an earlier draft of the current
article.<component x="31.15" y="446.53" width="191.29" height="19.18" page="10"
page_width="495.0" page_height="720.0"></component></section>
  <section line_height="7.71" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.22"
year_ratio="0.05" cap_ratio="0.27" name_ratio="0.15765765765765766" word_count="222"
lateness="0.9090909090909091" reference_score="28.64">Altarriba, J. (1990).
Constraints on interlingual facilitation effects in priming in Spanish-English
bilinguals. Unpublished doctoral dissertation, Vanderbilt University, Nashville, TN.
Altarriba, J. (1992). The representation of translation equivalents in bilingual
memory. In R. J. Harris (Ed.), Cognitive processing in bilinguals (pp. 157- 174).
Amsterdam: Elsevier Science. Altarriba, J. (2000). Language processing and memory
retrieval in Spanish-English bilinguals. Spanish Applied Linguistics, 4, 215-245.
Altarriba, J., &amp; Mathis, M. (1997). Conceptual and lexical development in second
language acquisition. Journal of Memory and Language , 36 , 550- 568. Bonvillian, J.
D., Rea, A. C., Orlansky, M. D., &amp; Slade, L. A. (1987). The effect of sign
language rehearsal on deaf subjects' immediate and delayed recall of English word
lists. Applied Psycholinguistics, 8, 33- 54. Bower, G. H., &amp; Karlin, M. B.
(1974). Depth of processing pictures of faces and recognition memory. Journal of
Experimental Psychology, 4, 751- 757. Cochran, B. P., McDonald, J. L., &amp; Parault,
S. J. (1999). Too smart for their own good: The disadvantage of a superior processing
capacity for adult language learners. Journal of Memory and Language , 41, 30- 58.
Corina, D. P., Vaid, J., &amp; Bellugi, U. (1992). The linguistic basis of left
hemisphere specialization. Science , 255, 1258-1260. Damasio, A. R., &amp; Damasio,
H.(2000). Language and the brain. In K. Emmorey &amp; H. Lane (Eds.), The
signs<component x="31.15" y="61.15" width="191.3" height="336.47" page="10"
page_width="495.0" page_height="720.0"></component></section>
  <section line_height="7.58" font="MGIIFA+NewBaskerville-Italic" letter_ratio="0.23"
year_ratio="0.04" cap_ratio="0.41" name_ratio="0.1457286432160804" word_count="398"
lateness="0.9090909090909091" reference_score="30.1">of language revisited: An
anthology to honor Ursula Bellugi and Edward Klima (pp. 477-491). Mahwah, NJ:
Erlbaum. Dijkstra, T., &amp; van Heuven, W. J. B. (1998). The BIA model and bilingual
word recognition. In J. Grainger &amp; A. Jacobs (Eds.), Localist connectionist
approaches to human cognition (pp. 189-225). Hove, England: Erlbaum. Emmorey, K.
(2002). Language, cognition, and the brain. Mahwah, NJ: Erlbaum. Emmorey, K., &amp;
Corina, D. (1993). Hemispheric specialization for ASL signs and English words:
Differences between imageable and abstract forms. Neuropsychologia, 31, 645-653.
Emmorey, K., Grabowski, T., McCullough, S., Damasio, H., Ponto, L., Hichwa, R., et
al. (2003). Neural systems underlying lexical retrieval for sign language.
Neuropsychologia, 41, 85-95. Engle, R. W.,Cantor, J., &amp; Turner, M.L. (1989).
Modality effects: Do they fall on deaf ears? Quarterly Journal of Experimental
Psychology A: Human Experimental Psychology, 41, 273-292. Fergusson, R. (1985). The
Penguin rhyming dictionary. London: Penguin Books. Gollan, T. H., Forster, K. I.,
&amp; Frost, R. (1997). Translation priming with different scripts: Masked priming
with cognates and noncognates in Hebrew- English bilinguals. Journal of Experimental
Psychology: Learning, Memory and Cognition, 23, 1122- 1139. Horwitz, B., Amunts, K.,
Bhattacharyya, R., Patkin, D., Jeffries, K., Zilles, K., et al. (2003). Activation of
Broca's area during the production of spoken and signed language: A combined
cytoarchitectonic mapping and PET analysis. Neuropsychologia, 41, 1868-1876.
Humphries, T., Padden, C., &amp; O'Rourke, T. J. (1980). A basic course in American
Sign Language . Silver Spring, MD: T. J. Publishers. Kroll, J. F., &amp; Stewart, E.
(1994). Category interference in translation and picture naming: Evidence for
asymmetric connections between bilingual memory representations. Journal of Memory
and Language , 33, 149-173. &#x2D8; Kucera, H., &amp; Francis, N. W. (1967).
Computational analysis of present-day American English. Providence, RI: Brown
University Press. Larsen-Freeman, D. (2003). Teaching language: From grammar to
grammaring . Boston: Thomson-Heinle. Liddell, S. (1984). Think and believe:
Sequentiality in American Sign Language. Language , 60, 372-398. Potter, M. C., So,
K. -F., von Eckardt, B., &amp; Feldman, L. B. (1984). Lexical and conceptual
representation in beginning and proficient bilinguals. Journal of Verbal Learning and
Verbal Behavior , 23, 23-38. Rosen, R. S. (2008). American Sign Language as a foreign
language in U.S. high schools: State of the art. Modern Language Journal , 92, 10-38.
Smith, C., Lentz, E. M., &amp; Mikos, K. (1988). Signing naturally: Student workbook
level 1. San Diego, CA: DawnSign Press.<component x="240.36" y="62.29" width="191.3"
height="605.34" page="10" page_width="495.0"
page_height="720.0"></component></section>
  <section line_height="8.19" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.09"
year_ratio="0.0" cap_ratio="0.31" name_ratio="0.13636363636363635" word_count="88"
lateness="1.0" reference_score="18.98">Mean age in years Mean self-rating (10-point
scale: 1 very little; 10 native-like) on overall English fluency = = Percentage of
day English was typically spoken Percentage of participants who had been exposed to
an L2 other than English from birth (countries of origin included Dominican Republic,
India, Iran, Pakistan, and Puerto Rico) Percentage of participants who had been
exposed to an L2 other than English later in life, primarily at school (languages
included Spanish, Arabic, Hindi, and Farsi but NOT American Sign Language or another
signed language)<component x="62.89" y="199.77" width="346.71" height="77.93"
page="11" page_width="495.0" page_height="720.0"></component></section>
  <section line_height="8.19" font="MGIIDO+NewBaskerville-Roman" letter_ratio="0.81"
year_ratio="0.0" cap_ratio="0.0" name_ratio="0" word_count="4" lateness="1.0"
reference_score="10.01">19.8 9.3 92.3 23<component x="447.36" y="239.62"
width="15.73" height="38.08" page="11" page_width="495.0"
page_height="720.0"></component></section>
  <reference>Altarriba, J. (1990). Constraints on interlingual facilitation effects
in priming in Spanish-English bilinguals. Un- published doctoral dissertation,
Vanderbilt Uni- versity, Nashville, TN.</reference>
  <reference>Altarriba, J. (1992). The representation of translation equivalents in
bilingual memory. In R. J. Harris (Ed.), Cognitive processing in bilinguals (pp. 157-
174). Amsterdam: Elsevier Science.</reference>
  <reference>Altarriba, J. (2000). Language processing and mem- ory retrieval in
Spanish-English bilinguals. Span- ish Applied Linguistics, 4, 215-245.</reference>
  <reference>Altarriba, J., &amp; Mathis, M. (1997). Conceptual and lexical
development in second language acquisi- tion. Journal of Memory and Language , 36 ,
550- 568.</reference>
  <reference>Bonvillian, J. D., Rea, A. C., Orlansky, M. D., &amp; Slade, L. A.
(1987). The effect of sign language rehearsal on deaf subjects' immediate and delayed
recall of English word lists. Applied Psycholinguistics, 8, 33- 54.</reference>
  <reference>Bower, G. H., &amp; Karlin, M. B. (1974). Depth of pro- cessing pictures
of faces and recognition mem- ory. Journal of Experimental Psychology, 4, 751-
757.</reference>
  <reference>Cochran, B. P., McDonald, J. L., &amp; Parault, S. J. (1999). Too smart
for their own good: The disadvantage of a superior processing capacity for adult
language learners. Journal of Memory and Language , 41, 30- 58.</reference>
  <reference>Corina, D. P., Vaid, J., &amp; Bellugi, U. (1992). The linguis- tic
basis of left hemisphere specialization. Science , 255, 1258-1260.</reference>
  <reference>Damasio, A. R., &amp; Damasio, H.(2000). Language and the brain. In K.
Emmorey &amp; H. Lane (Eds.), The signs</reference>
  <reference>Dijkstra, T., &amp; van Heuven, W. J. B. (1998). The BIA model and
bilingual word recognition. In J. Grainger &amp; A. Jacobs (Eds.), Localist
connection- ist approaches to human cognition (pp. 189-225). Hove, England:
Erlbaum.</reference>
  <reference>Emmorey, K. (2002). Language, cognition, and the brain. Mahwah, NJ:
Erlbaum.</reference>
  <reference>Emmorey, K., &amp; Corina, D. (1993). Hemispheric spe- cialization for
ASL signs and English words: Dif- ferences between imageable and abstract forms.
Neuropsychologia, 31, 645-653.</reference>
  <reference>Emmorey, K., Grabowski, T., McCullough, S., Damasio, H., Ponto, L.,
Hichwa, R., et al. (2003). Neural sys- tems underlying lexical retrieval for sign
language. Neuropsychologia, 41, 85-95.</reference>
  <reference>Engle, R. W.,Cantor, J., &amp; Turner, M.L. (1989). Modality effects: Do
they fall on deaf ears? Quarterly Journal of Experimental Psychology A: Human
Experimental Psychology, 41, 273-292.</reference>
  <reference>Fergusson, R. (1985). The Penguin rhyming dictionary. London: Penguin
Books.</reference>
  <reference>Gollan, T. H., Forster, K. I., &amp; Frost, R. (1997). Transla- tion
priming with different scripts: Masked prim- ing with cognates and noncognates in
Hebrew- English bilinguals. Journal of Experimental Psychol- ogy: Learning, Memory
and Cognition, 23, 1122- 1139.</reference>
  <reference>Horwitz, B., Amunts, K., Bhattacharyya, R., Patkin, D., Jeffries, K.,
Zilles, K., et al. (2003). Activation of Broca's area during the production of spoken
and signed language: A combined cytoarchitectonic mapping and PET analysis.
Neuropsychologia, 41, 1868-1876.</reference>
  <reference>Humphries, T., Padden, C., &amp; O'Rourke, T. J. (1980). A basic course
in American Sign Language . Silver Spring, MD: T. J. Publishers.</reference>
  <reference>Kroll, J. F., &amp; Stewart, E. (1994). Category interference in
translation and picture naming: Evidence for asymmetric connections between bilingual
mem- ory representations. Journal of Memory and Lan- guage , 33, 149-173.
&#x2D8;</reference>
  <reference>Kucera, H., &amp; Francis, N. W. (1967). Computational anal- ysis of
present-day American English. Providence, RI: Brown University Press.</reference>
  <reference>Larsen-Freeman, D. (2003). Teaching language: From grammar to grammaring
. Boston: Thomson-Heinle.</reference>
  <reference>Liddell, S. (1984). Think and believe: Sequentiality in American Sign
Language. Language , 60, 372-398.</reference>
  <reference>Potter, M. C., So, K. -F., von Eckardt, B., &amp; Feldman, L. B. (1984).
Lexical and conceptual representation in beginning and proficient bilinguals. Journal
of Verbal Learning and Verbal Behavior , 23, 23-38.</reference>
  <reference>Rosen, R. S. (2008). American Sign Language as a for- eign language in
U.S. high schools: State of the art. Modern Language Journal , 92, 10-38.</reference>
  <reference>Smith, C., Lentz, E. M., &amp; Mikos, K. (1988). Signing naturally:
Student workbook level 1. San Diego, CA: DawnSign Press.</reference>
  <reference>Altarriba, J. (1990). Constraints on interlingual facilitation effects
in priming in Spanish-English bilinguals. Un- published doctoral dissertation,
Vanderbilt Uni- versity, Nashville, TN.</reference>
  <reference>Altarriba, J. (1992). The representation of translation equivalents in
bilingual memory. In R. J. Harris (Ed.), Cognitive processing in bilinguals (pp. 157-
174). Amsterdam: Elsevier Science.</reference>
  <reference>Altarriba, J. (2000). Language processing and mem- ory retrieval in
Spanish-English bilinguals. Span- ish Applied Linguistics, 4, 215-245.</reference>
  <reference>Altarriba, J., &amp; Mathis, M. (1997). Conceptual and lexical
development in second language acquisi- tion. Journal of Memory and Language , 36 ,
550- 568.</reference>
  <reference>Bonvillian, J. D., Rea, A. C., Orlansky, M. D., &amp; Slade, L. A.
(1987). The effect of sign language rehearsal on deaf subjects' immediate and delayed
recall of English word lists. Applied Psycholinguistics, 8, 33- 54.</reference>
  <reference>Bower, G. H., &amp; Karlin, M. B. (1974). Depth of pro- cessing pictures
of faces and recognition mem- ory. Journal of Experimental Psychology, 4, 751-
757.</reference>
  <reference>Cochran, B. P., McDonald, J. L., &amp; Parault, S. J. (1999). Too smart
for their own good: The disadvantage of a superior processing capacity for adult
language learners. Journal of Memory and Language , 41, 30- 58.</reference>
  <reference>Corina, D. P., Vaid, J., &amp; Bellugi, U. (1992). The linguis- tic
basis of left hemisphere specialization. Science , 255, 1258-1260.</reference>
  <reference>Damasio, A. R., &amp; Damasio, H.(2000). Language and the brain. In K.
Emmorey &amp; H. Lane (Eds.), The signs</reference>
  <reference>Dijkstra, T., &amp; van Heuven, W. J. B. (1998). The BIA model and
bilingual word recognition. In J. Grainger &amp; A. Jacobs (Eds.), Localist
connection- ist approaches to human cognition (pp. 189-225). Hove, England:
Erlbaum.</reference>
  <reference>Emmorey, K. (2002). Language, cognition, and the brain. Mahwah, NJ:
Erlbaum.</reference>
  <reference>Emmorey, K., &amp; Corina, D. (1993). Hemispheric spe- cialization for
ASL signs and English words: Dif- ferences between imageable and abstract forms.
Neuropsychologia, 31, 645-653.</reference>
  <reference>Emmorey, K., Grabowski, T., McCullough, S., Damasio, H., Ponto, L.,
Hichwa, R., et al. (2003). Neural sys- tems underlying lexical retrieval for sign
language. Neuropsychologia, 41, 85-95.</reference>
  <reference>Engle, R. W.,Cantor, J., &amp; Turner, M.L. (1989). Modality effects: Do
they fall on deaf ears? Quarterly Journal of Experimental Psychology A: Human
Experimental Psychology, 41, 273-292.</reference>
  <reference>Fergusson, R. (1985). The Penguin rhyming dictionary. London: Penguin
Books.</reference>
  <reference>Gollan, T. H., Forster, K. I., &amp; Frost, R. (1997). Transla- tion
priming with different scripts: Masked prim- ing with cognates and noncognates in
Hebrew- English bilinguals. Journal of Experimental Psychol- ogy: Learning, Memory
and Cognition, 23, 1122- 1139.</reference>
  <reference>Horwitz, B., Amunts, K., Bhattacharyya, R., Patkin, D., Jeffries, K.,
Zilles, K., et al. (2003). Activation of Broca's area during the production of spoken
and signed language: A combined cytoarchitectonic mapping and PET analysis.
Neuropsychologia, 41, 1868-1876.</reference>
  <reference>Humphries, T., Padden, C., &amp; O'Rourke, T. J. (1980). A basic course
in American Sign Language . Silver Spring, MD: T. J. Publishers.</reference>
  <reference>Kroll, J. F., &amp; Stewart, E. (1994). Category interference in
translation and picture naming: Evidence for asymmetric connections between bilingual
mem- ory representations. Journal of Memory and Lan- guage , 33, 149-173.
&#x2D8;</reference>
  <reference>Kucera, H., &amp; Francis, N. W. (1967). Computational anal- ysis of
present-day American English. Providence, RI: Brown University Press.</reference>
  <reference>Larsen-Freeman, D. (2003). Teaching language: From grammar to grammaring
. Boston: Thomson-Heinle.</reference>
  <reference>Liddell, S. (1984). Think and believe: Sequentiality in American Sign
Language. Language , 60, 372-398.</reference>
  <reference>Potter, M. C., So, K. -F., von Eckardt, B., &amp; Feldman, L. B. (1984).
Lexical and conceptual representation in beginning and proficient bilinguals. Journal
of Verbal Learning and Verbal Behavior , 23, 23-38.</reference>
  <reference>Rosen, R. S. (2008). American Sign Language as a for- eign language in
U.S. high schools: State of the art. Modern Language Journal , 92, 10-38.</reference>
  <reference>Smith, C., Lentz, E. M., &amp; Mikos, K. (1988). Signing naturally:
Student workbook level 1. San Diego, CA: DawnSign Press.</reference>
  <resolved_reference>Altarriba, J. (1990). Constraints on interlingual facilitation
effects in priming in Spanish-English bilinguals. Un- published doctoral
dissertation, Vanderbilt Uni- versity, Nashville, TN.</resolved_reference>
  <resolved_reference>Altarriba, J. (1992). The representation of translation
equivalents in bilingual memory. In R. J. Harris (Ed.), Cognitive processing in
bilinguals (pp. 157- 174). Amsterdam: Elsevier Science.</resolved_reference>
  <resolved_reference>Altarriba, J. (2000). Language processing and mem- ory
retrieval in Spanish-English bilinguals. Span- ish Applied Linguistics, 4,
215-245.</resolved_reference>
  <resolved_reference>Altarriba, J., &amp; Mathis, M. (1997). Conceptual and lexical
development in second language acquisi- tion. Journal of Memory and Language , 36 ,
550- 568.</resolved_reference>
  <resolved_reference>Bonvillian, J. D., Rea, A. C., Orlansky, M. D., &amp; Slade, L.
A. (1987). The effect of sign language rehearsal on deaf subjects' immediate and
delayed recall of English word lists. Applied Psycholinguistics, 8, 33-
54.</resolved_reference>
  <resolved_reference>Bower, G. H., &amp; Karlin, M. B. (1974). Depth of pro- cessing
pictures of faces and recognition mem- ory. Journal of Experimental Psychology, 4,
751- 757.</resolved_reference>
  <resolved_reference>Cochran, B. P., McDonald, J. L., &amp; Parault, S. J. (1999).
Too smart for their own good: The disadvantage of a superior processing capacity for
adult language learners. Journal of Memory and Language , 41, 30-
58.</resolved_reference>
  <resolved_reference>Corina, D. P., Vaid, J., &amp; Bellugi, U. (1992). The linguis-
tic basis of left hemisphere specialization. Science , 255,
1258-1260.</resolved_reference>
  <resolved_reference>Damasio, A. R., &amp; Damasio, H.(2000). Language and the
brain. In K. Emmorey &amp; H. Lane (Eds.), The signs</resolved_reference>
  <resolved_reference>Dijkstra, T., &amp; van Heuven, W. J. B. (1998). The BIA model
and bilingual word recognition. In J. Grainger &amp; A. Jacobs (Eds.), Localist
connection- ist approaches to human cognition (pp. 189-225). Hove, England:
Erlbaum.</resolved_reference>
  <resolved_reference>Emmorey, K. (2002). Language, cognition, and the brain. Mahwah,
NJ: Erlbaum.</resolved_reference>
  <resolved_reference>Emmorey, K., &amp; Corina, D. (1993). Hemispheric spe-
cialization for ASL signs and English words: Dif- ferences between imageable and
abstract forms. Neuropsychologia, 31, 645-653.</resolved_reference>
  <resolved_reference>Emmorey, K., Grabowski, T., McCullough, S., Damasio, H., Ponto,
L., Hichwa, R., et al. (2003). Neural sys- tems underlying lexical retrieval for sign
language. Neuropsychologia, 41, 85-95.</resolved_reference>
  <resolved_reference>Engle, R. W.,Cantor, J., &amp; Turner, M.L. (1989). Modality
effects: Do they fall on deaf ears? Quarterly Journal of Experimental Psychology A:
Human Experimental Psychology, 41, 273-292.</resolved_reference>
  <resolved_reference>Fergusson, R. (1985). The Penguin rhyming dictionary. London:
Penguin Books.</resolved_reference>
  <resolved_reference>Gollan, T. H., Forster, K. I., &amp; Frost, R. (1997). Transla-
tion priming with different scripts: Masked prim- ing with cognates and noncognates
in Hebrew- English bilinguals. Journal of Experimental Psychol- ogy: Learning, Memory
and Cognition, 23, 1122- 1139.</resolved_reference>
  <resolved_reference>Horwitz, B., Amunts, K., Bhattacharyya, R., Patkin, D.,
Jeffries, K., Zilles, K., et al. (2003). Activation of Broca's area during the
production of spoken and signed language: A combined cytoarchitectonic mapping and
PET analysis. Neuropsychologia, 41, 1868-1876.</resolved_reference>
  <resolved_reference>Humphries, T., Padden, C., &amp; O'Rourke, T. J. (1980). A
basic course in American Sign Language . Silver Spring, MD: T. J.
Publishers.</resolved_reference>
  <resolved_reference>Kroll, J. F., &amp; Stewart, E. (1994). Category interference
in translation and picture naming: Evidence for asymmetric connections between
bilingual mem- ory representations. Journal of Memory and Lan- guage , 33, 149-173.
&#x2D8;</resolved_reference>
  <resolved_reference>Kucera, H., &amp; Francis, N. W. (1967). Computational anal-
ysis of present-day American English. Providence, RI: Brown University
Press.</resolved_reference>
  <resolved_reference>Larsen-Freeman, D. (2003). Teaching language: From grammar to
grammaring . Boston: Thomson-Heinle.</resolved_reference>
  <resolved_reference>Liddell, S. (1984). Think and believe: Sequentiality in
American Sign Language. Language , 60, 372-398.</resolved_reference>
  <resolved_reference>Potter, M. C., So, K. -F., von Eckardt, B., &amp; Feldman, L.
B. (1984). Lexical and conceptual representation in beginning and proficient
bilinguals. Journal of Verbal Learning and Verbal Behavior , 23,
23-38.</resolved_reference>
  <resolved_reference>Rosen, R. S. (2008). American Sign Language as a for- eign
language in U.S. high schools: State of the art. Modern Language Journal , 92,
10-38.</resolved_reference>
  <resolved_reference>Smith, C., Lentz, E. M., &amp; Mikos, K. (1988). Signing
naturally: Student workbook level 1. San Diego, CA: DawnSign
Press.</resolved_reference>
  <page width="495" height="720" number="2">
    <header x="31.15" y="677.64" width="400.52" height="8.67"></header>
  </page>
  <page width="495" height="720" number="3">
    <header x="62.89" y="677.24" width="400.52" height="8.67"></header>
  </page>
  <page width="495" height="720" number="4">
    <header x="31.15" y="677.64" width="400.52" height="8.67"></header>
  </page>
  <page width="495" height="720" number="5">
    <header x="62.89" y="677.7" width="400.52" height="8.67"></header>
  </page>
  <page width="495" height="720" number="6">
    <header x="31.15" y="677.64" width="400.54" height="8.67"></header>
  </page>
  <page width="495" height="720" number="7">
    <header x="62.89" y="677.7" width="400.52" height="8.67"></header>
  </page>
  <page width="495" height="720" number="8">
    <header x="31.15" y="677.64" width="400.53" height="8.67"></header>
  </page>
  <page width="495" height="720" number="9">
    <header x="62.89" y="677.7" width="400.52" height="8.67"></header>
  </page>
  <page width="495" height="720" number="10">
    <header x="31.15" y="677.64" width="400.52" height="8.67"></header>
  </page>
  <page width="495" height="720" number="11">
    <header x="62.89" y="677.7" width="400.5" height="8.67"></header>
  </page>
  <page width="495" height="720" number="12">
    <header x="31.15" y="677.64" width="400.5" height="8.67"></header>
  </page>
</pdf>
