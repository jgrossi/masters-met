<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.542083">
Testing the Development of Linguistic
Knowledge in Adult Na¨ıve Learners
of American Sign Language
</title>
<author confidence="0.210296">
MARGRETA VON PEIN
</author>
<affiliation confidence="0.791197666666667">
Union Institute &amp; University, Cincinnati, Ohio and
University at Albany, State University of New York
Department of Psychology
</affiliation>
<address confidence="0.955721">
1400 Washington Avenue
Albany, NY 12222
</address>
<email confidence="0.819609">
Email: mvpein@yahoo.com
</email>
<sectionHeader confidence="0.795933" genericHeader="method">
JEANETTE ALTARRIBA
</sectionHeader>
<affiliation confidence="0.8520095">
University at Albany, State University of New York
Department of Psychology
</affiliation>
<address confidence="0.963772">
1400 Washington Avenue
Albany, NY 12222
</address>
<email confidence="0.721676">
Email: ja087@albany.edu
</email>
<bodyText confidence="0.999843">
The present study was designed to investigate the ways in which notions of semantics and
phonology are acquired by adult na¨ıve learners of American Sign Language (ASL) when they
are first exposed to a set of simple signs. First, a set of ASL signs was tested for nontransparency
and a set of signs was selected for subsequent use. Next, a set of semantically related English
words and a set of phonologically related English words were generated and paired with
each of the signs selected earlier. In the experiment reported here, participants were taught
pairs of sign–English word translations. Subsequently, they were then engaged in a translation
recognition task in which foils were semantically related, phonologically related, or completely
unrelated to the corresponding translations. Interference in performing the recognition task
(i.e., the foil conditions) indicated that participants had encoded various features of the sign–
word combinations after a single learning session. Results are discussed with regard to bilingual
memory representations as well as to ASL acquisition.
</bodyText>
<sectionHeader confidence="0.954194" genericHeader="method">
THIS STUDY BUILDS ON THE RESEARCH ON
</sectionHeader>
<bodyText confidence="0.980298485714285">
the development of various levels of linguistic representation in bilingual memory. Over time, two
hypotheses with differing views on the structure
and representation of more than one language
in memory have been described: a word association model and a concept mediation model (see
Figures 1 and 2). The first model predicts that beginning bilinguals access second-language (L2)
words via their first-language (L1) lexicon (Kroll
&amp; Stewart, 1994). In contrast, the second model
predicts that beginning language learners access
concepts corresponding to L2 words and then mediate through the conceptual store to access the
L1 translations of the L2 words (as in Altarriba
&amp; Mathis, 1997). The word association hypothesis
assumes that there is a direct link between the L1
The Modern Language Journal, 95, ii, (2011)
DOI: 10.1111/j.1540-4781.2011.01173.x
0026-7902/11/205–216 $1.50/0
C 2011 The Modern Language Journal
and L2 whereby the novice bilingual associates the
new L2 word with known L1 vocabulary. Thus, a
novice bilingual learns a new word in the L2 by
associating it with its L1 translation and then referring to a conceptual store for meaning. Altarriba
and Mathis (1997) administered a timed translation recognition task to English monolingual
participants who had learned a set of English–
Spanish translations within the course of their experiment. When the choice offered for the correct
translation pair during a subsequent test phase
included an unrelated word, an orthographically
or semantically similar word (foils), or the correct
word, the slowest response time occurred with the
foils. The slower response time indicates that the
novice bilinguals associated the new L2 word with
the known L1 lexicon in determining the correct
choice for the target word. The concept mediation
hypothesis assumes that there is no direct link
to the L1 lexicon, but translation of L2 occurs
by accessing a common semantic store that both
L1 and L2 lexicons share. Slower response time
</bodyText>
<page confidence="0.992786">
206
</page>
<figure confidence="0.911406210526316">
The Modern Language Journal 95 (2011)
FIGURE 1
Word Association Model (Reproduced from Altarriba, 1990; originally taken from Potter, So, von Eckardt, &amp;
Feldman, 1984)
English
Cat
Dog
Spanish
Gato
Perro
FIGURE 2
Concept Mediation Model (reproduced from Altarriba, 1990; originally taken from Potter et al., 1984)
Lexical
Level
Cat
(L1)
Gato
(L2)
Conceptual Level
</figure>
<bodyText confidence="0.998860277777778">
for semantically similar words, for example, is evidence of this direct access to a conceptual store.
Bilingual research empirically testing theories
from second language acquisition (SLA) has not
generally included data on adult acquisition of
a visual–spatial L2, such as American Sign Language (ASL). No studies to date have tested the
acquisition of ASL signs by na¨ıve learners using a
timed procedure that captures the implicit learning of those signs, even though a recent review by
Rosen (2008) indicates that there is tremendous
growth in the study of ASL as a foreign language,
particularly among secondary school students in
the United States. Further, the experiments that
have been carried out to examine various characteristics of the representation of ASL signs did not
provide for a context in which the time allotted for
the access and retrieval of a newly acquired sign
was constrained, indicating the automatic processing of the sign. However, neurobiological research
in ASL has confirmed that visual–spatial language
processing is essentially the same as oral–aural
language processing (Emmorey, 2002; Emmorey
et al., 2003; Horwitz et al., 2003). The overall similarities in processing between ASL and spoken
English suggest that novice ASL bilinguals may
represent the new signs in the L2 via the same
mechanism that functions for bilinguals learning
a second spoken language.
Therefore, a fundamental question remains
open in this area of research study: To what extent are the memory processes involved in learning ASL signs in the context of L2 learning similar
to, or different from, those involved in learning
an oral–aural language? Are signs processed like
words in spoken languages?
The aim of the current study is threefold. First
and foremost is the aim to uncover the characteristics of word representation that are acquired
when an adult first learns ASL sign vocabulary.
Knowing the levels of language representation
(e.g., phonological, semantic) that are acquired
and how best they can be acquired may inform
training methods for learning ASL as an L2. Second, the work is aimed at investigating the representation in memory of newly acquired signs
under situations that would promote the automaticity of the access of that information. Using an interference paradigm that will be described later, it was possible to determine whether
</bodyText>
<page confidence="0.987731">
207
</page>
<bodyText confidence="0.989979111111111">
Margreta von Pein and Jeanette Altarriba
semantic or phonological information was encoded early in the learning of ASL signs without
the possibility of elaborative processes that can
be engaged in untimed response tasks. Third, the
present work is aimed at testing a hypothesis put
forth by Kroll and Stewart (1994) regarding the
conceptual or semantic development that occurs
when one first learns an L2. More will be said
about this final aim in the next section.
</bodyText>
<sectionHeader confidence="0.966946" genericHeader="method">
THE CURRENT STUDY
</sectionHeader>
<bodyText confidence="0.998161442307692">
This study investigates a specific part of what
adult na¨ıve learners of ASL learn when first exposed to the English equivalents of 28 simple ASL
signs. The study investigates only receptive skills
and the levels of representation acquired early
in learning. The study is not about learning ASL
itself; rather, it investigates what automatic mental representations or associations are acquired
when adults unfamiliar with a visual language first
“learn” the verbal translations of some signs. The
theoretical models of bilingual memory representation studied by both Kroll and Stewart (1994)
and Altarriba and Mathis (1997) are tested in the
current study on the memory of novice students
of ASL.
In merging aspects of both the word association
model and the concept mediation model of bilingual memory, Kroll and Stewart (1994) proposed
a model (i.e., the revised hierarchical model) that
describes the asymmetrical links that appear to be
present in bilingual language representation as
well as a model that accounts for the differences
reported in the literature on translation direction
(see Figure 3). This model contains mental lexicons for the L1 as well as an L2. The L1 mental
lexicon is depicted as larger than that of the L2 because it is assumed that the bilingual would have
a larger vocabulary in his or her native language
than in the L2. The link between the L1 and concepts appears to be bidirectional and very strong.
As a person acquires an L2, especially later in life,
L2 words would be integrated into memory by developing a pathway that is attached to the lexicon
of the L1 (an idea emerging from the original
word association model). Finally, the connection
between the L2 and concepts is illustrated as being weak. However, it has been suggested that this
link increases in strength as the bilingual becomes
more proficient or fluent in his or her L2 (a notion derived from the earlier concept mediation
model).
One advantage of the revised hierarchical
model is that it accounts for several findings that
have been reported in bilingual studies, such as
faster translation in the L2–L1 direction, category
interference that occurs only during L1–L2 translation (Kroll &amp; Stewart, 1994), and larger priming
effects in the L1–L2 direction than in the L2–L1
direction (e.g., Altarriba, 1992; Gollan, Forster,
&amp; Frost, 1997). In addition, the model attempts
to show how changes in a person’s proficiency in
the L2 will change the way in which lexical and
conceptual information is accessed (i.e., greater
proficiency in the L2 allows a greater amount
of conceptual information to be available). Although this may be true to some extent, it has
been argued that new words in an L2 may not
be stored in just the lexicon of the L2 but rather
represented as both a lexical and conceptual entry if the words were acquired in an environment
in which both form and meaning were emphasized (see Altarriba &amp; Mathis, 1997). Further, it
is possible that the conceptual aspect of some
words may not be stored in a common conceptual
store for both languages, simply because there are
some items that may represent language-specific
</bodyText>
<figure confidence="0.944771555555556">
FIGURE 3
Revised Hierarchical Model (Adapted from Kroll &amp; Stewart, 1994)
Lexical
Level
L2
L1
Conceptual Level
Note. L1 = first language; L2 = second language.
Concepts
</figure>
<page confidence="0.998934">
208
</page>
<bodyText confidence="0.990896581818182">
concepts and, therefore, direct translations in the
opposing language do not exist (Altarriba, 2000).
Altarriba and Mathis (1997) questioned the
revised hierarchical model of Kroll and Stewart
(1994), which suggests that nonfluent bilinguals
rely on lexical association early in SLA and only
later on concept mediation. As mentioned earlier,
Altarriba and Mathis tested Kroll and Stewart’s
model with monolingual English speakers who
were taught Spanish for the first time. Altarriba
and Mathis designed a set of experiments to investigate the acquisition of the link between conceptual memory and the L2, hypothesizing that
it could develop as early as the first encounter or
first learning session with the new language. Kroll
and Stewart had claimed that this link developed
over an unspecified length of time and remained
relatively weak. Altarriba and Mathis chose a translation recognition paradigm aimed at measuring
the interference that would be caused by the presentation of L1–L2 (English–Spanish) pairs that
were in some way similar, but not identical, to
the true translations. They theorized that individuals would be slower to respond (slower response
times [RTs]) to English–Spanish pairs that were
either orthographically or semantically similar to
the true translations (i.e., foils) that had been acquired during the learning session of their experiment. In the translation recognition task, they indeed found that both monolingual and bilingual
participants had slower RTs to the foils. They concluded that orthographic and semantic information is automatically coded early in the process of
SLA. In other words, the meanings of words in the
new language were represented in the learner’s
conceptual store as early as the first learning session. Could similar results be found in a “crossmodal” bilingual environment?
Because Altarriba and Mathis’s (1997) SLA
hypotheses and conclusions are based on experimental data from oral–aural languages, assumptions cannot be made as to whether these hypotheses will function in the acquisition of all L2s,
spoken and visual. Therefore, one of the aims of
the present study was to investigate what adults
na¨ıve to ASL learn when first exposed to signs
and their English meanings. The current study hypothesizes that hearing, English-speaking adults
learning ASL would also encode semantic, as well
as lexical, information early in the learning process. However, as the study’s focus was a visual
language as the L2 acquired, hypothesizing about
orthographically similar words between the two
languages had to be altered. Instead, the hypothesis concerned English words that were phonologically similar to the correct translation. Adult stu-
The Modern Language Journal 95 (2011)
dents of ASL should have slower RTs when the English words are phonologically similar to the correct translations than when the English words are
unrelated to the translations. A semantic condition was also included, as in Altarriba and Mathis.
To test these hypotheses, an experiment was designed that included learning and testing phases.
First, participants viewed a videotape of ASL signs
and heard the signs’ English equivalents. After
the participants studied the signs and their translations, we needed to determine if the participants had “learned” the corresponding English
words. Second, the participants were tested on
their “learning.” They viewed the same list of signs
and heard an English word from one of the test
conditions, paired with each sign. They had to
determine whether the word was or was not the
English translation they had learned for the sign.
It was expected that interference in processing
would occur for the foils that were semantically
and phonologically similar to the correct translations that the participants had learned in the
study phase of the experiment if the participants
had indeed accurately encoded the visual, phonological, and semantic referents for each sign.
</bodyText>
<sectionHeader confidence="0.86727" genericHeader="method">
METHOD
</sectionHeader>
<subsectionHeader confidence="0.707343">
Participants
</subsectionHeader>
<bodyText confidence="0.989540705882353">
Undergraduate introductory psychology students (n = 48, average age = 19.8) from the
University at Albany, State University of New
York participated in this experiment for course
credit. The participants had normal or correctedto-normal visual acuity and had no known hearing limitations. When they were asked before the
experiment, the participants said they had no
knowledge of finger spelling or ASL. Additionally,
the participants were also asked about their knowledge of ASL at the conclusion of the experiment.
This practice of asking participants about their
language background both before and after an experiment has been used previously, as it has been
found that, on occasion, the act of performing
the experiment brings to mind a forgotten memory of their exposure to ASL or other languages
(see, e.g., Altarriba &amp; Mathis, 1997). The participants received partial course credit. At the end
of the experiment, a brief language history questionnaire was administered to ensure that they
were na¨ıve to ASL. Mean self-ratings on a 10-point
scale revealed native fluency in English at 9.3.
Percent of the day English was spoken was 92.3.
Questionnaire results revealed no exposure to, or
</bodyText>
<page confidence="0.99656">
209
</page>
<listItem confidence="0.959077666666667">
Margreta von Pein and Jeanette Altarriba
knowledge of, ASL or any other signed language
(see Appendices A and B).
Materials
Sign Selection. Twenty-eight signs were selected
that abided by the following four criteria: (a)
simple or monomorphemic, (b) frequently used,
(c) visually dissimilar from each another, and
(d) not transparent. We relied on two beginning
</listItem>
<bodyText confidence="0.970258659090909">
ASL teaching texts and two ASL dictionaries as
the source for simple and frequently used signs
(Humphries, Padden, &amp; O’Rourke, 1980; Smith,
Lentz, &amp; Mikos, 1988; Sternberg, 1994; Stokoe,
Casterline, &amp; Croneberg, 1965). We wanted to select a list of signs that were completely distinct
from one another in terms of all parameters, including movement, shape, and position. In other
words, if two signs varied from each other on a
single parameter, we excluded those items from
our final list of signs. This ensured that the signs
on the list were visually dissimilar. The English
translations of signs on the list were all concrete
nouns.
A native deaf signer was videotaped signing
the list. Videotaping a native signer is the ASL
equivalent to having a native English speaker
say English words. The signer’s mean signing
time per word was 1,260 milliseconds. The English speaker’s mean time for each word was 534
milliseconds. Therefore, it was determined that
a 5,000-millsecond interval between each sign
would give participants adequate time to see the
sign, hear the English word, and respond as required. A 5-second interval was also the preferred
elapsed time between signs in recall and recognition tests in other published works (Bonvillian, Rea, Orlansky, &amp; Slade, 1987; Bower &amp; Karlin, 1974; Cochran, McDonald, &amp; Parault, 1999).
There was no sound on the videotape.
Next we needed to be sure the chosen signs
were not transparent. Thirty participants with
no knowledge of ASL or experience with finger
spelling and from the same pool as the subsequent experiment were then asked to guess the
English translations for the signs. Two participants
correctly guessed two different signs. These signs
were eliminated from the list. This ensured that
the remaining signs were not transparent—that
is, their translations were not easily guessed—and,
thus, these signs were used in the ensuing experiment.
Creating Semantic Associates. The English translations for the 28 signs selected were then presented to 30 participants who did not take part
in the earlier norming study or in the subsequent
experiment. They were asked to write down the
first word that came to mind next to each of the
English words. All of the words that the participants wrote were tabulated to find the word most
frequently associated with the target word on the
list. Only exact wording was tallied (i.e., not plurals for singular words or derivations of our words
on the list). For example, for “shoe” people wrote
“sock” and “socks,” which were counted as two different words. Thus, the most frequently reported
word for each target word was used as the semantic associate for these items. As the participants
were from the same pool as those who would perform the subsequent experiment, these association norms would presumably reflect the knowledge of the participants in the experiment proper.
</bodyText>
<subsectionHeader confidence="0.747372">
Design and Apparatus
</subsectionHeader>
<bodyText confidence="0.996914076923077">
The experiment required words in four test
conditions: (a) the target words (i.e., the English
words the participant learned for the videotaped
signs); (b) words unrelated to the target words;
(c) words semantically related to the target words;
and (d) words phonologically related to the target words. The unrelated items were made up of
words of approximately the same length and frequency as the signs’ English equivalents (Ku˘cera
&amp; Francis, 1967). Mean word length and mean
word frequency for the words in all four conditions are listed in Table 1. t-Tests indicated no
significant differences across conditions for either
frequency or length (all ps &amp;gt; .05). The phonologically related condition was constructed of rhyming
words (Fergusson, 1985; Webster’s, 1987). Sample
stimulus items include the following: Targets: apple, cookie; Unrelated: thigh, paddle; Semantic
</bodyText>
<figure confidence="0.968566875">
TABLE 1
Word Length and Frequency Means and Standard
Deviation for Four Test Conditions
Condition
Means
SD
Length
Target
Unrelated
Semantic
Phonological
5.08
5.08
4.71
5.21
Target
Unrelated
Semantic
Phonological
90.29
88.75
77.79
83.33
1.38
1.38
1.30
1.35
Frequency
117.95
112.43
81.96
136.50
</figure>
<page confidence="0.977307">
210
</page>
<bodyText confidence="0.997352017857143">
Foil: pie, sweet; Phonological Foil: chapel, rookie.
Thus, the words that corresponded to the target
“apple” in each condition included “thigh,” “pie,”
and “chapel.” The set can be derived for “cookie”
in the same way from the examples provided earlier (see Appendix C for a complete listing of
items).
The videotape of the 28 common ASL signs
created previously was used in the current experiment. Four signs and four English words, each
from a different test condition, were isolated for
use during the practice phase. The remaining 24
English words for each condition (i.e., the English
translations for the sign, the unrelated words, the
semantically related words, and the phonologically related words) were counterbalanced across
four experimental lists such that 6 words from
each condition appeared only in one list. Each list
had a different set of six words from each of the
four conditions. To familiarize participants with
the test procedure, the four practice signs and
words were shown and heard at the start of each
test phase. Everyone received the same practice
items.
The videotape of the 28 signs was then reordered into four randomly selected orders using
Media 100’s digital nonlinear editing system. With
the GoldWave audio program, the 96 test English
words, 24 words in four conditions, plus 8 words
used for practice were entered into the computer.
The words were cued so that they would be heard
after the sign began but before the sign ended. To
standardize how the signs were presented to the
participant, Liddell’s (1984) description of sign
phonology was employed. In his description, a
sign can begin with either a MOVEMENT (M)
or a HOLD (H) at a stationary location. Signs can
also end with either an M or an H. For example,
the sign for FATHER is HMH. In the sign for FATHER, the first movement to the forehead is not
relevant to sign formation. In the sign, the first
and last contacts of the thumb on the forehead
are HOLDS, with the intervening MOVEMENT.
(Note that another sign form for FATHER is the
thumb contact HOLD on the forehead without
MOVEMENT but with other fingers wiggling.)
While seeing FATHER on videotape, the participant heard the English word “father” after the
initial H but before the M. The participant heard
the English word as the signer’s palm began traveling toward her face. The English word was completed before the signer’s thumb came to rest on
her forehead. Hearing the English translation at
the same moment in each sign’s articulation was
crucial for accurately recording RT. Therefore,
the words were cued to be heard just after the ini-
The Modern Language Journal 95 (2011)
tial M or H, as the signer was transitioning to the
following H or M of the sign.
A program developed using SuperLab Pro software was used to record elapsed time between the
onset of the English word and the participant’s
response. The signs for the experiment were presented on a video monitor, and the words were
heard over speakers on either side of the monitor
and linked to a laptop computer.
</bodyText>
<subsubsectionHeader confidence="0.956726">
Procedure
</subsubsectionHeader>
<bodyText confidence="0.999496205882353">
All participants were assigned a random number and were tested individually. The first phase
of the experiment in which the participants studied the signs and their English translations was
the acquisition phase. Participants were seated in
front of the video monitor to watch 28 signs one
by one and hear their English translations. They
were asked to try their best to learn the English
translations for the 28 ASL signs. Within the same
5-second interval for each sign, the participants
heard the sign’s English translation twice. The
videotape was repeated twice in the same order, so
the participants saw the signs twice and heard the
English translations four times. Then the participants were asked to check what they had learned
by viewing the same 28 signs, without translations,
in a different order and saying aloud the English
word they remembered for the sign. At the end of
the viewing without the audio, we read aloud the
errors and omissions the participants had made
in naming the English translations and provided
the accurate sign and spoken translation for items
the participants had missed. Then the participants
viewed the list of 28 signs again but in a different
order. The English words and their corresponding signs were repeated once again. This study
test process was repeated in full, until the participants reached 100% accuracy. When the participants named the translations for the signs 100%
correctly, they went on to the testing phase of the
experiment. To limit the duration of the experiment, participants were excused from the experiment if they did not reach 100% accuracy after
half an hour of study. On this basis, 3 individuals were excluded from finishing the experiment
and 3 new participants were added to maintain
the group number at 48.
Following the acquisition phase, the participants were given a 3-minute intervening task,
which included counting backward by 4s from
534. This task diverted the participants from
thinking about the acquisition phase and actively
engaging in rehearsal. The 3 minutes also allowed
us to set up the computer for the test phase.
</bodyText>
<page confidence="0.976706">
211
</page>
<bodyText confidence="0.996032416666667">
Margreta von Pein and Jeanette Altarriba
The second phase of the experiment, in which
the participants decided if the word they heard
was the translation they had learned for the sign,
was the testing phase. On the monitor, the participants saw each of the 28 signs again in yet a
different order paired with hearing an English
word. (Four of those signs formed the practice
trials that were then followed by the remaining 24
signs divided equally among the following four
conditions: correct target, semantically related,
phonologically related, and unrelated.) Each participant viewed a single experimental list in random order. The participants were told to press a
designated “yes” or “no” key on the laptop keypad
indicating whether the word they heard was or
was not the word they had learned for the sign on
the video monitor. They were to make their decisions as quickly and as accurately as possible.
The participants were given 1,500 milliseconds
to respond. At the beginning of the test phase,
four signs each with an English word were presented as practice trials to familiarize the participants with the test procedure. Then the actual test
proceeded.
As mentioned earlier, at the end of the experiment, the participants were asked four questions
about sign recognition (see Appendix B) and answered a brief language history questionnaire.
None of the participants was found to have had
prior experience with ASL or any other signed
language.
</bodyText>
<sectionHeader confidence="0.981738" genericHeader="evaluation">
RESULTS
</sectionHeader>
<bodyText confidence="0.997831933333333">
For each participant, mean response times and
standard deviations (SDs) were computed for the
four conditions (true target, semantic, phonological, and unrelated). After computing SDs for each
participant’s RT in each condition, we found no
RTs, or outliers, that exceeded 2.5 SDs above or
below the mean for each condition. All participants’ RTs were included in our analysis. Mean
RTs, SDs, and error rates for the four test conditions (correct translation, unrelated, semantic,
and phonological) for all participants are listed
in Table 2. Only data for correct responses were
included. An analysis of variance (ANOVA) indicated that the four conditions differed significantly from one another, with F (3,45) = 27.708,
MS = 8.620, p &amp;lt; .001. Planned comparisons (Bonferroni corrections were applied) showed that RTs
for the semantic and the phonological conditions
were virtually the same, with t(47) = −0.220, p &amp;gt;
.05. However, the RTs for the semantic and phonological conditions compared to the unrelated
condition were significantly slower, indicated by
</bodyText>
<figure confidence="0.9834763125">
TABLE 2
Mean Response Times (Milliseconds), Standard
Deviations, and Error Rates (Percentages) for All
Test Conditions (n = 48)
Condition
Target
Unrelated
Semantic
Phonological
RT
SD
ER
968
1,127
1,195
1,202
</figure>
<page confidence="0.93918825">
334
364
431
417
</page>
<figure confidence="0.731973666666667">
1.04
0.69
2.08
</figure>
<page confidence="0.592294">
11.81
</page>
<bodyText confidence="0.336368">
Note. ER = error rate; RT = response time.
</bodyText>
<equation confidence="0.9142245">
t(47) = 2.363, p &amp;lt; .05 (Cohen’s d = 0.48) and
t(47) = 2.753, p &amp;lt; .01 (Cohen’s d = 0.56),
</equation>
<bodyText confidence="0.957514633333333">
respectively. Semantically related foils produced
an interference effect suggesting that novices in
ASL had formed a conceptual link to the ASL
signs. Phonologically related foils produced a
slightly larger interference effect, indicating that
the participants had learned to associate the newly
acquired signs and their phonological representations in English.
Error data were examined to see if the higher
rate of errors in the phonological condition was
significantly different from other conditions (see
Table 2). An ANOVA indicated that there was a significant difference in error rates across the four
conditions, with F (3,45) = 27.708, MS = 4.852;
p &amp;lt; .001. Planned comparisons (Bonferroni corrections were applied) revealed that the error rate
for the target condition differed significantly from
the phonological condition, with t(47) = −5.698,
p &amp;lt; .001 (Cohen’s d = 1.16). In addition, the error
rate for the unrelated condition was significantly
different from the phonological condition, with
t(47) = −6.132, p &amp;lt;. 0001 (Cohen’s d = 1.77).
Finally, the error rate for the semantic condition
was also significantly different from the phonological condition, with t(47) = −5.695, p &amp;lt; .001
(Cohen’s d = 1.16). Appendix D includes a listing of individual items and their corresponding
error rates. Note that although only one item in
the semantic category produced a significant error rate (i.e., “kids”), several items contributed to
the large error rate in the phonological condition. In this later condition, most prominent were
the items “fair,” “bother,” and “fig,” corresponding to “bear,” “father,” and “pig,” respectively.
Clearly, these kinds of errors of substitution stem
from the similarity across items in terms of initial phonemes; thus, as in most situations, whenever manner/place of articulation overlaps across
lexical items, errors of recognition and identification are more likely to occur. More will be said
later in terms of the implications of these kinds of
</bodyText>
<page confidence="0.989362">
212
</page>
<bodyText confidence="0.995742">
errors for lexical representation and processing
in general.
</bodyText>
<sectionHeader confidence="0.953578" genericHeader="conclusions">
GENERAL DISCUSSION
</sectionHeader>
<bodyText confidence="0.992969795081967">
The experiments described here were designed
to follow the approach of Altarriba and Mathis’s
(1997) experiments in SLA. When Altarriba and
Mathis tested English-speaking monolinguals who
had just acquired a set of words in an L2 (Spanish), they found that these participants had encoded both semantic and orthographic aspects
of the new words and were able to access this
new information when responding to a translation recognition task. Because an interference
effect occurred for both conditions, it appeared
that monolinguals formed a direct link with lexical and conceptual levels of representation when
first learning an L2. In the current study, the
results of the experiment on acquiring the ASL
signs confirmed that L2 (ASL) conceptual processing (as well as phonological processing of the
English translation equivalents) is involved very
early in the language acquisition process. Both
semantic and phonological interference effects
were reported within the current study. It can
be assumed, then, that the processes involved in
acquiring an L2 as described by Altarriba and
Mathis also come into play for adult novices learning a visual language as the L2. Moreover, as reported by Altarriba and Mathis, the current work
also indicates that the revised hierarchical model
proposed by Kroll and Stewart (1994) should be
modified to indicate that conceptual/semantic information can be acquired in the earliest stages
of L2 learning. In other words, even after a single learning session, individuals can acquire the
knowledge of the meaning of newly learned L2
words—a link that had been purported to take
more time to develop, as per the revised hierarchical model.
In relation to the above issues of acquisition
and development, note that all of the participants
in the current study had been exposed to an L2
at some point in their lives (either from birth or
through schooling in later years; see Appendix A).
Thus, it appears that for the current participants,
the acquisition of concepts via sign constituted a
kind of “third-language” exposure, although it was
not a verbal language, as were their L1s and L2s.
Given the briefness of the questionnaire that was
used, it is difficult to assess the degree to which
the present participants were fluent in their L2
compared to their L1. Thus, although all participants had been exposed to an L2 at some point
in their lives, their relative fluency in that lan-
The Modern Language Journal 95 (2011)
guage is likely to have varied considerably and
is not currently known. Future investigations of
the acquisition of ASL signs should examine the
extent to which individuals who are exposed to an
L2 and who consider themselves truly “bilingual”
or “fluent/proficient” in their L2 show different
patterns of translation recognition for newly acquired signs. Mode or context of learning and
acquisition should also be taken into account in
further investigations. Thus, participants’ bilingualism may be examined as a variable of interest in future studies of sign acquisition, as
this question was not a focus of the current
investigation.
The present study provided evidence that conceptual and phonological interference occurs in
learning the meanings of ASL signs—a finding
similar to that reported for the acquisition of
words of a second, spoken language (see, e.g., Altarriba &amp; Mathis, 1997; van Hell &amp; Mahn, 1997).
Previous ASL research evidence points to the parallel functioning of visual–spatial and oral–aural
languages. For example, signs that look different from one another are identified more quickly
than those that look similar to one another. This
mimics the phonological similarity effect that occurs
in spoken languages (see also Emmorey, 2002).
In addition, Liddell (1984) illustrated how signs
have beginnings, middles, and ends similar to the
segments of spoken words, onsets, medial phases,
and offsets.
An interesting finding in the current set of
results is that the error rates were significantly
higher in the phonological condition, as compared to other conditions within the experiment;
that is, many more confusion errors occurred
when foils were phonologically similar to the true
translation. Given that the test pairs in the current
case were comprised of a spoken word and a word
that was signed, the implication is that the participants accessed the phonological representations
of the signed words to the extent that those representations interfered with their ability to reject
the incorrect pairing. Theoretically, these data
suggest that individuals accessed phonology when
not specifically directed to do so in the context of
the current study. Phonology was encoded in an
implicit manner, as part of the learning of signs,
overall. Thus, as current models of bilingual representation have suggested (see, e.g., BIA and
BIA+ in Dijkstra &amp; van Heuven, 1998), phonology is often retrieved in the process of understanding newly acquired concepts in an L2—even
if it is a signed language. Further, the current
data underscore the basic finding in the literature that many auditory confusion errors are
Margreta von Pein and Jeanette Altarriba
derived from words that have phonological overlap and share either place of articulation or manner of articulation, or both. The fact that these
phonological representations in the current study
stem from the recognition of a signed word is
interesting evidence to suggest that phonological confusion errors are not modality-specific (see
also Engle, Cantor, &amp; Turner, 1989, for a related
discussion).
Although the current study examined translation recognition for newly acquired signs and
their English translations, the participants performed a learning task that by its very nature emphasized the phonological and semantic aspects
of the association between the English word and
its corresponding sign. Although the participants
developed these new representations such that
they achieved 100% accuracy on a test of their
knowledge, it is unclear to what extent different participants might have engaged in their own
strategies in learning the signs of interest. Clearly,
the possibility that the participants engaged in
their own mnemonic strategies to shape their
mental representations for the signs and their English counterparts may have affected the way in
which this knowledge was learned and encoded
for each participant. Future examinations of the
acquisition of signs should vary instructions so as
to either document the means by which participants actively learn signs or provide concrete instructions as to the types of strategies that should
be used (e.g., imagery, context availability) so
as to investigate the influence of learning strategy on the ultimate representation of new signs.1
Moreover, it is important to note here that although the current work focused on the learning of ASL signs, the learning of language, in
general, encompasses many more elements that
bring together aspects of reasoning, pragmatic
usage, contextual influences, and the like (see,
e.g., Larsen-Freeman, 2003; van Lier, 2004). Thus,
language development is a highly dynamic process, and future work may focus on the acquisition of ASL signs in broader contexts of language,
incorporating a more ecological approach to
acquisition.
In a related vein, neurological investigations
into the hemispheric involvement of imageable
concrete signs in ASL, as distinct from abstract lexical forms, continue to raise questions about the
different roles imagery may play in ASL and English (Emmorey &amp; Corina, 1993). Most recently,
neurobiological evidence also indicates that both
signed and spoken languages are generally localized in the same area in the left hemisphere
(Corina, Vaid, &amp; Bellugi, 1992; Damasio &amp; Dama-
</bodyText>
<page confidence="0.993693">
213
</page>
<bodyText confidence="0.998359558139535">
sio, 2000; Emmorey et al., 2003; Horwitz et al.,
2003).
Notwithstanding the linguistic and neurobiological parallels between ASL and the spoken languages of the world, we recognize that the visual
modality makes a distinct difference in L2 learning. The current study kept the learning challenge of ASL to a bare minimum (i.e., acquiring
the English words for 28 simple signs). Nothing
about sign perception was investigated. Clearly,
the greater part of understanding how sign-na¨ıve
adults learn ASL has to include working memory experiments on what the adult learner processes (i.e., sees, stores, attends to, recalls, etc.) in
the visual modality (see, e.g., Wilson &amp; Emmorey,
2003). Experiments on reproducing ASL signs
are recommended, as well as experiments with
ASL units longer than primarily single monomorphemic signs.
When we analyzed the ways the participants remembered the English meanings during the study
phase of the present experiment, another potential area of research became clear. Although the
participants studied the English meanings for the
signs in the learning part of the experiment, we
informally noted evident mnemonics used by two
participants, each for a single word. For example,
one participant said “father-head” while hearing
the word “father” and viewing FATHER, in which
the thumb of the open hand shape touches the
forehead. Another participant during the study
said “funny-nose” when seeing CLOWN, which
is made by cupping the nose with one hand.
Future experiments on systematically including
mnemonics in the study phase might offer insight into another method for teaching ASL as an
L2.
The concept mediation model, explained in Altarriba and Mathis’s (1997) experiments and in
the current study, supports the practice of teaching SLA using contextual units that emphasize the
semantic or conceptual representation of a newly
acquired word. Many beginning ASL texts already
emphasize contextual learning (see, e.g., Smith
et al., 1988). Thus, assuming that the acquisition
of words in aural and visual languages is similar,
researchers can focus on how the visual modality is
mentally represented by hearing adults learning a
signed language. What is most important to keep
in mind is that bilingual research should include
oral–aural as well as visual–spatial languages, and
as the experiment in this study shows, the concept
mediation hypothesis (as well as the modifications
of the revised hierarchical model as posed by Altarriba and Mathis) applies to signed as well as to
spoken language.
</bodyText>
<page confidence="0.99875">
214
</page>
<sectionHeader confidence="0.993905" genericHeader="acknowledgments">
ACKNOWLEDGMENTS
</sectionHeader>
<bodyText confidence="0.8980845">
This research was completed as part of the requirements for the Doctor of Philosophy degree awarded to
the first author. We would like to thank Lauren Cowell
for assistance with data collection, Erik L. Olheiser and
Matthew Pastizzo for their help with programming and
analysis, and Christine Pryzbylo for her role in the development of research materials, as a native ASL signer. We
would also like to extend our gratitude to Rhoda Linton, Nancy Mardas, Elizabeth Minnich, Randall Myers,
and Janet Pray for their comments on an earlier version
of this work, as members of the first author’s Doctoral
</bodyText>
<footnote confidence="0.87266725">
Dissertation Committee.
NOTE
1 We thank an anonymous reviewer for pointing out
this issue to us in an earlier draft of the current article.
</footnote>
<sectionHeader confidence="0.961033" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.931921948051948">
Altarriba, J. (1990). Constraints on interlingual facilitation
effects in priming in Spanish–English bilinguals. Unpublished doctoral dissertation, Vanderbilt University, Nashville, TN.
Altarriba, J. (1992). The representation of translation
equivalents in bilingual memory. In R. J. Harris
(Ed.), Cognitive processing in bilinguals (pp. 157–
174). Amsterdam: Elsevier Science.
Altarriba, J. (2000). Language processing and memory retrieval in Spanish–English bilinguals. Spanish Applied Linguistics, 4, 215–245.
Altarriba, J., &amp; Mathis, M. (1997). Conceptual and
lexical development in second language acquisition. Journal of Memory and Language, 36 , 550–
568.
Bonvillian, J. D., Rea, A. C., Orlansky, M. D., &amp; Slade, L.
A. (1987). The effect of sign language rehearsal
on deaf subjects’ immediate and delayed recall of
English word lists. Applied Psycholinguistics, 8, 33–
54.
Bower, G. H., &amp; Karlin, M. B. (1974). Depth of processing pictures of faces and recognition memory. Journal of Experimental Psychology, 4, 751–
757.
Cochran, B. P., McDonald, J. L., &amp; Parault, S. J. (1999).
Too smart for their own good: The disadvantage of
a superior processing capacity for adult language
learners. Journal of Memory and Language, 41, 30–
58.
Corina, D. P., Vaid, J., &amp; Bellugi, U. (1992). The linguistic basis of left hemisphere specialization. Science,
255, 1258–1260.
Damasio, A. R., &amp; Damasio, H. (2000). Language and the
brain. In K. Emmorey &amp; H. Lane (Eds.), The signs
The Modern Language Journal 95 (2011)
of language revisited: An anthology to honor Ursula
Bellugi and Edward Klima (pp. 477–491). Mahwah,
NJ: Erlbaum.
Dijkstra, T., &amp; van Heuven, W. J. B. (1998). The
BIA model and bilingual word recognition. In J.
Grainger &amp; A. Jacobs (Eds.), Localist connectionist approaches to human cognition (pp. 189–225).
Hove, England: Erlbaum.
Emmorey, K. (2002). Language, cognition, and the brain.
Mahwah, NJ: Erlbaum.
Emmorey, K., &amp; Corina, D. (1993). Hemispheric specialization for ASL signs and English words: Differences between imageable and abstract forms.
Neuropsychologia, 31, 645–653.
Emmorey, K., Grabowski, T., McCullough, S., Damasio,
H., Ponto, L., Hichwa, R., et al. (2003). Neural systems underlying lexical retrieval for sign language.
Neuropsychologia, 41, 85–95.
Engle, R. W., Cantor, J., &amp; Turner, M. L. (1989). Modality
effects: Do they fall on deaf ears? Quarterly Journal
of Experimental Psychology A: Human Experimental
Psychology, 41, 273–292.
Fergusson, R. (1985). The Penguin rhyming dictionary.
London: Penguin Books.
Gollan, T. H., Forster, K. I., &amp; Frost, R. (1997). Translation priming with different scripts: Masked priming with cognates and noncognates in Hebrew–
English bilinguals. Journal of Experimental Psychology: Learning, Memory and Cognition, 23, 1122–
1139.
Horwitz, B., Amunts, K., Bhattacharyya, R., Patkin, D.,
Jeffries, K., Zilles, K., et al. (2003). Activation of
Broca’s area during the production of spoken and
signed language: A combined cytoarchitectonic
mapping and PET analysis. Neuropsychologia, 41,
1868–1876.
Humphries, T., Padden, C., &amp; O’Rourke, T. J. (1980).
A basic course in American Sign Language. Silver
Spring, MD: T. J. Publishers.
Kroll, J. F., &amp; Stewart, E. (1994). Category interference
in translation and picture naming: Evidence for
asymmetric connections between bilingual memory representations. Journal of Memory and Language, 33, 149–173.
Ku˘cera, H., &amp; Francis, N. W. (1967). Computational analysis of present-day American English. Providence, RI:
Brown University Press.
Larsen-Freeman, D. (2003). Teaching language: From
grammar to grammaring . Boston: Thomson-Heinle.
Liddell, S. (1984). Think and believe: Sequentiality in
American Sign Language. Language, 60, 372–398.
Potter, M. C., So, K. -F., von Eckardt, B., &amp; Feldman, L.
B. (1984). Lexical and conceptual representation
in beginning and proficient bilinguals. Journal of
Verbal Learning and Verbal Behavior , 23, 23–38.
Rosen, R. S. (2008). American Sign Language as a foreign language in U.S. high schools: State of the
art. Modern Language Journal , 92, 10–38.
Smith, C., Lentz, E. M., &amp; Mikos, K. (1988). Signing
naturally: Student workbook level 1. San Diego, CA:
DawnSign Press.
</reference>
<page confidence="0.96264">
215
</page>
<reference confidence="0.985754">
Margreta von Pein and Jeanette Altarriba
Sternberg, M. (Ed). (1994). American Sign Language dictionary (Rev. ed.). New York: Harper Perennial.
Stokoe, W. C., Casterline, D., &amp; Croneberg, C. A. (1965).
A dictionary of American Sign Language on linguistic
principles. Washington, D.C.: Gallaudet.
van Hell, J. G., &amp; Mahn, A. C. (1997). Keyword mnemonics versus rote rehearsal: Learning concrete and
abstract foreign words by experienced and inexperienced learners. Language Learning , 47 , 507–
546.
van Lier, L. (2004, March). The ecology of language learning . Paper presented at the UC Language Consortium Conference on Theoretical and Pedagogical
Perspectives, University of California, Davis.
Webster’s Compact Rhyming Dictionary. (1987). Springfield, MA: Merriam-Webster.
Wilson, M., &amp; Emmorey, K. (2003). The effects of irrelevant visual input on working memory for sign
language. Journal of Deaf Studies and Deaf Education, 8, 97–102.
</reference>
<table confidence="0.5776108">
APPENDIX A
Responses to Language History Questionnaire (n = 48)
Mean age in years
Mean self-rating (10-point scale: 1 = very little; 10 = native-like) on overall English fluency
Percentage of day English was typically spoken
Percentage of participants who had been exposed to an L2 other than English from birth
(countries of origin included Dominican Republic, India, Iran, Pakistan, and Puerto Rico)
Percentage of participants who had been exposed to an L2 other than English later in life,
primarily at school (languages included Spanish, Arabic, Hindi, and Farsi but NOT American
Sign Language or another signed language)
</table>
<page confidence="0.533666">
19.8
</page>
<figure confidence="0.993083546052632">
9.3
92.3
23
77
APPENDIX B
Posttest Interview Questions
1.
2.
3.
4.
Did you recognize any signs? What signs?
Did any of the signs look like the English meanings after you learned them? Which?
Did you see any letters in the signs? Explain.
Did you notice any relationship between the words you heard on the test and the words you learned for
the signs? Explain.
216
The Modern Language Journal 95 (2011)
APPENDIX C
Items Included in Experimental Test Conditions
Target
Unrelated
Semantic
Phonological
animal
apple
bathroom
bear
children
clown
cookie
farm
father
girl
gold
king
ice
liquor
machine
meat
mirror
movie
penny
pig
rock
school
shoe
train
signal
thigh
ceremony
spot
interest
chick
paddle
game
ground
land
hero
rose
guy
muscle
station
ring
butter
fence
beard
bum
file
number
bush
watch
dog
pie
toilet
hug
kids
circus
sweet
cow
mother
boy
silver
queen
cold
drink
car
steak
image
theater
copper
pink
hard
teacher
socks
track
minimal
chapel
classroom
fair
nation
crown
rookie
charm
bother
curl
mold
thing
price
vicar
cuisine
street
hearer
navy
jenny
fig
lock
pool
few
brain
APPENDIX D
Error Rates (Percentages) for Individual Items per Target Condition∗
Target Condition
Bear
Rock
0.520
0.520
Unrelated Condition
Chick
Hero
0.345
0.345
Semantic Condition
Kids
2.08
Phonological Condition
Fair
Bother
Fig
Crown
Nation
Hearer
Classroom
Vicar
4.23
3.31
1.88
0.479
0.479
0.479
0.479
0.479
Note. ∗ Items that are not included above were responded to accurately 100% of the time.
</figure>
</variant>
</algorithm>

<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Altarriba</author>
</authors>
<title>Constraints on interlingual facilitation effects in priming in Spanish–English bilinguals. Unpublished doctoral dissertation,</title>
<date>1990</date>
<institution>Vanderbilt University,</institution>
<location>Nashville, TN.</location>
<contexts>
<context position="3695" citStr="Altarriba, 1990" startWordPosition="558" endWordPosition="559">orthographically or semantically similar word (foils), or the correct word, the slowest response time occurred with the foils. The slower response time indicates that the novice bilinguals associated the new L2 word with the known L1 lexicon in determining the correct choice for the target word. The concept mediation hypothesis assumes that there is no direct link to the L1 lexicon, but translation of L2 occurs by accessing a common semantic store that both L1 and L2 lexicons share. Slower response time 206 The Modern Language Journal 95 (2011) FIGURE 1 Word Association Model (Reproduced from Altarriba, 1990; originally taken from Potter, So, von Eckardt, &amp; Feldman, 1984) English Cat Dog Spanish Gato Perro FIGURE 2 Concept Mediation Model (reproduced from Altarriba, 1990; originally taken from Potter et al., 1984) Lexical Level Cat (L1) Gato (L2) Conceptual Level for semantically similar words, for example, is evidence of this direct access to a conceptual store. Bilingual research empirically testing theories from second language acquisition (SLA) has not generally included data on adult acquisition of a visual–spatial L2, such as American Sign Language (ASL). No studies to date have tested the </context>
</contexts>
<marker>Altarriba, 1990</marker>
<rawString>Altarriba, J. (1990). Constraints on interlingual facilitation effects in priming in Spanish–English bilinguals. Unpublished doctoral dissertation, Vanderbilt University, Nashville, TN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Altarriba</author>
</authors>
<title>The representation of translation equivalents in bilingual memory. In</title>
<date>1992</date>
<publisher>Elsevier Science.</publisher>
<location>Amsterdam:</location>
<contexts>
<context position="9128" citStr="Altarriba, 1992" startWordPosition="1422" endWordPosition="1423">and concepts is illustrated as being weak. However, it has been suggested that this link increases in strength as the bilingual becomes more proficient or fluent in his or her L2 (a notion derived from the earlier concept mediation model). One advantage of the revised hierarchical model is that it accounts for several findings that have been reported in bilingual studies, such as faster translation in the L2–L1 direction, category interference that occurs only during L1–L2 translation (Kroll &amp; Stewart, 1994), and larger priming effects in the L1–L2 direction than in the L2–L1 direction (e.g., Altarriba, 1992; Gollan, Forster, &amp; Frost, 1997). In addition, the model attempts to show how changes in a person’s proficiency in the L2 will change the way in which lexical and conceptual information is accessed (i.e., greater proficiency in the L2 allows a greater amount of conceptual information to be available). Although this may be true to some extent, it has been argued that new words in an L2 may not be stored in just the lexicon of the L2 but rather represented as both a lexical and conceptual entry if the words were acquired in an environment in which both form and meaning were emphasized (see Alta</context>
</contexts>
<marker>Altarriba, 1992</marker>
<rawString>Altarriba, J. (1992). The representation of translation equivalents in bilingual memory. In R. J. Harris (Ed.), Cognitive processing in bilinguals (pp. 157– 174). Amsterdam: Elsevier Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Altarriba</author>
</authors>
<title>Language processing and memory retrieval in Spanish–English bilinguals.</title>
<date>2000</date>
<journal>Spanish Applied Linguistics,</journal>
<volume>4</volume>
<pages>215--245</pages>
<contexts>
<context position="10228" citStr="Altarriba, 2000" startWordPosition="1606" endWordPosition="1607">nceptual entry if the words were acquired in an environment in which both form and meaning were emphasized (see Altarriba &amp; Mathis, 1997). Further, it is possible that the conceptual aspect of some words may not be stored in a common conceptual store for both languages, simply because there are some items that may represent language-specific FIGURE 3 Revised Hierarchical Model (Adapted from Kroll &amp; Stewart, 1994) Lexical Level L2 L1 Conceptual Level Note. L1 = first language; L2 = second language. Concepts 208 concepts and, therefore, direct translations in the opposing language do not exist (Altarriba, 2000). Altarriba and Mathis (1997) questioned the revised hierarchical model of Kroll and Stewart (1994), which suggests that nonfluent bilinguals rely on lexical association early in SLA and only later on concept mediation. As mentioned earlier, Altarriba and Mathis tested Kroll and Stewart’s model with monolingual English speakers who were taught Spanish for the first time. Altarriba and Mathis designed a set of experiments to investigate the acquisition of the link between conceptual memory and the L2, hypothesizing that it could develop as early as the first encounter or first learning session </context>
</contexts>
<marker>Altarriba, 2000</marker>
<rawString>Altarriba, J. (2000). Language processing and memory retrieval in Spanish–English bilinguals. Spanish Applied Linguistics, 4, 215–245.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Altarriba</author>
<author>M Mathis</author>
</authors>
<title>Conceptual and lexical development in second language acquisition.</title>
<date>1997</date>
<journal>Journal of Memory and Language,</journal>
<volume>36</volume>
<pages>550--568</pages>
<contexts>
<context position="2780" citStr="Altarriba and Mathis (1997)" startWordPosition="414" endWordPosition="417"> words and then mediate through the conceptual store to access the L1 translations of the L2 words (as in Altarriba &amp; Mathis, 1997). The word association hypothesis assumes that there is a direct link between the L1 The Modern Language Journal, 95, ii, (2011) DOI: 10.1111/j.1540-4781.2011.01173.x 0026-7902/11/205–216 $1.50/0 C 2011 The Modern Language Journal and L2 whereby the novice bilingual associates the new L2 word with known L1 vocabulary. Thus, a novice bilingual learns a new word in the L2 by associating it with its L1 translation and then referring to a conceptual store for meaning. Altarriba and Mathis (1997) administered a timed translation recognition task to English monolingual participants who had learned a set of English– Spanish translations within the course of their experiment. When the choice offered for the correct translation pair during a subsequent test phase included an unrelated word, an orthographically or semantically similar word (foils), or the correct word, the slowest response time occurred with the foils. The slower response time indicates that the novice bilinguals associated the new L2 word with the known L1 lexicon in determining the correct choice for the target word. The</context>
<context position="7439" citStr="Altarriba and Mathis (1997)" startWordPosition="1139" endWordPosition="1142">UDY This study investigates a specific part of what adult na¨ıve learners of ASL learn when first exposed to the English equivalents of 28 simple ASL signs. The study investigates only receptive skills and the levels of representation acquired early in learning. The study is not about learning ASL itself; rather, it investigates what automatic mental representations or associations are acquired when adults unfamiliar with a visual language first “learn” the verbal translations of some signs. The theoretical models of bilingual memory representation studied by both Kroll and Stewart (1994) and Altarriba and Mathis (1997) are tested in the current study on the memory of novice students of ASL. In merging aspects of both the word association model and the concept mediation model of bilingual memory, Kroll and Stewart (1994) proposed a model (i.e., the revised hierarchical model) that describes the asymmetrical links that appear to be present in bilingual language representation as well as a model that accounts for the differences reported in the literature on translation direction (see Figure 3). This model contains mental lexicons for the L1 as well as an L2. The L1 mental lexicon is depicted as larger than th</context>
<context position="10257" citStr="Altarriba and Mathis (1997)" startWordPosition="1608" endWordPosition="1611">the words were acquired in an environment in which both form and meaning were emphasized (see Altarriba &amp; Mathis, 1997). Further, it is possible that the conceptual aspect of some words may not be stored in a common conceptual store for both languages, simply because there are some items that may represent language-specific FIGURE 3 Revised Hierarchical Model (Adapted from Kroll &amp; Stewart, 1994) Lexical Level L2 L1 Conceptual Level Note. L1 = first language; L2 = second language. Concepts 208 concepts and, therefore, direct translations in the opposing language do not exist (Altarriba, 2000). Altarriba and Mathis (1997) questioned the revised hierarchical model of Kroll and Stewart (1994), which suggests that nonfluent bilinguals rely on lexical association early in SLA and only later on concept mediation. As mentioned earlier, Altarriba and Mathis tested Kroll and Stewart’s model with monolingual English speakers who were taught Spanish for the first time. Altarriba and Mathis designed a set of experiments to investigate the acquisition of the link between conceptual memory and the L2, hypothesizing that it could develop as early as the first encounter or first learning session with the new language. Kroll </context>
<context position="2284" citStr="Altarriba &amp; Mathis, 1997" startWordPosition="337" endWordPosition="340">in bilingual memory. Over time, two hypotheses with differing views on the structure and representation of more than one language in memory have been described: a word association model and a concept mediation model (see Figures 1 and 2). The first model predicts that beginning bilinguals access second-language (L2) words via their first-language (L1) lexicon (Kroll &amp; Stewart, 1994). In contrast, the second model predicts that beginning language learners access concepts corresponding to L2 words and then mediate through the conceptual store to access the L1 translations of the L2 words (as in Altarriba &amp; Mathis, 1997). The word association hypothesis assumes that there is a direct link between the L1 The Modern Language Journal, 95, ii, (2011) DOI: 10.1111/j.1540-4781.2011.01173.x 0026-7902/11/205–216 $1.50/0 C 2011 The Modern Language Journal and L2 whereby the novice bilingual associates the new L2 word with known L1 vocabulary. Thus, a novice bilingual learns a new word in the L2 by associating it with its L1 translation and then referring to a conceptual store for meaning. Altarriba and Mathis (1997) administered a timed translation recognition task to English monolingual participants who had learned a</context>
<context position="9749" citStr="Altarriba &amp; Mathis, 1997" startWordPosition="1529" endWordPosition="1532">1992; Gollan, Forster, &amp; Frost, 1997). In addition, the model attempts to show how changes in a person’s proficiency in the L2 will change the way in which lexical and conceptual information is accessed (i.e., greater proficiency in the L2 allows a greater amount of conceptual information to be available). Although this may be true to some extent, it has been argued that new words in an L2 may not be stored in just the lexicon of the L2 but rather represented as both a lexical and conceptual entry if the words were acquired in an environment in which both form and meaning were emphasized (see Altarriba &amp; Mathis, 1997). Further, it is possible that the conceptual aspect of some words may not be stored in a common conceptual store for both languages, simply because there are some items that may represent language-specific FIGURE 3 Revised Hierarchical Model (Adapted from Kroll &amp; Stewart, 1994) Lexical Level L2 L1 Conceptual Level Note. L1 = first language; L2 = second language. Concepts 208 concepts and, therefore, direct translations in the opposing language do not exist (Altarriba, 2000). Altarriba and Mathis (1997) questioned the revised hierarchical model of Kroll and Stewart (1994), which suggests that </context>
<context position="14938" citStr="Altarriba &amp; Mathis, 1997" startWordPosition="2324" endWordPosition="2327">or correctedto-normal visual acuity and had no known hearing limitations. When they were asked before the experiment, the participants said they had no knowledge of finger spelling or ASL. Additionally, the participants were also asked about their knowledge of ASL at the conclusion of the experiment. This practice of asking participants about their language background both before and after an experiment has been used previously, as it has been found that, on occasion, the act of performing the experiment brings to mind a forgotten memory of their exposure to ASL or other languages (see, e.g., Altarriba &amp; Mathis, 1997). The participants received partial course credit. At the end of the experiment, a brief language history questionnaire was administered to ensure that they were na¨ıve to ASL. Mean self-ratings on a 10-point scale revealed native fluency in English at 9.3. Percent of the day English was spoken was 92.3. Questionnaire results revealed no exposure to, or 209 Margreta von Pein and Jeanette Altarriba knowledge of, ASL or any other signed language (see Appendices A and B). Materials Sign Selection. Twenty-eight signs were selected that abided by the following four criteria: (a) simple or monomorph</context>
<context position="33226" citStr="Altarriba &amp; Mathis, 1997" startWordPosition="5258" endWordPosition="5261">their L2 show different patterns of translation recognition for newly acquired signs. Mode or context of learning and acquisition should also be taken into account in further investigations. Thus, participants’ bilingualism may be examined as a variable of interest in future studies of sign acquisition, as this question was not a focus of the current investigation. The present study provided evidence that conceptual and phonological interference occurs in learning the meanings of ASL signs—a finding similar to that reported for the acquisition of words of a second, spoken language (see, e.g., Altarriba &amp; Mathis, 1997; van Hell &amp; Mahn, 1997). Previous ASL research evidence points to the parallel functioning of visual–spatial and oral–aural languages. For example, signs that look different from one another are identified more quickly than those that look similar to one another. This mimics the phonological similarity effect that occurs in spoken languages (see also Emmorey, 2002). In addition, Liddell (1984) illustrated how signs have beginnings, middles, and ends similar to the segments of spoken words, onsets, medial phases, and offsets. An interesting finding in the current set of results is that the err</context>
</contexts>
<marker>Altarriba, Mathis, 1997</marker>
<rawString>Altarriba, J., &amp; Mathis, M. (1997). Conceptual and lexical development in second language acquisition. Journal of Memory and Language, 36 , 550– 568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Bonvillian</author>
<author>A C Rea</author>
<author>M D Orlansky</author>
<author>L A Slade</author>
</authors>
<title>The effect of sign language rehearsal on deaf subjects’ immediate and delayed recall of English word lists.</title>
<date>1987</date>
<journal>Applied Psycholinguistics,</journal>
<volume>8</volume>
<pages>54</pages>
<contexts>
<context position="16938" citStr="Bonvillian, Rea, Orlansky, &amp; Slade, 1987" startWordPosition="2640" endWordPosition="2645"> native deaf signer was videotaped signing the list. Videotaping a native signer is the ASL equivalent to having a native English speaker say English words. The signer’s mean signing time per word was 1,260 milliseconds. The English speaker’s mean time for each word was 534 milliseconds. Therefore, it was determined that a 5,000-millsecond interval between each sign would give participants adequate time to see the sign, hear the English word, and respond as required. A 5-second interval was also the preferred elapsed time between signs in recall and recognition tests in other published works (Bonvillian, Rea, Orlansky, &amp; Slade, 1987; Bower &amp; Karlin, 1974; Cochran, McDonald, &amp; Parault, 1999). There was no sound on the videotape. Next we needed to be sure the chosen signs were not transparent. Thirty participants with no knowledge of ASL or experience with finger spelling and from the same pool as the subsequent experiment were then asked to guess the English translations for the signs. Two participants correctly guessed two different signs. These signs were eliminated from the list. This ensured that the remaining signs were not transparent—that is, their translations were not easily guessed—and, thus, these signs were us</context>
</contexts>
<marker>Bonvillian, Rea, Orlansky, Slade, 1987</marker>
<rawString>Bonvillian, J. D., Rea, A. C., Orlansky, M. D., &amp; Slade, L. A. (1987). The effect of sign language rehearsal on deaf subjects’ immediate and delayed recall of English word lists. Applied Psycholinguistics, 8, 33– 54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G H Bower</author>
<author>M B Karlin</author>
</authors>
<title>Depth of processing pictures of faces and recognition memory.</title>
<date>1974</date>
<journal>Journal of Experimental Psychology,</journal>
<volume>4</volume>
<pages>751--757</pages>
<contexts>
<context position="16960" citStr="Bower &amp; Karlin, 1974" startWordPosition="2646" endWordPosition="2649"> the list. Videotaping a native signer is the ASL equivalent to having a native English speaker say English words. The signer’s mean signing time per word was 1,260 milliseconds. The English speaker’s mean time for each word was 534 milliseconds. Therefore, it was determined that a 5,000-millsecond interval between each sign would give participants adequate time to see the sign, hear the English word, and respond as required. A 5-second interval was also the preferred elapsed time between signs in recall and recognition tests in other published works (Bonvillian, Rea, Orlansky, &amp; Slade, 1987; Bower &amp; Karlin, 1974; Cochran, McDonald, &amp; Parault, 1999). There was no sound on the videotape. Next we needed to be sure the chosen signs were not transparent. Thirty participants with no knowledge of ASL or experience with finger spelling and from the same pool as the subsequent experiment were then asked to guess the English translations for the signs. Two participants correctly guessed two different signs. These signs were eliminated from the list. This ensured that the remaining signs were not transparent—that is, their translations were not easily guessed—and, thus, these signs were used in the ensuing expe</context>
</contexts>
<marker>Bower, Karlin, 1974</marker>
<rawString>Bower, G. H., &amp; Karlin, M. B. (1974). Depth of processing pictures of faces and recognition memory. Journal of Experimental Psychology, 4, 751– 757.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B P Cochran</author>
<author>J L McDonald</author>
<author>S J Parault</author>
</authors>
<title>Too smart for their own good: The disadvantage of a superior processing capacity for adult language learners.</title>
<date>1999</date>
<journal>Journal of Memory and Language,</journal>
<volume>41</volume>
<pages>58</pages>
<contexts>
<context position="16996" citStr="Cochran, McDonald, &amp; Parault, 1999" startWordPosition="2650" endWordPosition="2654"> a native signer is the ASL equivalent to having a native English speaker say English words. The signer’s mean signing time per word was 1,260 milliseconds. The English speaker’s mean time for each word was 534 milliseconds. Therefore, it was determined that a 5,000-millsecond interval between each sign would give participants adequate time to see the sign, hear the English word, and respond as required. A 5-second interval was also the preferred elapsed time between signs in recall and recognition tests in other published works (Bonvillian, Rea, Orlansky, &amp; Slade, 1987; Bower &amp; Karlin, 1974; Cochran, McDonald, &amp; Parault, 1999). There was no sound on the videotape. Next we needed to be sure the chosen signs were not transparent. Thirty participants with no knowledge of ASL or experience with finger spelling and from the same pool as the subsequent experiment were then asked to guess the English translations for the signs. Two participants correctly guessed two different signs. These signs were eliminated from the list. This ensured that the remaining signs were not transparent—that is, their translations were not easily guessed—and, thus, these signs were used in the ensuing experiment. Creating Semantic Associates</context>
</contexts>
<marker>Cochran, McDonald, Parault, 1999</marker>
<rawString>Cochran, B. P., McDonald, J. L., &amp; Parault, S. J. (1999). Too smart for their own good: The disadvantage of a superior processing capacity for adult language learners. Journal of Memory and Language, 41, 30– 58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D P Corina</author>
<author>J Vaid</author>
<author>U Bellugi</author>
</authors>
<title>The linguistic basis of left hemisphere specialization.</title>
<date>1992</date>
<journal>Science,</journal>
<volume>255</volume>
<pages>1258--1260</pages>
<contexts>
<context position="37605" citStr="Corina, Vaid, &amp; Bellugi, 1992" startWordPosition="5921" endWordPosition="5925">hly dynamic process, and future work may focus on the acquisition of ASL signs in broader contexts of language, incorporating a more ecological approach to acquisition. In a related vein, neurological investigations into the hemispheric involvement of imageable concrete signs in ASL, as distinct from abstract lexical forms, continue to raise questions about the different roles imagery may play in ASL and English (Emmorey &amp; Corina, 1993). Most recently, neurobiological evidence also indicates that both signed and spoken languages are generally localized in the same area in the left hemisphere (Corina, Vaid, &amp; Bellugi, 1992; Damasio &amp; Dama213 sio, 2000; Emmorey et al., 2003; Horwitz et al., 2003). Notwithstanding the linguistic and neurobiological parallels between ASL and the spoken languages of the world, we recognize that the visual modality makes a distinct difference in L2 learning. The current study kept the learning challenge of ASL to a bare minimum (i.e., acquiring the English words for 28 simple signs). Nothing about sign perception was investigated. Clearly, the greater part of understanding how sign-na¨ıve adults learn ASL has to include working memory experiments on what the adult learner processes </context>
</contexts>
<marker>Corina, Vaid, Bellugi, 1992</marker>
<rawString>Corina, D. P., Vaid, J., &amp; Bellugi, U. (1992). The linguistic basis of left hemisphere specialization. Science, 255, 1258–1260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Damasio</author>
<author>H Damasio</author>
</authors>
<title>Language and the brain. In</title>
<date>2000</date>
<journal>Language Journal</journal>
<volume>95</volume>
<pages>477--491</pages>
<publisher>Erlbaum.</publisher>
<location>Mahwah, NJ:</location>
<marker>Damasio, Damasio, 2000</marker>
<rawString>Damasio, A. R., &amp; Damasio, H. (2000). Language and the brain. In K. Emmorey &amp; H. Lane (Eds.), The signs The Modern Language Journal 95 (2011) of language revisited: An anthology to honor Ursula Bellugi and Edward Klima (pp. 477–491). Mahwah, NJ: Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dijkstra</author>
<author>W J B van Heuven</author>
</authors>
<title>The BIA model and bilingual word recognition. In</title>
<date>1998</date>
<pages>189--225</pages>
<publisher>Erlbaum.</publisher>
<location>Hove, England:</location>
<marker>Dijkstra, van Heuven, 1998</marker>
<rawString>Dijkstra, T., &amp; van Heuven, W. J. B. (1998). The BIA model and bilingual word recognition. In J. Grainger &amp; A. Jacobs (Eds.), Localist connectionist approaches to human cognition (pp. 189–225). Hove, England: Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Emmorey</author>
</authors>
<title>Language, cognition, and the brain.</title>
<date>2002</date>
<publisher>Erlbaum.</publisher>
<location>Mahwah, NJ:</location>
<contexts>
<context position="5077" citStr="Emmorey, 2002" startWordPosition="769" endWordPosition="770">ates that there is tremendous growth in the study of ASL as a foreign language, particularly among secondary school students in the United States. Further, the experiments that have been carried out to examine various characteristics of the representation of ASL signs did not provide for a context in which the time allotted for the access and retrieval of a newly acquired sign was constrained, indicating the automatic processing of the sign. However, neurobiological research in ASL has confirmed that visual–spatial language processing is essentially the same as oral–aural language processing (Emmorey, 2002; Emmorey et al., 2003; Horwitz et al., 2003). The overall similarities in processing between ASL and spoken English suggest that novice ASL bilinguals may represent the new signs in the L2 via the same mechanism that functions for bilinguals learning a second spoken language. Therefore, a fundamental question remains open in this area of research study: To what extent are the memory processes involved in learning ASL signs in the context of L2 learning similar to, or different from, those involved in learning an oral–aural language? Are signs processed like words in spoken languages? The aim </context>
<context position="33594" citStr="Emmorey, 2002" startWordPosition="5315" endWordPosition="5316">t study provided evidence that conceptual and phonological interference occurs in learning the meanings of ASL signs—a finding similar to that reported for the acquisition of words of a second, spoken language (see, e.g., Altarriba &amp; Mathis, 1997; van Hell &amp; Mahn, 1997). Previous ASL research evidence points to the parallel functioning of visual–spatial and oral–aural languages. For example, signs that look different from one another are identified more quickly than those that look similar to one another. This mimics the phonological similarity effect that occurs in spoken languages (see also Emmorey, 2002). In addition, Liddell (1984) illustrated how signs have beginnings, middles, and ends similar to the segments of spoken words, onsets, medial phases, and offsets. An interesting finding in the current set of results is that the error rates were significantly higher in the phonological condition, as compared to other conditions within the experiment; that is, many more confusion errors occurred when foils were phonologically similar to the true translation. Given that the test pairs in the current case were comprised of a spoken word and a word that was signed, the implication is that the part</context>
</contexts>
<marker>Emmorey, 2002</marker>
<rawString>Emmorey, K. (2002). Language, cognition, and the brain. Mahwah, NJ: Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Emmorey</author>
<author>D Corina</author>
</authors>
<title>Hemispheric specialization for ASL signs and English words: Differences between imageable and abstract forms.</title>
<date>1993</date>
<journal>Neuropsychologia,</journal>
<volume>31</volume>
<pages>645--653</pages>
<contexts>
<context position="37416" citStr="Emmorey &amp; Corina, 1993" startWordPosition="5894" endWordPosition="5897">s that bring together aspects of reasoning, pragmatic usage, contextual influences, and the like (see, e.g., Larsen-Freeman, 2003; van Lier, 2004). Thus, language development is a highly dynamic process, and future work may focus on the acquisition of ASL signs in broader contexts of language, incorporating a more ecological approach to acquisition. In a related vein, neurological investigations into the hemispheric involvement of imageable concrete signs in ASL, as distinct from abstract lexical forms, continue to raise questions about the different roles imagery may play in ASL and English (Emmorey &amp; Corina, 1993). Most recently, neurobiological evidence also indicates that both signed and spoken languages are generally localized in the same area in the left hemisphere (Corina, Vaid, &amp; Bellugi, 1992; Damasio &amp; Dama213 sio, 2000; Emmorey et al., 2003; Horwitz et al., 2003). Notwithstanding the linguistic and neurobiological parallels between ASL and the spoken languages of the world, we recognize that the visual modality makes a distinct difference in L2 learning. The current study kept the learning challenge of ASL to a bare minimum (i.e., acquiring the English words for 28 simple signs). Nothing about</context>
</contexts>
<marker>Emmorey, Corina, 1993</marker>
<rawString>Emmorey, K., &amp; Corina, D. (1993). Hemispheric specialization for ASL signs and English words: Differences between imageable and abstract forms. Neuropsychologia, 31, 645–653.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Emmorey</author>
<author>T Grabowski</author>
<author>S McCullough</author>
<author>H Damasio</author>
<author>L Ponto</author>
<author>R Hichwa</author>
</authors>
<title>Neural systems underlying lexical retrieval for sign language.</title>
<date>2003</date>
<journal>Neuropsychologia,</journal>
<volume>41</volume>
<pages>85--95</pages>
<contexts>
<context position="5099" citStr="Emmorey et al., 2003" startWordPosition="771" endWordPosition="774"> is tremendous growth in the study of ASL as a foreign language, particularly among secondary school students in the United States. Further, the experiments that have been carried out to examine various characteristics of the representation of ASL signs did not provide for a context in which the time allotted for the access and retrieval of a newly acquired sign was constrained, indicating the automatic processing of the sign. However, neurobiological research in ASL has confirmed that visual–spatial language processing is essentially the same as oral–aural language processing (Emmorey, 2002; Emmorey et al., 2003; Horwitz et al., 2003). The overall similarities in processing between ASL and spoken English suggest that novice ASL bilinguals may represent the new signs in the L2 via the same mechanism that functions for bilinguals learning a second spoken language. Therefore, a fundamental question remains open in this area of research study: To what extent are the memory processes involved in learning ASL signs in the context of L2 learning similar to, or different from, those involved in learning an oral–aural language? Are signs processed like words in spoken languages? The aim of the current study i</context>
<context position="37656" citStr="Emmorey et al., 2003" startWordPosition="5932" endWordPosition="5935">ition of ASL signs in broader contexts of language, incorporating a more ecological approach to acquisition. In a related vein, neurological investigations into the hemispheric involvement of imageable concrete signs in ASL, as distinct from abstract lexical forms, continue to raise questions about the different roles imagery may play in ASL and English (Emmorey &amp; Corina, 1993). Most recently, neurobiological evidence also indicates that both signed and spoken languages are generally localized in the same area in the left hemisphere (Corina, Vaid, &amp; Bellugi, 1992; Damasio &amp; Dama213 sio, 2000; Emmorey et al., 2003; Horwitz et al., 2003). Notwithstanding the linguistic and neurobiological parallels between ASL and the spoken languages of the world, we recognize that the visual modality makes a distinct difference in L2 learning. The current study kept the learning challenge of ASL to a bare minimum (i.e., acquiring the English words for 28 simple signs). Nothing about sign perception was investigated. Clearly, the greater part of understanding how sign-na¨ıve adults learn ASL has to include working memory experiments on what the adult learner processes (i.e., sees, stores, attends to, recalls, etc.) in </context>
</contexts>
<marker>Emmorey, Grabowski, McCullough, Damasio, Ponto, Hichwa, 2003</marker>
<rawString>Emmorey, K., Grabowski, T., McCullough, S., Damasio, H., Ponto, L., Hichwa, R., et al. (2003). Neural systems underlying lexical retrieval for sign language. Neuropsychologia, 41, 85–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Engle</author>
<author>J Cantor</author>
<author>M L Turner</author>
</authors>
<title>Modality effects: Do they fall on deaf ears?</title>
<date>1989</date>
<journal>Quarterly Journal of Experimental Psychology A: Human Experimental Psychology,</journal>
<volume>41</volume>
<pages>273--292</pages>
<contexts>
<context position="35383" citStr="Engle, Cantor, &amp; Turner, 1989" startWordPosition="5588" endWordPosition="5592">ved in the process of understanding newly acquired concepts in an L2—even if it is a signed language. Further, the current data underscore the basic finding in the literature that many auditory confusion errors are Margreta von Pein and Jeanette Altarriba derived from words that have phonological overlap and share either place of articulation or manner of articulation, or both. The fact that these phonological representations in the current study stem from the recognition of a signed word is interesting evidence to suggest that phonological confusion errors are not modality-specific (see also Engle, Cantor, &amp; Turner, 1989, for a related discussion). Although the current study examined translation recognition for newly acquired signs and their English translations, the participants performed a learning task that by its very nature emphasized the phonological and semantic aspects of the association between the English word and its corresponding sign. Although the participants developed these new representations such that they achieved 100% accuracy on a test of their knowledge, it is unclear to what extent different participants might have engaged in their own strategies in learning the signs of interest. Clearl</context>
</contexts>
<marker>Engle, Cantor, Turner, 1989</marker>
<rawString>Engle, R. W., Cantor, J., &amp; Turner, M. L. (1989). Modality effects: Do they fall on deaf ears? Quarterly Journal of Experimental Psychology A: Human Experimental Psychology, 41, 273–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Fergusson</author>
</authors>
<title>The Penguin rhyming dictionary.</title>
<date>1985</date>
<publisher>Penguin Books.</publisher>
<location>London:</location>
<contexts>
<context position="19310" citStr="Fergusson, 1985" startWordPosition="3024" endWordPosition="3025">deotaped signs); (b) words unrelated to the target words; (c) words semantically related to the target words; and (d) words phonologically related to the target words. The unrelated items were made up of words of approximately the same length and frequency as the signs’ English equivalents (Ku˘cera &amp; Francis, 1967). Mean word length and mean word frequency for the words in all four conditions are listed in Table 1. t-Tests indicated no significant differences across conditions for either frequency or length (all ps &amp;gt; .05). The phonologically related condition was constructed of rhyming words (Fergusson, 1985; Webster’s, 1987). Sample stimulus items include the following: Targets: apple, cookie; Unrelated: thigh, paddle; Semantic TABLE 1 Word Length and Frequency Means and Standard Deviation for Four Test Conditions Condition Means SD Length Target Unrelated Semantic Phonological 5.08 5.08 4.71 5.21 Target Unrelated Semantic Phonological 90.29 88.75 77.79 83.33 1.38 1.38 1.30 1.35 Frequency 117.95 112.43 81.96 136.50 210 Foil: pie, sweet; Phonological Foil: chapel, rookie. Thus, the words that corresponded to the target “apple” in each condition included “thigh,” “pie,” and “chapel.” The set can b</context>
</contexts>
<marker>Fergusson, 1985</marker>
<rawString>Fergusson, R. (1985). The Penguin rhyming dictionary. London: Penguin Books.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T H Gollan</author>
<author>K I Forster</author>
<author>R Frost</author>
</authors>
<title>Translation priming with different scripts: Masked priming with cognates and noncognates in Hebrew– English bilinguals.</title>
<date>1997</date>
<journal>Journal of Experimental Psychology: Learning, Memory and Cognition,</journal>
<volume>23</volume>
<pages>1122--1139</pages>
<contexts>
<context position="9160" citStr="Gollan, Forster, &amp; Frost, 1997" startWordPosition="1424" endWordPosition="1428">llustrated as being weak. However, it has been suggested that this link increases in strength as the bilingual becomes more proficient or fluent in his or her L2 (a notion derived from the earlier concept mediation model). One advantage of the revised hierarchical model is that it accounts for several findings that have been reported in bilingual studies, such as faster translation in the L2–L1 direction, category interference that occurs only during L1–L2 translation (Kroll &amp; Stewart, 1994), and larger priming effects in the L1–L2 direction than in the L2–L1 direction (e.g., Altarriba, 1992; Gollan, Forster, &amp; Frost, 1997). In addition, the model attempts to show how changes in a person’s proficiency in the L2 will change the way in which lexical and conceptual information is accessed (i.e., greater proficiency in the L2 allows a greater amount of conceptual information to be available). Although this may be true to some extent, it has been argued that new words in an L2 may not be stored in just the lexicon of the L2 but rather represented as both a lexical and conceptual entry if the words were acquired in an environment in which both form and meaning were emphasized (see Altarriba &amp; Mathis, 1997). Further, </context>
</contexts>
<marker>Gollan, Forster, Frost, 1997</marker>
<rawString>Gollan, T. H., Forster, K. I., &amp; Frost, R. (1997). Translation priming with different scripts: Masked priming with cognates and noncognates in Hebrew– English bilinguals. Journal of Experimental Psychology: Learning, Memory and Cognition, 23, 1122– 1139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Horwitz</author>
<author>K Amunts</author>
<author>R Bhattacharyya</author>
<author>D Patkin</author>
<author>K Jeffries</author>
<author>K Zilles</author>
</authors>
<title>Activation of Broca’s area during the production of spoken and signed language: A combined cytoarchitectonic mapping and PET analysis.</title>
<date>2003</date>
<journal>Neuropsychologia,</journal>
<volume>41</volume>
<pages>1868--1876</pages>
<contexts>
<context position="5122" citStr="Horwitz et al., 2003" startWordPosition="775" endWordPosition="778">in the study of ASL as a foreign language, particularly among secondary school students in the United States. Further, the experiments that have been carried out to examine various characteristics of the representation of ASL signs did not provide for a context in which the time allotted for the access and retrieval of a newly acquired sign was constrained, indicating the automatic processing of the sign. However, neurobiological research in ASL has confirmed that visual–spatial language processing is essentially the same as oral–aural language processing (Emmorey, 2002; Emmorey et al., 2003; Horwitz et al., 2003). The overall similarities in processing between ASL and spoken English suggest that novice ASL bilinguals may represent the new signs in the L2 via the same mechanism that functions for bilinguals learning a second spoken language. Therefore, a fundamental question remains open in this area of research study: To what extent are the memory processes involved in learning ASL signs in the context of L2 learning similar to, or different from, those involved in learning an oral–aural language? Are signs processed like words in spoken languages? The aim of the current study is threefold. First and </context>
<context position="37679" citStr="Horwitz et al., 2003" startWordPosition="5936" endWordPosition="5939">broader contexts of language, incorporating a more ecological approach to acquisition. In a related vein, neurological investigations into the hemispheric involvement of imageable concrete signs in ASL, as distinct from abstract lexical forms, continue to raise questions about the different roles imagery may play in ASL and English (Emmorey &amp; Corina, 1993). Most recently, neurobiological evidence also indicates that both signed and spoken languages are generally localized in the same area in the left hemisphere (Corina, Vaid, &amp; Bellugi, 1992; Damasio &amp; Dama213 sio, 2000; Emmorey et al., 2003; Horwitz et al., 2003). Notwithstanding the linguistic and neurobiological parallels between ASL and the spoken languages of the world, we recognize that the visual modality makes a distinct difference in L2 learning. The current study kept the learning challenge of ASL to a bare minimum (i.e., acquiring the English words for 28 simple signs). Nothing about sign perception was investigated. Clearly, the greater part of understanding how sign-na¨ıve adults learn ASL has to include working memory experiments on what the adult learner processes (i.e., sees, stores, attends to, recalls, etc.) in the visual modality (se</context>
</contexts>
<marker>Horwitz, Amunts, Bhattacharyya, Patkin, Jeffries, Zilles, 2003</marker>
<rawString>Horwitz, B., Amunts, K., Bhattacharyya, R., Patkin, D., Jeffries, K., Zilles, K., et al. (2003). Activation of Broca’s area during the production of spoken and signed language: A combined cytoarchitectonic mapping and PET analysis. Neuropsychologia, 41, 1868–1876.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Humphries</author>
<author>C Padden</author>
<author>T J O’Rourke</author>
</authors>
<title>A basic course in American Sign Language. Silver Spring, MD:</title>
<date>1980</date>
<journal>T. J. Publishers.</journal>
<marker>Humphries, Padden, O’Rourke, 1980</marker>
<rawString>Humphries, T., Padden, C., &amp; O’Rourke, T. J. (1980). A basic course in American Sign Language. Silver Spring, MD: T. J. Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Kroll</author>
<author>E Stewart</author>
</authors>
<title>Category interference in translation and picture naming: Evidence for asymmetric connections between bilingual memory representations.</title>
<date>1994</date>
<journal>Journal of Memory and Language,</journal>
<volume>33</volume>
<pages>149--173</pages>
<contexts>
<context position="6647" citStr="Kroll and Stewart (1994)" startWordPosition="1016" endWordPosition="1019">learning ASL as an L2. Second, the work is aimed at investigating the representation in memory of newly acquired signs under situations that would promote the automaticity of the access of that information. Using an interference paradigm that will be described later, it was possible to determine whether 207 Margreta von Pein and Jeanette Altarriba semantic or phonological information was encoded early in the learning of ASL signs without the possibility of elaborative processes that can be engaged in untimed response tasks. Third, the present work is aimed at testing a hypothesis put forth by Kroll and Stewart (1994) regarding the conceptual or semantic development that occurs when one first learns an L2. More will be said about this final aim in the next section. THE CURRENT STUDY This study investigates a specific part of what adult na¨ıve learners of ASL learn when first exposed to the English equivalents of 28 simple ASL signs. The study investigates only receptive skills and the levels of representation acquired early in learning. The study is not about learning ASL itself; rather, it investigates what automatic mental representations or associations are acquired when adults unfamiliar with a visual </context>
<context position="10327" citStr="Kroll and Stewart (1994)" startWordPosition="1618" endWordPosition="1621">were emphasized (see Altarriba &amp; Mathis, 1997). Further, it is possible that the conceptual aspect of some words may not be stored in a common conceptual store for both languages, simply because there are some items that may represent language-specific FIGURE 3 Revised Hierarchical Model (Adapted from Kroll &amp; Stewart, 1994) Lexical Level L2 L1 Conceptual Level Note. L1 = first language; L2 = second language. Concepts 208 concepts and, therefore, direct translations in the opposing language do not exist (Altarriba, 2000). Altarriba and Mathis (1997) questioned the revised hierarchical model of Kroll and Stewart (1994), which suggests that nonfluent bilinguals rely on lexical association early in SLA and only later on concept mediation. As mentioned earlier, Altarriba and Mathis tested Kroll and Stewart’s model with monolingual English speakers who were taught Spanish for the first time. Altarriba and Mathis designed a set of experiments to investigate the acquisition of the link between conceptual memory and the L2, hypothesizing that it could develop as early as the first encounter or first learning session with the new language. Kroll and Stewart had claimed that this link developed over an unspecified l</context>
<context position="31191" citStr="Kroll and Stewart (1994)" startWordPosition="4929" endWordPosition="4932">the ASL signs confirmed that L2 (ASL) conceptual processing (as well as phonological processing of the English translation equivalents) is involved very early in the language acquisition process. Both semantic and phonological interference effects were reported within the current study. It can be assumed, then, that the processes involved in acquiring an L2 as described by Altarriba and Mathis also come into play for adult novices learning a visual language as the L2. Moreover, as reported by Altarriba and Mathis, the current work also indicates that the revised hierarchical model proposed by Kroll and Stewart (1994) should be modified to indicate that conceptual/semantic information can be acquired in the earliest stages of L2 learning. In other words, even after a single learning session, individuals can acquire the knowledge of the meaning of newly learned L2 words—a link that had been purported to take more time to develop, as per the revised hierarchical model. In relation to the above issues of acquisition and development, note that all of the participants in the current study had been exposed to an L2 at some point in their lives (either from birth or through schooling in later years; see Appendix </context>
<context position="2044" citStr="Kroll &amp; Stewart, 1994" startWordPosition="299" endWordPosition="302">ns after a single learning session. Results are discussed with regard to bilingual memory representations as well as to ASL acquisition. THIS STUDY BUILDS ON THE RESEARCH ON the development of various levels of linguistic representation in bilingual memory. Over time, two hypotheses with differing views on the structure and representation of more than one language in memory have been described: a word association model and a concept mediation model (see Figures 1 and 2). The first model predicts that beginning bilinguals access second-language (L2) words via their first-language (L1) lexicon (Kroll &amp; Stewart, 1994). In contrast, the second model predicts that beginning language learners access concepts corresponding to L2 words and then mediate through the conceptual store to access the L1 translations of the L2 words (as in Altarriba &amp; Mathis, 1997). The word association hypothesis assumes that there is a direct link between the L1 The Modern Language Journal, 95, ii, (2011) DOI: 10.1111/j.1540-4781.2011.01173.x 0026-7902/11/205–216 $1.50/0 C 2011 The Modern Language Journal and L2 whereby the novice bilingual associates the new L2 word with known L1 vocabulary. Thus, a novice bilingual learns a new wo</context>
<context position="9026" citStr="Kroll &amp; Stewart, 1994" startWordPosition="1404" endWordPosition="1407">f the L1 (an idea emerging from the original word association model). Finally, the connection between the L2 and concepts is illustrated as being weak. However, it has been suggested that this link increases in strength as the bilingual becomes more proficient or fluent in his or her L2 (a notion derived from the earlier concept mediation model). One advantage of the revised hierarchical model is that it accounts for several findings that have been reported in bilingual studies, such as faster translation in the L2–L1 direction, category interference that occurs only during L1–L2 translation (Kroll &amp; Stewart, 1994), and larger priming effects in the L1–L2 direction than in the L2–L1 direction (e.g., Altarriba, 1992; Gollan, Forster, &amp; Frost, 1997). In addition, the model attempts to show how changes in a person’s proficiency in the L2 will change the way in which lexical and conceptual information is accessed (i.e., greater proficiency in the L2 allows a greater amount of conceptual information to be available). Although this may be true to some extent, it has been argued that new words in an L2 may not be stored in just the lexicon of the L2 but rather represented as both a lexical and conceptual entry</context>
</contexts>
<marker>Kroll, Stewart, 1994</marker>
<rawString>Kroll, J. F., &amp; Stewart, E. (1994). Category interference in translation and picture naming: Evidence for asymmetric connections between bilingual memory representations. Journal of Memory and Language, 33, 149–173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ku˘cera</author>
<author>N W Francis</author>
</authors>
<title>Computational analysis of present-day American English.</title>
<date>1967</date>
<publisher>Brown University Press.</publisher>
<location>Providence, RI:</location>
<marker>Ku˘cera, Francis, 1967</marker>
<rawString>Ku˘cera, H., &amp; Francis, N. W. (1967). Computational analysis of present-day American English. Providence, RI: Brown University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Larsen-Freeman</author>
</authors>
<title>Teaching language: From grammar to grammaring .</title>
<date>2003</date>
<location>Boston: Thomson-Heinle.</location>
<contexts>
<context position="36922" citStr="Larsen-Freeman, 2003" startWordPosition="5821" endWordPosition="5822">y instructions so as to either document the means by which participants actively learn signs or provide concrete instructions as to the types of strategies that should be used (e.g., imagery, context availability) so as to investigate the influence of learning strategy on the ultimate representation of new signs.1 Moreover, it is important to note here that although the current work focused on the learning of ASL signs, the learning of language, in general, encompasses many more elements that bring together aspects of reasoning, pragmatic usage, contextual influences, and the like (see, e.g., Larsen-Freeman, 2003; van Lier, 2004). Thus, language development is a highly dynamic process, and future work may focus on the acquisition of ASL signs in broader contexts of language, incorporating a more ecological approach to acquisition. In a related vein, neurological investigations into the hemispheric involvement of imageable concrete signs in ASL, as distinct from abstract lexical forms, continue to raise questions about the different roles imagery may play in ASL and English (Emmorey &amp; Corina, 1993). Most recently, neurobiological evidence also indicates that both signed and spoken languages are general</context>
</contexts>
<marker>Larsen-Freeman, 2003</marker>
<rawString>Larsen-Freeman, D. (2003). Teaching language: From grammar to grammaring . Boston: Thomson-Heinle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Liddell</author>
</authors>
<title>Think and believe: Sequentiality in</title>
<date>1984</date>
<journal>American Sign Language. Language,</journal>
<volume>60</volume>
<pages>372--398</pages>
<contexts>
<context position="33623" citStr="Liddell (1984)" startWordPosition="5319" endWordPosition="5320">t conceptual and phonological interference occurs in learning the meanings of ASL signs—a finding similar to that reported for the acquisition of words of a second, spoken language (see, e.g., Altarriba &amp; Mathis, 1997; van Hell &amp; Mahn, 1997). Previous ASL research evidence points to the parallel functioning of visual–spatial and oral–aural languages. For example, signs that look different from one another are identified more quickly than those that look similar to one another. This mimics the phonological similarity effect that occurs in spoken languages (see also Emmorey, 2002). In addition, Liddell (1984) illustrated how signs have beginnings, middles, and ends similar to the segments of spoken words, onsets, medial phases, and offsets. An interesting finding in the current set of results is that the error rates were significantly higher in the phonological condition, as compared to other conditions within the experiment; that is, many more confusion errors occurred when foils were phonologically similar to the true translation. Given that the test pairs in the current case were comprised of a spoken word and a word that was signed, the implication is that the participants accessed the phonolo</context>
</contexts>
<marker>Liddell, 1984</marker>
<rawString>Liddell, S. (1984). Think and believe: Sequentiality in American Sign Language. Language, 60, 372–398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C Potter</author>
<author>K -F So</author>
<author>B von Eckardt</author>
<author>L B Feldman</author>
</authors>
<title>Lexical and conceptual representation in beginning and proficient bilinguals.</title>
<date>1984</date>
<journal>Journal of Verbal Learning and Verbal Behavior ,</journal>
<volume>23</volume>
<pages>23--38</pages>
<marker>Potter, So, von Eckardt, Feldman, 1984</marker>
<rawString>Potter, M. C., So, K. -F., von Eckardt, B., &amp; Feldman, L. B. (1984). Lexical and conceptual representation in beginning and proficient bilinguals. Journal of Verbal Learning and Verbal Behavior , 23, 23–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S Rosen</author>
</authors>
<title>American Sign Language as a foreign language in U.S. high schools: State of the art.</title>
<date>2008</date>
<journal>Modern Language Journal ,</journal>
<volume>92</volume>
<pages>10--38</pages>
<contexts>
<context position="4458" citStr="Rosen (2008)" startWordPosition="676" endWordPosition="677">Altarriba, 1990; originally taken from Potter et al., 1984) Lexical Level Cat (L1) Gato (L2) Conceptual Level for semantically similar words, for example, is evidence of this direct access to a conceptual store. Bilingual research empirically testing theories from second language acquisition (SLA) has not generally included data on adult acquisition of a visual–spatial L2, such as American Sign Language (ASL). No studies to date have tested the acquisition of ASL signs by na¨ıve learners using a timed procedure that captures the implicit learning of those signs, even though a recent review by Rosen (2008) indicates that there is tremendous growth in the study of ASL as a foreign language, particularly among secondary school students in the United States. Further, the experiments that have been carried out to examine various characteristics of the representation of ASL signs did not provide for a context in which the time allotted for the access and retrieval of a newly acquired sign was constrained, indicating the automatic processing of the sign. However, neurobiological research in ASL has confirmed that visual–spatial language processing is essentially the same as oral–aural language proces</context>
</contexts>
<marker>Rosen, 2008</marker>
<rawString>Rosen, R. S. (2008). American Sign Language as a foreign language in U.S. high schools: State of the art. Modern Language Journal , 92, 10–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Smith</author>
<author>E M Lentz</author>
<author>K Mikos</author>
</authors>
<title>Signing naturally: Student workbook level 1.</title>
<date>1988</date>
<publisher>DawnSign Press.</publisher>
<location>San Diego, CA:</location>
<contexts>
<context position="15820" citStr="Smith, Lentz, &amp; Mikos, 1988" startWordPosition="2461" endWordPosition="2465">3. Percent of the day English was spoken was 92.3. Questionnaire results revealed no exposure to, or 209 Margreta von Pein and Jeanette Altarriba knowledge of, ASL or any other signed language (see Appendices A and B). Materials Sign Selection. Twenty-eight signs were selected that abided by the following four criteria: (a) simple or monomorphemic, (b) frequently used, (c) visually dissimilar from each another, and (d) not transparent. We relied on two beginning ASL teaching texts and two ASL dictionaries as the source for simple and frequently used signs (Humphries, Padden, &amp; O’Rourke, 1980; Smith, Lentz, &amp; Mikos, 1988; Sternberg, 1994; Stokoe, Casterline, &amp; Croneberg, 1965). We wanted to select a list of signs that were completely distinct from one another in terms of all parameters, including movement, shape, and position. In other words, if two signs varied from each other on a single parameter, we excluded those items from our final list of signs. This ensured that the signs on the list were visually dissimilar. The English translations of signs on the list were all concrete nouns. A native deaf signer was videotaped signing the list. Videotaping a native signer is the ASL equivalent to having a native </context>
<context position="39604" citStr="Smith et al., 1988" startWordPosition="6228" endWordPosition="6231">ead. Another participant during the study said “funny-nose” when seeing CLOWN, which is made by cupping the nose with one hand. Future experiments on systematically including mnemonics in the study phase might offer insight into another method for teaching ASL as an L2. The concept mediation model, explained in Altarriba and Mathis’s (1997) experiments and in the current study, supports the practice of teaching SLA using contextual units that emphasize the semantic or conceptual representation of a newly acquired word. Many beginning ASL texts already emphasize contextual learning (see, e.g., Smith et al., 1988). Thus, assuming that the acquisition of words in aural and visual languages is similar, researchers can focus on how the visual modality is mentally represented by hearing adults learning a signed language. What is most important to keep in mind is that bilingual research should include oral–aural as well as visual–spatial languages, and as the experiment in this study shows, the concept mediation hypothesis (as well as the modifications of the revised hierarchical model as posed by Altarriba and Mathis) applies to signed as well as to spoken language. 214 ACKNOWLEDGMENTS This research was co</context>
</contexts>
<marker>Smith, Lentz, Mikos, 1988</marker>
<rawString>Smith, C., Lentz, E. M., &amp; Mikos, K. (1988). Signing naturally: Student workbook level 1. San Diego, CA: DawnSign Press.</rawString>
</citation>
<citation valid="true">
<date>1994</date>
<journal>American Sign Language</journal>
<editor>Margreta von Pein and Jeanette Altarriba Sternberg, M. (Ed).</editor>
<publisher>Harper Perennial.</publisher>
<location>New York:</location>
<contexts>
<context position="6647" citStr="(1994)" startWordPosition="1019" endWordPosition="1019"> L2. Second, the work is aimed at investigating the representation in memory of newly acquired signs under situations that would promote the automaticity of the access of that information. Using an interference paradigm that will be described later, it was possible to determine whether 207 Margreta von Pein and Jeanette Altarriba semantic or phonological information was encoded early in the learning of ASL signs without the possibility of elaborative processes that can be engaged in untimed response tasks. Third, the present work is aimed at testing a hypothesis put forth by Kroll and Stewart (1994) regarding the conceptual or semantic development that occurs when one first learns an L2. More will be said about this final aim in the next section. THE CURRENT STUDY This study investigates a specific part of what adult na¨ıve learners of ASL learn when first exposed to the English equivalents of 28 simple ASL signs. The study investigates only receptive skills and the levels of representation acquired early in learning. The study is not about learning ASL itself; rather, it investigates what automatic mental representations or associations are acquired when adults unfamiliar with a visual </context>
<context position="10327" citStr="(1994)" startWordPosition="1621" endWordPosition="1621">ee Altarriba &amp; Mathis, 1997). Further, it is possible that the conceptual aspect of some words may not be stored in a common conceptual store for both languages, simply because there are some items that may represent language-specific FIGURE 3 Revised Hierarchical Model (Adapted from Kroll &amp; Stewart, 1994) Lexical Level L2 L1 Conceptual Level Note. L1 = first language; L2 = second language. Concepts 208 concepts and, therefore, direct translations in the opposing language do not exist (Altarriba, 2000). Altarriba and Mathis (1997) questioned the revised hierarchical model of Kroll and Stewart (1994), which suggests that nonfluent bilinguals rely on lexical association early in SLA and only later on concept mediation. As mentioned earlier, Altarriba and Mathis tested Kroll and Stewart’s model with monolingual English speakers who were taught Spanish for the first time. Altarriba and Mathis designed a set of experiments to investigate the acquisition of the link between conceptual memory and the L2, hypothesizing that it could develop as early as the first encounter or first learning session with the new language. Kroll and Stewart had claimed that this link developed over an unspecified l</context>
<context position="31191" citStr="(1994)" startWordPosition="4932" endWordPosition="4932">irmed that L2 (ASL) conceptual processing (as well as phonological processing of the English translation equivalents) is involved very early in the language acquisition process. Both semantic and phonological interference effects were reported within the current study. It can be assumed, then, that the processes involved in acquiring an L2 as described by Altarriba and Mathis also come into play for adult novices learning a visual language as the L2. Moreover, as reported by Altarriba and Mathis, the current work also indicates that the revised hierarchical model proposed by Kroll and Stewart (1994) should be modified to indicate that conceptual/semantic information can be acquired in the earliest stages of L2 learning. In other words, even after a single learning session, individuals can acquire the knowledge of the meaning of newly learned L2 words—a link that had been purported to take more time to develop, as per the revised hierarchical model. In relation to the above issues of acquisition and development, note that all of the participants in the current study had been exposed to an L2 at some point in their lives (either from birth or through schooling in later years; see Appendix </context>
</contexts>
<marker>1994</marker>
<rawString>Margreta von Pein and Jeanette Altarriba Sternberg, M. (Ed). (1994). American Sign Language dictionary (Rev. ed.). New York: Harper Perennial.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Stokoe</author>
<author>D Casterline</author>
<author>C A Croneberg</author>
</authors>
<title>A dictionary of American Sign Language on linguistic principles.</title>
<date>1965</date>
<publisher>Gallaudet.</publisher>
<location>Washington, D.C.:</location>
<contexts>
<context position="15876" citStr="Stokoe, Casterline, &amp; Croneberg, 1965" startWordPosition="2468" endWordPosition="2472">2.3. Questionnaire results revealed no exposure to, or 209 Margreta von Pein and Jeanette Altarriba knowledge of, ASL or any other signed language (see Appendices A and B). Materials Sign Selection. Twenty-eight signs were selected that abided by the following four criteria: (a) simple or monomorphemic, (b) frequently used, (c) visually dissimilar from each another, and (d) not transparent. We relied on two beginning ASL teaching texts and two ASL dictionaries as the source for simple and frequently used signs (Humphries, Padden, &amp; O’Rourke, 1980; Smith, Lentz, &amp; Mikos, 1988; Sternberg, 1994; Stokoe, Casterline, &amp; Croneberg, 1965). We wanted to select a list of signs that were completely distinct from one another in terms of all parameters, including movement, shape, and position. In other words, if two signs varied from each other on a single parameter, we excluded those items from our final list of signs. This ensured that the signs on the list were visually dissimilar. The English translations of signs on the list were all concrete nouns. A native deaf signer was videotaped signing the list. Videotaping a native signer is the ASL equivalent to having a native English speaker say English words. The signer’s mean sig</context>
</contexts>
<marker>Stokoe, Casterline, Croneberg, 1965</marker>
<rawString>Stokoe, W. C., Casterline, D., &amp; Croneberg, C. A. (1965). A dictionary of American Sign Language on linguistic principles. Washington, D.C.: Gallaudet.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G van Hell</author>
<author>A C Mahn</author>
</authors>
<title>Keyword mnemonics versus rote rehearsal: Learning concrete and abstract foreign words by experienced and inexperienced learners.</title>
<date>1997</date>
<journal>Language Learning , 47 ,</journal>
<volume>507</volume>
<pages>546</pages>
<marker>van Hell, Mahn, 1997</marker>
<rawString>van Hell, J. G., &amp; Mahn, A. C. (1997). Keyword mnemonics versus rote rehearsal: Learning concrete and abstract foreign words by experienced and inexperienced learners. Language Learning , 47 , 507– 546.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L van Lier</author>
</authors>
<title>The ecology of language learning . Paper presented at the UC Language Consortium Conference on Theoretical and Pedagogical Perspectives,</title>
<date>2004</date>
<location>University of California, Davis.</location>
<marker>van Lier, 2004</marker>
<rawString>van Lier, L. (2004, March). The ecology of language learning . Paper presented at the UC Language Consortium Conference on Theoretical and Pedagogical Perspectives, University of California, Davis.</rawString>
</citation>
<citation valid="true">
<title>Webster’s Compact Rhyming Dictionary.</title>
<date>1987</date>
<publisher>Merriam-Webster.</publisher>
<location>Springfield, MA:</location>
<marker>1987</marker>
<rawString>Webster’s Compact Rhyming Dictionary. (1987). Springfield, MA: Merriam-Webster.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wilson</author>
<author>K Emmorey</author>
</authors>
<title>The effects of irrelevant visual input on working memory for sign language.</title>
<date>2003</date>
<journal>Journal of Deaf Studies and Deaf Education,</journal>
<volume>8</volume>
<pages>97--102</pages>
<contexts>
<context position="38311" citStr="Wilson &amp; Emmorey, 2003" startWordPosition="6032" endWordPosition="6035">standing the linguistic and neurobiological parallels between ASL and the spoken languages of the world, we recognize that the visual modality makes a distinct difference in L2 learning. The current study kept the learning challenge of ASL to a bare minimum (i.e., acquiring the English words for 28 simple signs). Nothing about sign perception was investigated. Clearly, the greater part of understanding how sign-na¨ıve adults learn ASL has to include working memory experiments on what the adult learner processes (i.e., sees, stores, attends to, recalls, etc.) in the visual modality (see, e.g., Wilson &amp; Emmorey, 2003). Experiments on reproducing ASL signs are recommended, as well as experiments with ASL units longer than primarily single monomorphemic signs. When we analyzed the ways the participants remembered the English meanings during the study phase of the present experiment, another potential area of research became clear. Although the participants studied the English meanings for the signs in the learning part of the experiment, we informally noted evident mnemonics used by two participants, each for a single word. For example, one participant said “father-head” while hearing the word “father” and v</context>
</contexts>
<marker>Wilson, Emmorey, 2003</marker>
<rawString>Wilson, M., &amp; Emmorey, K. (2003). The effects of irrelevant visual input on working memory for sign language. Journal of Deaf Studies and Deaf Education, 8, 97–102.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>