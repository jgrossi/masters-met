<article>
  <front>
    <journal-meta>
      <journal-title-group>
        <journal-title>The Modern Language Journal</journal-title>
      </journal-title-group>
    </journal-meta>
    <article-meta>
      <title-group>
        <article-title>Testing the Development of Linguistic Knowledge in Adult Na¨ıve Learners of American Sign Language</article-title>
      </title-group>
      <article-id pub-id-type="doi">10.1111/j.1540-4781.2011.01173.x</article-id>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>MARGRETA VON PEIN</string-name>
          <email>Email: mvpein@yahoo.com</email>
          <xref ref-type="aff" rid="0">0</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>JEANETTE ALTARRIBA</string-name>
          <email>Email: ja087@albany.edu</email>
          <xref ref-type="aff" rid="1">1</xref>
        </contrib>
        <aff id="0">
          <label>0</label>
          <institution>Union Institute &amp; University</institution>
          ,
          <addr-line>Cincinnati, Ohio and</addr-line>
          ,
          <institution>University at Albany, State University of New York, Department of Psychology</institution>
          ,
          <addr-line>1400 Washington Avenue, Albany, NY 12222</addr-line>
        </aff>
        <aff id="1">
          <label>1</label>
          <institution>University at Albany, State University of New York, Department of Psychology</institution>
          ,
          <addr-line>1400 Washington Avenue, Albany, NY 12222</addr-line>
        </aff>
      </contrib-group>
      <abstract>
        <p>The present study was designed to investigate the ways in which notions of semantics and phonology are acquired by adult na¨ıve learners of American Sign Language (ASL) when they are first exposed to a set of simple signs. First, a set of ASL signs was tested for nontransparency and a set of signs was selected for subsequent use. Next, a set of semantically related English words and a set of phonologically related English words were generated and paired with each of the signs selected earlier. In the experiment reported here, participants were taught pairs of sign-English word translations. Subsequently, they were then engaged in a translation recognition task in which foils were semantically related, phonologically related, or completely unrelated to the corresponding translations. Interference in performing the recognition task (i.e., the foil conditions) indicated that participants had encoded various features of the signword combinations after a single learning session. Results are discussed with regard to bilingual memory representations as well as to ASL acquisition.</p>
      </abstract>
      <volume>95</volume>
      <issue>2011</issue>
      <fpage>205</fpage>
      <lpage>216</lpage>
      <pub-date>
        <year>2011</year>
      </pub-date>
    </article-meta>
  </front>
  <body>
    <sec id="1">
      <title>-</title>
      <p>and L2 whereby the novice bilingual associates the
new L2 word with known L1 vocabulary. Thus, a
novice bilingual learns a new word in the L2 by
associating it with its L1 translation and then
referring to a conceptual store for meaning. Altarriba
and Mathis (1997) administered a timed
translation recognition task to English monolingual
participants who had learned a set of English–
Spanish translations within the course of their
experiment. When the choice offered for the correct
translation pair during a subsequent test phase
included an unrelated word, an orthographically
or semantically similar word (foils), or the correct
word, the slowest response time occurred with the
foils. The slower response time indicates that the
novice bilinguals associated the new L2 word with
the known L1 lexicon in determining the correct
choice for the target word. The concept mediation
hypothesis assumes that there is no direct link
to the L1 lexicon, but translation of L2 occurs
by accessing a common semantic store that both
L1 and L2 lexicons share. Slower response time
for semantically similar words, for example, is
evidence of this direct access to a conceptual store.</p>
      <p>Bilingual research empirically testing theories
from second language acquisition (SLA) has not
generally included data on adult acquisition of
a visual–spatial L2, such as American Sign
Language (ASL). No studies to date have tested the
acquisition of ASL signs by na¨ıve learners using a
timed procedure that captures the implicit
learning of those signs, even though a recent review by
Rosen (2008) indicates that there is tremendous
growth in the study of ASL as a foreign language,
particularly among secondary school students in
the United States. Further, the experiments that
have been carried out to examine various
characteristics of the representation of ASL signs did not
provide for a context in which the time allotted for
the access and retrieval of a newly acquired sign
was constrained, indicating the automatic
processing of the sign. However, neurobiological research
in ASL has confirmed that visual–spatial language
processing is essentially the same as oral–aural
language processing (Emmorey, 2002; Emmorey
et al., 2003; Horwitz et al., 2003). The overall
similarities in processing between ASL and spoken
English suggest that novice ASL bilinguals may
represent the new signs in the L2 via the same
mechanism that functions for bilinguals learning
a second spoken language.</p>
      <p>Therefore, a fundamental question remains
open in this area of research study: To what
extent are the memory processes involved in
learning ASL signs in the context of L2 learning similar
to, or different from, those involved in learning
an oral–aural language? Are signs processed like
words in spoken languages?</p>
      <p>The aim of the current study is threefold. First
and foremost is the aim to uncover the
characteristics of word representation that are acquired
when an adult first learns ASL sign vocabulary.
Knowing the levels of language representation
(e.g., phonological, semantic) that are acquired
and how best they can be acquired may inform
training methods for learning ASL as an L2.
Second, the work is aimed at investigating the
representation in memory of newly acquired signs
under situations that would promote the
automaticity of the access of that information.
Using an interference paradigm that will be
described later, it was possible to determine whether
semantic or phonological information was
encoded early in the learning of ASL signs without
the possibility of elaborative processes that can
be engaged in untimed response tasks. Third, the
present work is aimed at testing a hypothesis put
forth by Kroll and Stewart (1994) regarding the
conceptual or semantic development that occurs
when one first learns an L2. More will be said
about this final aim in the next section.</p>
      <p>THE CURRENT STUDY</p>
      <p>This study investigates a specific part of what
adult na¨ıve learners of ASL learn when first
exposed to the English equivalents of 28 simple ASL
signs. The study investigates only receptive skills
and the levels of representation acquired early
in learning. The study is not about learning ASL
itself; rather, it investigates what automatic
mental representations or associations are acquired
when adults unfamiliar with a visual language first
“learn” the verbal translations of some signs. The
theoretical models of bilingual memory
representation studied by both Kroll and Stewart (1994)
and Altarriba and Mathis (1997) are tested in the
current study on the memory of novice students
of ASL.</p>
      <p>In merging aspects of both the word association
model and the concept mediation model of
bilingual memory, Kroll and Stewart (1994) proposed
a model (i.e., the revised hierarchical model) that
describes the asymmetrical links that appear to be
present in bilingual language representation as
well as a model that accounts for the differences
reported in the literature on translation direction
(see Figure 3). This model contains mental
lexicons for the L1 as well as an L2. The L1 mental
lexicon is depicted as larger than that of the L2
because it is assumed that the bilingual would have
a larger vocabulary in his or her native language
than in the L2. The link between the L1 and
concepts appears to be bidirectional and very strong.
As a person acquires an L2, especially later in life,
L2 words would be integrated into memory by
developing a pathway that is attached to the lexicon
of the L1 (an idea emerging from the original
word association model). Finally, the connection
between the L2 and concepts is illustrated as
being weak. However, it has been suggested that this
link increases in strength as the bilingual becomes
more proficient or fluent in his or her L2 (a
notion derived from the earlier concept mediation
model).</p>
      <p>One advantage of the revised hierarchical
model is that it accounts for several findings that
have been reported in bilingual studies, such as
faster translation in the L2–L1 direction, category
interference that occurs only during L1–L2
translation (Kroll &amp; Stewart, 1994), and larger priming
effects in the L1–L2 direction than in the L2–L1
direction (e.g., Altarriba, 1992; Gollan, Forster,
&amp; Frost, 1997). In addition, the model attempts
to show how changes in a person’s proficiency in
the L2 will change the way in which lexical and
conceptual information is accessed (i.e., greater
proficiency in the L2 allows a greater amount
of conceptual information to be available).
Although this may be true to some extent, it has
been argued that new words in an L2 may not
be stored in just the lexicon of the L2 but rather
represented as both a lexical and conceptual
entry if the words were acquired in an environment
in which both form and meaning were
emphasized (see Altarriba &amp; Mathis, 1997). Further, it
is possible that the conceptual aspect of some
words may not be stored in a common conceptual
store for both languages, simply because there are
some items that may represent language-specific</p>
      <p>Note. L1 = first language; L2 = second language.
concepts and, therefore, direct translations in the
opposing language do not exist (Altarriba, 2000).</p>
      <p>Altarriba and Mathis (1997) questioned the
revised hierarchical model of Kroll and Stewart
(1994), which suggests that nonfluent bilinguals
rely on lexical association early in SLA and only
later on concept mediation. As mentioned earlier,
Altarriba and Mathis tested Kroll and Stewart’s
model with monolingual English speakers who
were taught Spanish for the first time. Altarriba
and Mathis designed a set of experiments to
investigate the acquisition of the link between
conceptual memory and the L2, hypothesizing that
it could develop as early as the first encounter or
first learning session with the new language. Kroll
and Stewart had claimed that this link developed
over an unspecified length of time and remained
relatively weak. Altarriba and Mathis chose a
translation recognition paradigm aimed at measuring
the interference that would be caused by the
presentation of L1–L2 (English–Spanish) pairs that
were in some way similar, but not identical, to
the true translations. They theorized that
individuals would be slower to respond (slower response
times [RTs]) to English–Spanish pairs that were
either orthographically or semantically similar to
the true translations (i.e., foils) that had been
acquired during the learning session of their
experiment. In the translation recognition task, they
indeed found that both monolingual and bilingual
participants had slower RTs to the foils. They
concluded that orthographic and semantic
information is automatically coded early in the process of
SLA. In other words, the meanings of words in the
new language were represented in the learner’s
conceptual store as early as the first learning
session. Could similar results be found in a
“crossmodal” bilingual environment?</p>
      <p>Because Altarriba and Mathis’s (1997) SLA
hypotheses and conclusions are based on
experimental data from oral–aural languages,
assumptions cannot be made as to whether these
hypotheses will function in the acquisition of all L2s,
spoken and visual. Therefore, one of the aims of
the present study was to investigate what adults
na¨ıve to ASL learn when first exposed to signs
and their English meanings. The current study
hypothesizes that hearing, English-speaking adults
learning ASL would also encode semantic, as well
as lexical, information early in the learning
process. However, as the study’s focus was a visual
language as the L2 acquired, hypothesizing about
orthographically similar words between the two
languages had to be altered. Instead, the
hypothesis concerned English words that were
phonologically similar to the correct translation. Adult
students of ASL should have slower RTs when the
English words are phonologically similar to the
correct translations than when the English words are
unrelated to the translations. A semantic
condition was also included, as in Altarriba and Mathis.</p>
      <p>To test these hypotheses, an experiment was
designed that included learning and testing phases.
First, participants viewed a videotape of ASL signs
and heard the signs’ English equivalents. After
the participants studied the signs and their
translations, we needed to determine if the
participants had “learned” the corresponding English
words. Second, the participants were tested on
their “learning.” They viewed the same list of signs
and heard an English word from one of the test
conditions, paired with each sign. They had to
determine whether the word was or was not the
English translation they had learned for the sign.
It was expected that interference in processing
would occur for the foils that were semantically
and phonologically similar to the correct
translations that the participants had learned in the
study phase of the experiment if the participants
had indeed accurately encoded the visual,
phonological, and semantic referents for each sign.</p>
      <p>Undergraduate introductory psychology
students (n = 48, average age = 19.8) from the
University at Albany, State University of New
York participated in this experiment for course
credit. The participants had normal or
correctedto-normal visual acuity and had no known
hearing limitations. When they were asked before the
experiment, the participants said they had no
knowledge of finger spelling or ASL. Additionally,
the participants were also asked about their
knowledge of ASL at the conclusion of the experiment.
This practice of asking participants about their
language background both before and after an
experiment has been used previously, as it has been
found that, on occasion, the act of performing
the experiment brings to mind a forgotten
memory of their exposure to ASL or other languages
(see, e.g., Altarriba &amp; Mathis, 1997). The
participants received partial course credit. At the end
of the experiment, a brief language history
questionnaire was administered to ensure that they
were na¨ıve to ASL. Mean self-ratings on a 10-point
scale revealed native fluency in English at 9.3.
Percent of the day English was spoken was 92.3.
Questionnaire results revealed no exposure to, or
knowledge of, ASL or any other signed language
(see Appendices A and B).</p>
      <p>Sign Selection. Twenty-eight signs were selected
that abided by the following four criteria: (a)
simple or monomorphemic, (b) frequently used,
(c) visually dissimilar from each another, and
(d) not transparent. We relied on two beginning
ASL teaching texts and two ASL dictionaries as
the source for simple and frequently used signs
(Humphries, Padden, &amp; O’Rourke, 1980; Smith,
Lentz, &amp; Mikos, 1988; Sternberg, 1994; Stokoe,
Casterline, &amp; Croneberg, 1965). We wanted to
select a list of signs that were completely distinct
from one another in terms of all parameters,
including movement, shape, and position. In other
words, if two signs varied from each other on a
single parameter, we excluded those items from
our final list of signs. This ensured that the signs
on the list were visually dissimilar. The English
translations of signs on the list were all concrete
nouns.</p>
      <p>A native deaf signer was videotaped signing
the list. Videotaping a native signer is the ASL
equivalent to having a native English speaker
say English words. The signer’s mean signing
time per word was 1,260 milliseconds. The
English speaker’s mean time for each word was 534
milliseconds. Therefore, it was determined that
a 5,000-millsecond interval between each sign
would give participants adequate time to see the
sign, hear the English word, and respond as
required. A 5-second interval was also the preferred
elapsed time between signs in recall and
recognition tests in other published works
(Bonvillian, Rea, Orlansky, &amp; Slade, 1987; Bower &amp;
Karlin, 1974; Cochran, McDonald, &amp; Parault, 1999).
There was no sound on the videotape.</p>
      <p>Next we needed to be sure the chosen signs
were not transparent. Thirty participants with
no knowledge of ASL or experience with finger
spelling and from the same pool as the
subsequent experiment were then asked to guess the
English translations for the signs. Two participants
correctly guessed two different signs. These signs
were eliminated from the list. This ensured that
the remaining signs were not transparent—that
is, their translations were not easily guessed—and,
thus, these signs were used in the ensuing
experiment.</p>
      <p>Creating Semantic Associates. The English
translations for the 28 signs selected were then
presented to 30 participants who did not take part
in the earlier norming study or in the subsequent
experiment. They were asked to write down the
first word that came to mind next to each of the
English words. All of the words that the
participants wrote were tabulated to find the word most
frequently associated with the target word on the
list. Only exact wording was tallied (i.e., not
plurals for singular words or derivations of our words
on the list). For example, for “shoe” people wrote
“sock” and “socks,” which were counted as two
different words. Thus, the most frequently reported
word for each target word was used as the
semantic associate for these items. As the participants
were from the same pool as those who would
perform the subsequent experiment, these
association norms would presumably reflect the
knowledge of the participants in the experiment proper.
Design and Apparatus</p>
      <p>The experiment required words in four test
conditions: (a) the target words (i.e., the English
words the participant learned for the videotaped
signs); (b) words unrelated to the target words;
(c) words semantically related to the target words;
and (d) words phonologically related to the
target words. The unrelated items were made up of
words of approximately the same length and
frequency as the signs’ English equivalents (Kuc˘era
&amp; Francis, 1967). Mean word length and mean
word frequency for the words in all four
conditions are listed in Table 1. t-Tests indicated no
significant differences across conditions for either
frequency or length (all ps &gt; .05). The
phonologically related condition was constructed of rhyming
words (Fergusson, 1985; Webster’s, 1987). Sample
stimulus items include the following: Targets:
apple, cookie; Unrelated: thigh, paddle; Semantic
Foil: pie, sweet; Phonological Foil: chapel, rookie.
Thus, the words that corresponded to the target
“apple” in each condition included “thigh,” “pie,”
and “chapel.” The set can be derived for “cookie”
in the same way from the examples provided
earlier (see Appendix C for a complete listing of
items).</p>
      <p>The videotape of the 28 common ASL signs
created previously was used in the current
experiment. Four signs and four English words, each
from a different test condition, were isolated for
use during the practice phase. The remaining 24
English words for each condition (i.e., the English
translations for the sign, the unrelated words, the
semantically related words, and the
phonologically related words) were counterbalanced across
four experimental lists such that 6 words from
each condition appeared only in one list. Each list
had a different set of six words from each of the
four conditions. To familiarize participants with
the test procedure, the four practice signs and
words were shown and heard at the start of each
test phase. Everyone received the same practice
items.</p>
      <p>The videotape of the 28 signs was then
reordered into four randomly selected orders using
Media 100’s digital nonlinear editing system. With
the GoldWave audio program, the 96 test English
words, 24 words in four conditions, plus 8 words
used for practice were entered into the computer.
The words were cued so that they would be heard
after the sign began but before the sign ended. To
standardize how the signs were presented to the
participant, Liddell’s (1984) description of sign
phonology was employed. In his description, a
sign can begin with either a MOVEMENT (M)
or a HOLD (H) at a stationary location. Signs can
also end with either an M or an H. For example,
the sign for FATHER is HMH. In the sign for
FATHER, the first movement to the forehead is not
relevant to sign formation. In the sign, the first
and last contacts of the thumb on the forehead
are HOLDS, with the intervening MOVEMENT.
(Note that another sign form for FATHER is the
thumb contact HOLD on the forehead without
MOVEMENT but with other fingers wiggling.)
While seeing FATHER on videotape, the
participant heard the English word “father” after the
initial H but before the M. The participant heard
the English word as the signer’s palm began
traveling toward her face. The English word was
completed before the signer’s thumb came to rest on
her forehead. Hearing the English translation at
the same moment in each sign’s articulation was
crucial for accurately recording RT. Therefore,
the words were cued to be heard just after the
initial M or H, as the signer was transitioning to the
following H or M of the sign.</p>
      <p>A program developed using SuperLab Pro
software was used to record elapsed time between the
onset of the English word and the participant’s
response. The signs for the experiment were
presented on a video monitor, and the words were
heard over speakers on either side of the monitor
and linked to a laptop computer.</p>
      <p>All participants were assigned a random
number and were tested individually. The first phase
of the experiment in which the participants
studied the signs and their English translations was
the acquisition phase. Participants were seated in
front of the video monitor to watch 28 signs one
by one and hear their English translations. They
were asked to try their best to learn the English
translations for the 28 ASL signs. Within the same
5-second interval for each sign, the participants
heard the sign’s English translation twice. The
videotape was repeated twice in the same order, so
the participants saw the signs twice and heard the
English translations four times. Then the
participants were asked to check what they had learned
by viewing the same 28 signs, without translations,
in a different order and saying aloud the English
word they remembered for the sign. At the end of
the viewing without the audio, we read aloud the
errors and omissions the participants had made
in naming the English translations and provided
the accurate sign and spoken translation for items
the participants had missed. Then the participants
viewed the list of 28 signs again but in a different
order. The English words and their
corresponding signs were repeated once again. This study
test process was repeated in full, until the
participants reached 100% accuracy. When the
participants named the translations for the signs 100%
correctly, they went on to the testing phase of the
experiment. To limit the duration of the
experiment, participants were excused from the
experiment if they did not reach 100% accuracy after
half an hour of study. On this basis, 3
individuals were excluded from finishing the experiment
and 3 new participants were added to maintain
the group number at 48.</p>
      <p>Following the acquisition phase, the
participants were given a 3-minute intervening task,
which included counting backward by 4s from
534. This task diverted the participants from
thinking about the acquisition phase and actively
engaging in rehearsal. The 3 minutes also allowed
us to set up the computer for the test phase.</p>
      <p>The second phase of the experiment, in which
the participants decided if the word they heard
was the translation they had learned for the sign,
was the testing phase. On the monitor, the
participants saw each of the 28 signs again in yet a
different order paired with hearing an English
word. (Four of those signs formed the practice
trials that were then followed by the remaining 24
signs divided equally among the following four
conditions: correct target, semantically related,
phonologically related, and unrelated.) Each
participant viewed a single experimental list in
random order. The participants were told to press a
designated “yes” or “no” key on the laptop keypad
indicating whether the word they heard was or
was not the word they had learned for the sign on
the video monitor. They were to make their
decisions as quickly and as accurately as possible.
The participants were given 1,500 milliseconds
to respond. At the beginning of the test phase,
four signs each with an English word were
presented as practice trials to familiarize the
participants with the test procedure. Then the actual test
proceeded.</p>
      <p>As mentioned earlier, at the end of the
experiment, the participants were asked four questions
about sign recognition (see Appendix B) and
answered a brief language history questionnaire.
None of the participants was found to have had
prior experience with ASL or any other signed
language.</p>
      <p>For each participant, mean response times and
standard deviations (SDs) were computed for the
four conditions (true target, semantic,
phonological, and unrelated). After computing SDs for each
participant’s RT in each condition, we found no
RTs, or outliers, that exceeded 2.5 SDs above or
below the mean for each condition. All
participants’ RTs were included in our analysis. Mean
RTs, SDs, and error rates for the four test
conditions (correct translation, unrelated, semantic,
and phonological) for all participants are listed
in Table 2. Only data for correct responses were
included. An analysis of variance (ANOVA)
indicated that the four conditions differed
significantly from one another, with F (3,45) = 27.708,
MS = 8.620, p &lt; .001. Planned comparisons
(Bonferroni corrections were applied) showed that RTs
for the semantic and the phonological conditions
were virtually the same, with t(47) = −0.220, p &gt;
.05. However, the RTs for the semantic and
phonological conditions compared to the unrelated
condition were significantly slower, indicated by
Note. ER = error rate; RT = response time.
t(47) = 2.363, p &lt; .05 (Cohen’s d = 0.48) and
t(47) = 2.753, p &lt; .01 (Cohen’s d = 0.56),
respectively. Semantically related foils produced
an interference effect suggesting that novices in
ASL had formed a conceptual link to the ASL
signs. Phonologically related foils produced a
slightly larger interference effect, indicating that
the participants had learned to associate the newly
acquired signs and their phonological
representations in English.</p>
      <p>Error data were examined to see if the higher
rate of errors in the phonological condition was
significantly different from other conditions (see
Table 2). An ANOVA indicated that there was a
significant difference in error rates across the four
conditions, with F (3,45) = 27.708, MS = 4.852;
p &lt; .001. Planned comparisons (Bonferroni
corrections were applied) revealed that the error rate
for the target condition differed significantly from
the phonological condition, with t(47) = −5.698,
p &lt; .001 (Cohen’s d = 1.16). In addition, the error
rate for the unrelated condition was significantly
different from the phonological condition, with
t(47) = −6.132, p &lt;. 0001 (Cohen’s d = 1.77).
Finally, the error rate for the semantic condition
was also significantly different from the
phonological condition, with t(47) = −5.695, p &lt; .001
(Cohen’s d = 1.16). Appendix D includes a
listing of individual items and their corresponding
error rates. Note that although only one item in
the semantic category produced a significant
error rate (i.e., “kids”), several items contributed to
the large error rate in the phonological
condition. In this later condition, most prominent were
the items “fair,” “bother,” and “fig,”
corresponding to “bear,” “father,” and “pig,” respectively.
Clearly, these kinds of errors of substitution stem
from the similarity across items in terms of
initial phonemes; thus, as in most situations,
whenever manner/place of articulation overlaps across
lexical items, errors of recognition and
identification are more likely to occur. More will be said
later in terms of the implications of these kinds of</p>
      <p>GENERAL DISCUSSION</p>
      <p>The experiments described here were designed
to follow the approach of Altarriba and Mathis’s
(1997) experiments in SLA. When Altarriba and
Mathis tested English-speaking monolinguals who
had just acquired a set of words in an L2
(Spanish), they found that these participants had
encoded both semantic and orthographic aspects
of the new words and were able to access this
new information when responding to a
translation recognition task. Because an interference
effect occurred for both conditions, it appeared
that monolinguals formed a direct link with
lexical and conceptual levels of representation when
first learning an L2. In the current study, the
results of the experiment on acquiring the ASL
signs confirmed that L2 (ASL) conceptual
processing (as well as phonological processing of the
English translation equivalents) is involved very
early in the language acquisition process. Both
semantic and phonological interference effects
were reported within the current study. It can
be assumed, then, that the processes involved in
acquiring an L2 as described by Altarriba and
Mathis also come into play for adult novices
learning a visual language as the L2. Moreover, as
reported by Altarriba and Mathis, the current work
also indicates that the revised hierarchical model
proposed by Kroll and Stewart (1994) should be
modified to indicate that conceptual/semantic
information can be acquired in the earliest stages
of L2 learning. In other words, even after a
single learning session, individuals can acquire the
knowledge of the meaning of newly learned L2
words—a link that had been purported to take
more time to develop, as per the revised
hierarchical model.</p>
      <p>In relation to the above issues of acquisition
and development, note that all of the participants
in the current study had been exposed to an L2
at some point in their lives (either from birth or
through schooling in later years; see Appendix A).
Thus, it appears that for the current participants,
the acquisition of concepts via sign constituted a
kind of “third-language” exposure, although it was
not a verbal language, as were their L1s and L2s.
Given the briefness of the questionnaire that was
used, it is difficult to assess the degree to which
the present participants were fluent in their L2
compared to their L1. Thus, although all
participants had been exposed to an L2 at some point
in their lives, their relative fluency in that
language is likely to have varied considerably and
is not currently known. Future investigations of
the acquisition of ASL signs should examine the
extent to which individuals who are exposed to an
L2 and who consider themselves truly “bilingual”
or “fluent/proficient” in their L2 show different
patterns of translation recognition for newly
acquired signs. Mode or context of learning and
acquisition should also be taken into account in
further investigations. Thus, participants’
bilingualism may be examined as a variable of
interest in future studies of sign acquisition, as
this question was not a focus of the current
investigation.</p>
      <p>The present study provided evidence that
conceptual and phonological interference occurs in
learning the meanings of ASL signs—a finding
similar to that reported for the acquisition of
words of a second, spoken language (see, e.g.,
Altarriba &amp; Mathis, 1997; van Hell &amp; Mahn, 1997).
Previous ASL research evidence points to the
parallel functioning of visual–spatial and oral–aural
languages. For example, signs that look
different from one another are identified more quickly
than those that look similar to one another. This
mimics the phonological similarity effect that occurs
in spoken languages (see also Emmorey, 2002).
In addition, Liddell (1984) illustrated how signs
have beginnings, middles, and ends similar to the
segments of spoken words, onsets, medial phases,
and offsets.</p>
      <p>An interesting finding in the current set of
results is that the error rates were significantly
higher in the phonological condition, as
compared to other conditions within the experiment;
that is, many more confusion errors occurred
when foils were phonologically similar to the true
translation. Given that the test pairs in the current
case were comprised of a spoken word and a word
that was signed, the implication is that the
participants accessed the phonological representations
of the signed words to the extent that those
representations interfered with their ability to reject
the incorrect pairing. Theoretically, these data
suggest that individuals accessed phonology when
not specifically directed to do so in the context of
the current study. Phonology was encoded in an
implicit manner, as part of the learning of signs,
overall. Thus, as current models of bilingual
representation have suggested (see, e.g., BIA and
BIA+ in Dijkstra &amp; van Heuven, 1998),
phonology is often retrieved in the process of
understanding newly acquired concepts in an L2—even
if it is a signed language. Further, the current
data underscore the basic finding in the
literature that many auditory confusion errors are
derived from words that have phonological
overlap and share either place of articulation or
manner of articulation, or both. The fact that these
phonological representations in the current study
stem from the recognition of a signed word is
interesting evidence to suggest that
phonological confusion errors are not modality-specific (see
also Engle, Cantor, &amp; Turner, 1989, for a related
discussion).</p>
      <p>Although the current study examined
translation recognition for newly acquired signs and
their English translations, the participants
performed a learning task that by its very nature
emphasized the phonological and semantic aspects
of the association between the English word and
its corresponding sign. Although the participants
developed these new representations such that
they achieved 100% accuracy on a test of their
knowledge, it is unclear to what extent
different participants might have engaged in their own
strategies in learning the signs of interest. Clearly,
the possibility that the participants engaged in
their own mnemonic strategies to shape their
mental representations for the signs and their
English counterparts may have affected the way in
which this knowledge was learned and encoded
for each participant. Future examinations of the
acquisition of signs should vary instructions so as
to either document the means by which
participants actively learn signs or provide concrete
instructions as to the types of strategies that should
be used (e.g., imagery, context availability) so
as to investigate the influence of learning
strategy on the ultimate representation of new signs.1
Moreover, it is important to note here that
although the current work focused on the
learning of ASL signs, the learning of language, in
general, encompasses many more elements that
bring together aspects of reasoning, pragmatic
usage, contextual influences, and the like (see,
e.g., Larsen-Freeman, 2003; van Lier, 2004). Thus,
language development is a highly dynamic
process, and future work may focus on the
acquisition of ASL signs in broader contexts of language,
incorporating a more ecological approach to
acquisition.</p>
      <p>In a related vein, neurological investigations
into the hemispheric involvement of imageable
concrete signs in ASL, as distinct from abstract
lexical forms, continue to raise questions about the
different roles imagery may play in ASL and
English (Emmorey &amp; Corina, 1993). Most recently,
neurobiological evidence also indicates that both
signed and spoken languages are generally
localized in the same area in the left hemisphere
(Corina, Vaid, &amp; Bellugi, 1992; Damasio &amp;
Damasio, 2000; Emmorey et al., 2003; Horwitz et al.,
2003).</p>
      <p>Notwithstanding the linguistic and
neurobiological parallels between ASL and the spoken
languages of the world, we recognize that the visual
modality makes a distinct difference in L2
learning. The current study kept the learning
challenge of ASL to a bare minimum (i.e., acquiring
the English words for 28 simple signs). Nothing
about sign perception was investigated. Clearly,
the greater part of understanding how sign-na¨ıve
adults learn ASL has to include working
memory experiments on what the adult learner
processes (i.e., sees, stores, attends to, recalls, etc.) in
the visual modality (see, e.g., Wilson &amp; Emmorey,
2003). Experiments on reproducing ASL signs
are recommended, as well as experiments with
ASL units longer than primarily single
monomorphemic signs.</p>
      <p>When we analyzed the ways the participants
remembered the English meanings during the study
phase of the present experiment, another
potential area of research became clear. Although the
participants studied the English meanings for the
signs in the learning part of the experiment, we
informally noted evident mnemonics used by two
participants, each for a single word. For example,
one participant said “father-head” while hearing
the word “father” and viewing FATHER, in which
the thumb of the open hand shape touches the
forehead. Another participant during the study
said “funny-nose” when seeing CLOWN, which
is made by cupping the nose with one hand.
Future experiments on systematically including
mnemonics in the study phase might offer
insight into another method for teaching ASL as an
L2.</p>
      <p>The concept mediation model, explained in
Altarriba and Mathis’s (1997) experiments and in
the current study, supports the practice of
teaching SLA using contextual units that emphasize the
semantic or conceptual representation of a newly
acquired word. Many beginning ASL texts already
emphasize contextual learning (see, e.g., Smith
et al., 1988). Thus, assuming that the acquisition
of words in aural and visual languages is similar,
researchers can focus on how the visual modality is
mentally represented by hearing adults learning a
signed language. What is most important to keep
in mind is that bilingual research should include
oral–aural as well as visual–spatial languages, and
as the experiment in this study shows, the concept
mediation hypothesis (as well as the modifications
of the revised hierarchical model as posed by
Altarriba and Mathis) applies to signed as well as to
spoken language.</p>
      <p>This research was completed as part of the
requirements for the Doctor of Philosophy degree awarded to
the first author. We would like to thank Lauren Cowell
for assistance with data collection, Erik L. Olheiser and
Matthew Pastizzo for their help with programming and
analysis, and Christine Pryzbylo for her role in the
development of research materials, as a native ASL signer. We
would also like to extend our gratitude to Rhoda
Linton, Nancy Mardas, Elizabeth Minnich, Randall Myers,
and Janet Pray for their comments on an earlier version
of this work, as members of the first author’s Doctoral
Dissertation Committee.</p>
      <p>1We thank an anonymous reviewer for pointing out
this issue to us in an earlier draft of the current article.</p>
    </sec>
    <sec id="2">
      <title>Responses to Language History Questionnaire (n = 48)</title>
      <p>Mean age in years
Mean self-rating (10-point scale: 1 = very little; 10 = native-like) on overall English fluency
Percentage of day English was typically spoken
Percentage of participants who had been exposed to an L2 other than English from birth
(countries of origin included Dominican Republic, India, Iran, Pakistan, and Puerto Rico)
Percentage of participants who had been exposed to an L2 other than English later in life,
primarily at school (languages included Spanish, Arabic, Hindi, and Farsi but NOT American
Sign Language or another signed language)
APPENDIX B
Posttest Interview Questions
APPENDIX C
Items Included in Experimental Test Conditions
APPENDIX D
Error Rates (Percentages) for Individual Items per Target Condition∗</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Altarriba</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          (
          <year>1990</year>
          ).
          <article-title>Constraints on interlingual facilitation effects in priming in Spanish-English bilinguals</article-title>
          .
          <source>Unpublished doctoral dissertation</source>
          , Vanderbilt University, Nashville, TN.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Altarriba</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          (
          <year>1992</year>
          ).
          <article-title>The representation of translation equivalents in bilingual memory</article-title>
          . In R. J. Harris (Ed.), Cognitive processing in bilinguals (pp.
          <fpage>157</fpage>
          -
          <lpage>174</lpage>
          ). Amsterdam: Elsevier Science.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Altarriba</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          (
          <year>2000</year>
          ).
          <article-title>Language processing and memory retrieval in Spanish-English bilinguals</article-title>
          .
          <source>Spanish Applied Linguistics, 4</source>
          ,
          <fpage>215</fpage>
          -
          <lpage>245</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Altarriba</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Mathis</surname>
            ,
            <given-names>M.</given-names>
          </string-name>
          (
          <year>1997</year>
          ).
          <article-title>Conceptual and lexical development in second language acquisition</article-title>
          .
          <source>Journal of Memory and Language</source>
          ,
          <volume>36</volume>
          ,
          <fpage>550</fpage>
          -
          <lpage>568</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Bonvillian</surname>
            ,
            <given-names>J. D.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Rea</surname>
            ,
            <given-names>A. C.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Orlansky</surname>
            ,
            <given-names>M. D.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Slade</surname>
            ,
            <given-names>L. A.</given-names>
          </string-name>
          (
          <year>1987</year>
          ).
          <article-title>The effect of sign language rehearsal on deaf subjects' immediate and delayed recall of English word lists</article-title>
          . Applied Psycholinguistics, 8,
          <fpage>33</fpage>
          -
          <lpage>54</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Bower</surname>
            ,
            <given-names>G. H.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Karlin</surname>
            ,
            <given-names>M. B.</given-names>
          </string-name>
          (
          <year>1974</year>
          ).
          <article-title>Depth of processing pictures of faces and recognition memory</article-title>
          .
          <source>Journal of Experimental Psychology</source>
          ,
          <volume>4</volume>
          ,
          <fpage>751</fpage>
          -
          <lpage>757</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Cochran</surname>
            ,
            <given-names>B. P.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>McDonald</surname>
            ,
            <given-names>J. L.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Parault</surname>
            ,
            <given-names>S. J.</given-names>
          </string-name>
          (
          <year>1999</year>
          ).
          <article-title>Too smart for their own good: The disadvantage of a superior processing capacity for adult language learners</article-title>
          .
          <source>Journal of Memory and Language</source>
          ,
          <volume>41</volume>
          ,
          <fpage>30</fpage>
          -
          <lpage>58</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Corina</surname>
            ,
            <given-names>D. P.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Vaid</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Bellugi</surname>
            ,
            <given-names>U.</given-names>
          </string-name>
          (
          <year>1992</year>
          ).
          <article-title>The linguistic basis of left hemisphere specialization</article-title>
          .
          <source>Science</source>
          ,
          <volume>255</volume>
          ,
          <fpage>1258</fpage>
          -
          <lpage>1260</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Damasio</surname>
            ,
            <given-names>A. R</given-names>
          </string-name>
          ., &amp;
          <string-name>
            <surname>Damasio</surname>
            ,
            <given-names>H.</given-names>
          </string-name>
          (
          <year>2000</year>
          ).
          <article-title>Language and the brain</article-title>
          . In K. Emmorey &amp; H. Lane (Eds.),
          <article-title>The signs of language revisited: An anthology to honor Ursula Bellugi</article-title>
          and
          <string-name>
            <given-names>Edward</given-names>
            <surname>Klima</surname>
          </string-name>
          (pp.
          <fpage>477</fpage>
          -
          <lpage>491</lpage>
          ). Mahwah, NJ: Erlbaum.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Dijkstra</surname>
            ,
            <given-names>T.</given-names>
          </string-name>
          , &amp; van Heuven,
          <string-name>
            <surname>W. J. B.</surname>
          </string-name>
          (
          <year>1998</year>
          ).
          <article-title>The BIA model and bilingual word recognition</article-title>
          .
          <source>In J. Grainger &amp; A</source>
          . Jacobs (Eds.),
          <article-title>Localist connectionist approaches to human cognition</article-title>
          (pp.
          <fpage>189</fpage>
          -
          <lpage>225</lpage>
          ). Hove, England: Erlbaum.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Emmorey</surname>
            ,
            <given-names>K.</given-names>
          </string-name>
          (
          <year>2002</year>
          ).
          <article-title>Language, cognition, and the brain</article-title>
          .
          <source>Mahwah, NJ: Erlbaum.</source>
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Emmorey</surname>
            ,
            <given-names>K.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Corina</surname>
            ,
            <given-names>D.</given-names>
          </string-name>
          (
          <year>1993</year>
          ).
          <article-title>Hemispheric specialization for ASL signs and English words: Differences between imageable and abstract forms</article-title>
          .
          <source>Neuropsychologia</source>
          ,
          <volume>31</volume>
          ,
          <fpage>645</fpage>
          -
          <lpage>653</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Emmorey</surname>
            ,
            <given-names>K.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Grabowski</surname>
            ,
            <given-names>T.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>McCullough</surname>
            ,
            <given-names>S.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Damasio</surname>
            ,
            <given-names>H.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Ponto</surname>
            ,
            <given-names>L.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Hichwa</surname>
            ,
            <given-names>R.</given-names>
          </string-name>
          , et al. (
          <year>2003</year>
          ).
          <article-title>Neural systems underlying lexical retrieval for sign language</article-title>
          .
          <source>Neuropsychologia</source>
          ,
          <volume>41</volume>
          ,
          <fpage>85</fpage>
          -
          <lpage>95</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Engle</surname>
            ,
            <given-names>R. W.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Cantor</surname>
            ,
            <given-names>J.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Turner</surname>
            ,
            <given-names>M. L.</given-names>
          </string-name>
          (
          <year>1989</year>
          ).
          <article-title>Modality effects: Do they fall on deaf ears</article-title>
          ?
          <source>Quarterly Journal of Experimental Psychology A: Human Experimental Psychology</source>
          ,
          <volume>41</volume>
          ,
          <fpage>273</fpage>
          -
          <lpage>292</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Fergusson</surname>
            ,
            <given-names>R.</given-names>
          </string-name>
          (
          <year>1985</year>
          ).
          <article-title>The Penguin rhyming dictionary</article-title>
          . London: Penguin Books.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Gollan</surname>
            ,
            <given-names>T. H.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Forster</surname>
            ,
            <given-names>K. I.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Frost</surname>
            ,
            <given-names>R.</given-names>
          </string-name>
          (
          <year>1997</year>
          ).
          <article-title>Translation priming with different scripts: Masked priming with cognates and noncognates in HebrewEnglish bilinguals</article-title>
          .
          <source>Journal of Experimental Psychology: Learning, Memory and Cognition</source>
          ,
          <volume>23</volume>
          ,
          <fpage>1122</fpage>
          -
          <lpage>1139</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Horwitz</surname>
            ,
            <given-names>B.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Amunts</surname>
            ,
            <given-names>K.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Bhattacharyya</surname>
            ,
            <given-names>R.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Patkin</surname>
            ,
            <given-names>D.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Jeffries</surname>
            ,
            <given-names>K.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Zilles</surname>
            ,
            <given-names>K.</given-names>
          </string-name>
          , et al. (
          <year>2003</year>
          ).
          <article-title>Activation of Broca's area during the production of spoken and signed language: A combined cytoarchitectonic mapping and PET analysis</article-title>
          .
          <source>Neuropsychologia</source>
          ,
          <volume>41</volume>
          ,
          <fpage>1868</fpage>
          -
          <lpage>1876</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Humphries</surname>
            ,
            <given-names>T.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Padden</surname>
            ,
            <given-names>C.</given-names>
          </string-name>
          , &amp; O'Rourke,
          <string-name>
            <surname>T. J.</surname>
          </string-name>
          (
          <year>1980</year>
          ).
          <article-title>A basic course in American Sign Language</article-title>
          . Silver Spring, MD: T. J. Publishers.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Kroll</surname>
            ,
            <given-names>J. F.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Stewart</surname>
            ,
            <given-names>E.</given-names>
          </string-name>
          (
          <year>1994</year>
          ).
          <article-title>Category interference in translation and picture naming: Evidence for asymmetric connections between bilingual memory representations</article-title>
          .
          <source>Journal of Memory and Language</source>
          ,
          <volume>33</volume>
          ,
          <fpage>149</fpage>
          -
          <lpage>173</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          Kuc˘era,
          <string-name>
            <given-names>H.</given-names>
            , &amp;
            <surname>Francis</surname>
          </string-name>
          ,
          <string-name>
            <surname>N. W.</surname>
          </string-name>
          (
          <year>1967</year>
          ).
          <article-title>Computational analysis of present-day American English</article-title>
          . Providence, RI: Brown University Press.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Larsen-Freeman</surname>
            ,
            <given-names>D.</given-names>
          </string-name>
          (
          <year>2003</year>
          ).
          <article-title>Teaching language: From grammar to grammaring</article-title>
          . Boston: Thomson-Heinle.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Liddell</surname>
            ,
            <given-names>S.</given-names>
          </string-name>
          (
          <year>1984</year>
          ).
          <article-title>Think and believe: Sequentiality in American Sign Language</article-title>
          . Language,
          <volume>60</volume>
          ,
          <fpage>372</fpage>
          -
          <lpage>398</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Potter</surname>
            ,
            <given-names>M. C.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>So</surname>
            ,
            <given-names>K.</given-names>
          </string-name>
          -F.,
          <string-name>
            <surname>von Eckardt</surname>
            ,
            <given-names>B.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Feldman</surname>
            ,
            <given-names>L. B.</given-names>
          </string-name>
          (
          <year>1984</year>
          ).
          <article-title>Lexical and conceptual representation in beginning and proficient bilinguals</article-title>
          .
          <source>Journal of Verbal Learning and Verbal Behavior</source>
          ,
          <volume>23</volume>
          ,
          <fpage>23</fpage>
          -
          <lpage>38</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Rosen</surname>
            ,
            <given-names>R. S.</given-names>
          </string-name>
          (
          <year>2008</year>
          ).
          <article-title>American Sign Language as a foreign</article-title>
          language in U.S.
          <article-title>high schools: State of the art</article-title>
          .
          <source>Modern Language Journal</source>
          ,
          <volume>92</volume>
          ,
          <fpage>10</fpage>
          -
          <lpage>38</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Smith</surname>
            ,
            <given-names>C.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Lentz</surname>
            ,
            <given-names>E. M.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Mikos</surname>
            ,
            <given-names>K.</given-names>
          </string-name>
          (
          <year>1988</year>
          ).
          <article-title>Signing naturally: Student workbook level 1</article-title>
          . San Diego, CA: DawnSign Press.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Sternberg</surname>
            ,
            <given-names>M.</given-names>
          </string-name>
          (Ed). (
          <year>1994</year>
          ).
          <article-title>American Sign Language dictionary (Rev</article-title>
          . ed.).
          <publisher-loc>New York</publisher-loc>
          : Harper Perennial.
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>Stokoe</surname>
            ,
            <given-names>W. C.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Casterline</surname>
            ,
            <given-names>D.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Croneberg</surname>
            ,
            <given-names>C. A.</given-names>
          </string-name>
          (
          <year>1965</year>
          ).
          <article-title>A dictionary of American Sign Language on linguistic principles</article-title>
          . Washington, D.C.:
          <string-name>
            <surname>Gallaudet</surname>
          </string-name>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          <string-name>
            <surname>van Hell</surname>
            ,
            <given-names>J. G.</given-names>
          </string-name>
          , &amp;
          <string-name>
            <surname>Mahn</surname>
            ,
            <given-names>A. C.</given-names>
          </string-name>
          (
          <year>1997</year>
          ).
          <article-title>Keyword mnemonics versus rote rehearsal: Learning concrete and abstract foreign words by experienced and inexperienced learners</article-title>
          .
          <source>Language Learning</source>
          ,
          <volume>47</volume>
          ,
          <fpage>507</fpage>
          -
          <lpage>546</lpage>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          1.
          <article-title>Did you recognize any signs? What signs?</article-title>
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          2.
          <article-title>Did any of the signs look like the English meanings after you learned them? Which?</article-title>
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          3.
          <article-title>Did you see any letters in the signs? Explain</article-title>
          .
        </mixed-citation>
      </ref>
      <ref>
        <mixed-citation>
          4.
          <article-title>Did you notice any relationship between the words you heard on the test and the words you learned for the signs? Explain</article-title>
          .
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
